[
  {
    "objectID": "book/references.html",
    "href": "book/references.html",
    "title": "References",
    "section": "",
    "text": "Fisher, R. A. 1925. Statistical Methods for Research Workers.\nEdinburgh Oliver & Boyd.\n\n\nHarris, Charles R., K. Jarrod Millman, Stéfan J. van der Walt, Ralf\nGommers, Pauli Virtanen, David Cournapeau, Eric Wieser, et al. 2020.\n“Array Programming with NumPy.”\nNature 585 (7825): 357–62. https://doi.org/10.1038/s41586-020-2649-2.\n\n\nKennedy-Shaffer, Lee. 2024. “Teaching the Difficult Past of\nStatistics to Improve the Future.” Journal of Statistics and\nData Science Education 32 (1): 108–19. https://doi.org/10.1080/26939169.2023.2224407.\n\n\nLohr, S. L. 2021. Sampling: Design and Analysis. Chapman;\nHall/CRC. https://doi.org/https://doi.org/10.1201/9780429298899.\n\n\nMacKenzie, D. A. 1981. Statistics in Britain, 1865-1930: The Social\nConstruction of Scientific Knowledge. Edinburgh University Press.\n\n\nR Core Team. 2024. “R: A Language and Environment for Statistical\nComputing.” Vienna, Austria: R Foundation for Statistical\nComputing. https://www.R-project.org/.\n\n\nReinhart, Alex. 2015. Statistics Done Wrong: The Woefully Complete\nGuide. 1st ed. San Francisco, CA: No Starch Press. https://www.statisticsdonewrong.com/index.html.\n\n\nRodríguez-Arelis, G. Alexi, Daniel Chen, Benjamin Bloem-Redd, Tiffany\nTimbers, and Vincenzo Coia. 2024. “DSCI 554: Experimentation and\nCausal Inference.” https://ubc-mds.github.io/DSCI_554_exper-causal-inf/README.html.\n\n\nTabery, James, and Sahotra Sarkar. 2015. “R. A. Fisher, Lancelot\nHogben, and the ‘Competition’ for the Chair of Social\nBiology at the London School of Economics in 1930: Correcting the\nLegend.” Notes and Records: The Royal Society Journal of the\nHistory of Science 69 (4): 437–46. https://doi.org/10.1098/rsnr.2014.0065.\n\n\nTarran, Brian. 2020. “Award\n‘Retired’ Over R. A. Fisher’s Links to\nEugenics.” Significance 17 (4): 2–3. https://doi.org/10.1111/1740-9713.01411.\n\n\nThe Pandas Development Team. 2024. “Pandas-Dev/Pandas:\nPandas.” Zenodo. https://doi.org/10.5281/zenodo.3509134.\n\n\nTukey, John W. 1962. “The Future of Data\nAnalysis.” The Annals of Mathematical Statistics\n33 (1): 1–67. https://doi.org/10.1214/aoms/1177704711.\n\n\nVan Rossum, Guido, and Fred L. Drake. 2009. Python 3 Reference\nManual. Scotts Valley, CA: CreateSpace.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy\nD’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019.\n“Welcome to the tidyverse.”\nJournal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "book/A-greek-alphabet.html",
    "href": "book/A-greek-alphabet.html",
    "title": "Appendix A — Greek Alphabet",
    "section": "",
    "text": "In the context of hypothesis testing in statistics, mathematical notation serves an important purpose: it distinguishes between unknown population parameters and sample-based estimates. A key convention in this framework is the use of Greek letters to represent population parameters. For example, \\(\\mu\\) represents the population mean, \\(\\sigma\\) denotes the population standard deviation, and \\(\\pi\\) signifies the population proportion. In a frequentist framework, these letters indicate unknown and fixed parameters that characterize the entire population of interest. Since hypothesis testing primarily focuses on making inferential conclusions about these parameters, we will consistently use this notation throughout all chapters of this mini-book.\n\n\nHeads-up on the use of \\(\\pi\\)!\n\n\nIn this textbook, unless otherwise stated, the letter \\(\\pi\\) will represent a population parameter and not the mathematical constant \\(3.141592...\\)\n\n\n\n\n\nImage by meineresterampe via Pixabay.\n\n\nIt is important to remember that each hypothesis test involves formulating null and alternative hypotheses regarding the population parameter(s) of interest. For instance, when inferring a population mean \\(\\mu\\), the null hypothesis in a two-sided one-sample \\(t\\)-test might indicate that this mean is equal to 100 (i.e., \\(\\text{$H_0$: } \\mu = 100\\)), while the alternative hypothesis will indicate that the mean is not equal to 100 (i.e., \\(\\text{$H_1$: } \\mu \\neq 100\\)). Using Greek letters to define our hypotheses helps frame the entire test clearly and precisely. If at any point throughout the chapters this notation feels unfamiliar, we recommend consulting Table A.1 as a reference resource. Regular exposure to this notation will enhance your conceptual clarity when performing statistical inference.\n\n\n\nTable A.1: Greek alphabet composed of 24 letters, from left to right you can find the name of letter along with its corresponding uppercase and lowercase forms.\n\n\n\n\n\nName\nUppercase\nLowercase\n\n\n\n\nAlpha\n\\(\\text{A}\\)\n\\(\\alpha\\)\n\n\nBeta\n\\(\\text{B}\\)\n\\(\\beta\\)\n\n\nGamma\n\\(\\Gamma\\)\n\\(\\gamma\\)\n\n\nDelta\n\\(\\Delta\\)\n\\(\\delta\\)\n\n\nEpsilon\n\\(\\text{E}\\)\n\\(\\epsilon\\)\n\n\nZeta\n\\(\\text{Z}\\)\n\\(\\zeta\\)\n\n\nEta\n\\(\\text{H}\\)\n\\(\\eta\\)\n\n\nTheta\n\\(\\Theta\\)\n\\(\\theta\\)\n\n\nIota\n\\(\\text{I}\\)\n\\(\\iota\\)\n\n\nKappa\n\\(\\text{K}\\)\n\\(\\kappa\\)\n\n\nLambda\n\\(\\Lambda\\)\n\\(\\lambda\\)\n\n\nMu\n\\(\\text{M}\\)\n\\(\\mu\\)\n\n\nNu\n\\(\\text{N}\\)\n\\(\\nu\\)\n\n\nXi\n\\(\\Xi\\)\n\\(\\xi\\)\n\n\nO\n\\(\\text{O}\\)\n\\(\\text{o}\\)\n\n\nPi\n\\(\\Pi\\)\n\\(\\pi\\)\n\n\nRho\n\\(\\text{P}\\)\n\\(\\rho\\)\n\n\nSigma\n\\(\\Sigma\\)\n\\(\\sigma\\)\n\n\nTau\n\\(\\text{T}\\)\n\\(\\tau\\)\n\n\nUpsilon\n\\(\\Upsilon\\)\n\\(\\upsilon\\)\n\n\nPhi\n\\(\\Phi\\)\n\\(\\phi\\)\n\n\nChi\n\\(\\text{X}\\)\n\\(\\chi\\)\n\n\nPsi\n\\(\\Psi\\)\n\\(\\psi\\)\n\n\nOmega\n\\(\\Omega\\)\n\\(\\omega\\)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Greek Alphabet</span>"
    ]
  },
  {
    "objectID": "book/B-simulated-datasets.html",
    "href": "book/B-simulated-datasets.html",
    "title": "Appendix B — Simulated Datasets",
    "section": "",
    "text": "B.1 ANOVA Dataset\nWhile we have made an effort to include real datasets wherever possible in this mini-book, we will utilize simulated data to demonstrate the application of the test workflow from Chapter 1 for certain hypothesis testings. This simulation-based approach allows us to have suitable datasets to illustrate how each test’s modelling assumptions must be satisfied to ensure that we deliver robust inferential conclusions to our stakeholders. Therefore, this appendix will explain the generative modelling process used to create these simulated datasets.\nFor each of the datasets listed below, besides providing the simulation code, we will elaborate on the dataset context along with the relevant equations (if necessary) that generate this data.\nThis dataset is used in Chapter 4 to elaborate on analysis of variance (ANOVA) and pertains to an experimental context. Suppose a data-driven marketing team at a well-known tech company, which operates a global online store, is conducting an A/B/n testing aimed at increasing the customer conversion score (i.e., the outcome). In this experiment, the customer conversion score is defined as a unitless and standardized engagement index. This index combines various elements, such as clicks, time spent on the webpage, and the probability of making a purchase, with a baseline mean set at \\(50\\). This score measures customer responsiveness on the online store: the higher the score, the greater the customer responsiveness.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Simulated Datasets</span>"
    ]
  },
  {
    "objectID": "book/B-simulated-datasets.html#anova-dataset",
    "href": "book/B-simulated-datasets.html#anova-dataset",
    "title": "Appendix B — Simulated Datasets",
    "section": "",
    "text": "Image by Pabitra Kaity via Pixabay.\n\n\nB.1.1 Generative Modelling Process\nThe experiment has the following controllable factors by the experimenter:\n\n\nWebpage design: Three different layouts \\(D_1\\) (the current layout), \\(D_2\\) (a new layout), and \\(D_3\\) (another new layout). This makes a three-level factor.\n\nDiscount framing: \\(\\text{Low}\\) (i.e., “Save 10% today”) or \\(\\text{High}\\) (i.e., “Save up to 40% today”). This makes a two-level factor.\n\nThis study will be a full factorial experiment characterized by the following elements:\n\nTwo factors: webpage design and discount framing.\nThere are \\(3 \\times 2 = 6\\) treatments (i.e., six different combinations of all the factor levels), which classifies this study as A/B/n testing.\nWe will simulate 200 customers (i.e., replicates) per treatment in our final dataset.\nThe outcome variable \\(Y\\) is the customer conversion score, which has been previously explained.\n\nOur data structure will be an additive model conceptually depicted as:\n\\[\n\\begin{align*}\n\\text{Outcome} &= \\text{First Main Effect} + \\text{Second Main Effect} \\\\\n& \\qquad \\text{Interaction Effect} + \\text{Random Error}.\n\\end{align*}\n\\tag{B.1}\\]\nThen, for the data generation process, let \\(Y_{i,j,k}\\) represent the customer conversion score for the \\(k\\)th replicate of the treatment related to the \\(i\\)th webpage design and the \\(j\\)th discount framing levels. Equation B.1 is translated as:\n\\[\nY_{i,j,k} = \\alpha_i + \\beta_j + (\\alpha \\beta)_{i,j} + \\varepsilon_{i,j,k},\n\\tag{B.2}\\]\nwhere\n\n\n\\(\\alpha_i\\) is the fixed first main effect corresponding to the \\(i\\)th level of webpage design for \\(i = D_1, D_2, D_3\\);\n\n\\(\\beta_j\\) is the second fixed main effect corresponding to the \\(j\\)th level of discount framing for \\(j = \\text{Low}, \\text{High}\\);\n\n\\((\\alpha \\beta)_{i,j}\\) is the fixed interaction effect between the \\(i\\)th and \\(j\\)th levels of webpage design and discount framing respectively, and\n\n\\(\\varepsilon_{i,j,k}\\) is the random error associated to each \\(Y_{i,j,k}\\).\n\n\n\nHeads-up on the mathematical representation of the interaction term!\n\n\nThe \\((\\alpha \\beta)_{i,j}\\) in Equation B.2 does not indicate that the main effects are multiplying each other. Mathematically, it is just another additive term on the right-hand side of the equation.\n\n\nIn this case, Equation B.2 is breaking down the outcome on the right-hand side into four additive components, which form the basis on how ANOVA models the data. With the exception of the random error \\(\\varepsilon_{i,j,k}\\), the other three terms are assumed to be fixed within the data-generating process, given that we are using a frequentist approach. Since \\(\\varepsilon_{i,j,k}\\) is random, we will assume that it follows a Normal distribution with a mean of \\(0\\) and a variance of \\(\\sigma^2\\) (which is another fixed parameter in the simulation):\n\\[\n\\varepsilon_{i,j,k} \\sim \\text{Normal}(0, \\sigma^2).\n\\] In terms of our simulation, imagine you have a population of customers with the following fixed parameters:\n\nA vector of webpage design effects (i.e., the first main effect)\n\n\\[\\boldsymbol{\\alpha} =\n\\begin{bmatrix} \\alpha_{D_1} \\\\ \\alpha_{D_2} \\\\ \\alpha_{D_3} \\end{bmatrix} =\n\\begin{bmatrix} 40 \\\\ 50 \\\\ 70 \\end{bmatrix}.\\]\n\nA vector of discount framing effects (i.e., the second main effect)\n\n\\[\\boldsymbol{\\beta} =\n\\begin{bmatrix} \\alpha_{\\text{Low}} \\\\ \\alpha_{\\text{High}} \\end{bmatrix} =\n\\begin{bmatrix} -5 \\\\ 12 \\end{bmatrix}.\\]\n\nA matrix of interaction effects, whose rows correspond to the levels of webpage design and columns to the levels of discount framing,\n\n\\[\n\\boldsymbol{(\\alpha \\beta)} =\n\\begin{bmatrix}\n(\\alpha \\beta)_{D_1,\\text{Low}} & (\\alpha \\beta)_{D_1,\\text{High}} \\\\\n(\\alpha \\beta)_{D_2,\\text{Low}} & (\\alpha \\beta)_{D_2,\\text{High}} \\\\\n(\\alpha \\beta)_{D_3,\\text{Low}} & (\\alpha \\beta)_{D_3,\\text{High}}\n\\end{bmatrix} =\n\\begin{bmatrix}\n0 & 5 \\\\\n-8 & 0 \\\\\n11 & -13\n\\end{bmatrix}.\n\\]\n\nAn overall variance\n\n\\[\n\\sigma^2 = 16.\n\\]\nThe fixed-effect interaction arrangement above induces non-parallel trends in an interaction plot, as shown in Chapter 4, while preserving additive decomposition for interpretation and statistical testing.\n\nB.1.2 Code\nLet us move to the corresponding code to simulate this data. Recall we are simulating 200 customers for each one of the six treatments, which will give us an overall sample size of \\(n = 1,200\\). Furthermore, note that Python additionally uses the {numpy} (Harris et al. 2020) and {pandas} libraries. The final data frame will be stored in ABn_customer_data whose columns will be webpage_design, discount_framing, and conversion_score.\n\n\nR Code\nPython Code\n\n\n\nset.seed(123)  # Seed for reproducibility\n\n# Factor levels and sampled customers per treatment\nwebpage_design_levels &lt;- c(\"D1\", \"D2\", \"D3\")\ndiscount_framing_levels &lt;- c(\"Low\", \"High\")\nn_per_treatment &lt;- 200\n\n# Population fixed additive parameters\nalpha &lt;- c(40, 50, 70)\nbeta &lt;- c(-5, 12)\ninteraction &lt;- matrix(\n  c(\n    0, 5,\n    -8, 0,\n    11, -13\n  ),\n  nrow = 3, byrow = TRUE\n)\n\n# Simulating data\ndata_list &lt;- list()\nfor (i in 1:3) {\n  for (j in 1:2) {\n    mean_ij &lt;- alpha[i] + beta[j] + interaction[i, j]\n    y &lt;- rnorm(n_per_treatment, mean = mean_ij, sd = sqrt(16))     # sigma^2 = 16\n    df_ij &lt;- data.frame(\n      webpage_design = as.factor(webpage_design_levels[i]),\n      discount_framing = as.factor(discount_framing_levels[j]),\n      conversion_score = round(y, 2)\n    )\n    data_list[[length(data_list) + 1]] &lt;- df_ij\n  }\n}\nABn_customer_data &lt;- do.call(rbind, data_list)\n\n# Showing the first 100 customers of the A/B/n testing\nhead(ABn_customer_data, n = 100)\n\n\n# Importing libraries\nimport numpy as np\nimport pandas as pd\n\n# Set seed for reproducibility\nnp.random.seed(123)\n\n# Factor levels and sampled customers per treatment\nwebpage_design_levels = [\"D1\", \"D2\", \"D3\"]\ndiscount_framing_levels = [\"Low\", \"High\"]\nn_per_treatment = 200\n\n# Population fixed additive parameters\nalpha = [40, 50, 70]          \nbeta = [-5, 12]              \ninteraction = np.array([\n    [0, 5],\n    [-8, 0],\n    [11, -13]\n])\n\n# Simulating data\ndata_list = []\n\nfor i in range(3):  \n    for j in range(2):  \n        mean_ij = alpha[i] + beta[j] + interaction[i, j]\n        y = np.random.normal(loc=mean_ij, scale=np.sqrt(16), size = n_per_treatment)      # sigma^2 = 16\n        y_rounded = np.round(y, 2) \n        \n        df_ij = pd.DataFrame({\n            'webpage_design': [webpage_design_levels[i]] * n_per_treatment,\n            'discount_framing': [discount_framing_levels[j]] * n_per_treatment,\n            'conversion_score': y_rounded\n        })\n        \n        data_list.append(df_ij)\n\n# Concatenate all groups into one DataFrame\nABn_customer_data = pd.concat(data_list, ignore_index = True)\n\n# Showing the first 100 customers of the A/B/n testing\nprint(ABn_customer_data.head(100))\n\n\n\n\n\nR Output\nPython Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHarris, Charles R., K. Jarrod Millman, Stéfan J. van der Walt, Ralf Gommers, Pauli Virtanen, David Cournapeau, Eric Wieser, et al. 2020. “Array Programming with NumPy.” Nature 585 (7825): 357–62. https://doi.org/10.1038/s41586-020-2649-2.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Simulated Datasets</span>"
    ]
  },
  {
    "objectID": "book/chapter4-anova.html",
    "href": "book/chapter4-anova.html",
    "title": "4  ANOVA-related Tests for \\(k\\) Continuous Population Means",
    "section": "",
    "text": "4.1 The ANOVA Dataset\nIt is time to expand our hypothesis testing framework from comparing two population means to a generalized approach for \\(k\\) population means by exploring analysis of variance (ANOVA). ANOVA is a foundational test in frequentist statistics designed to compare means across multiple populations under specific distributional assumptions, which we will examine in this chapter. Originally formalized by Ronald A. Fisher (Fisher 1925), ANOVA extends the concept of the two-sample \\(t\\)-test by partitioning the total variability of our outcome of interest into components attributable to main effects, interactions, and random error. This partitioning enables us to determine whether observed differences in groups are improbable to appear under the null hypothesis, which states that all groups share the same population mean.\nThis chapter builds on the concepts introduced in the earlier works by Chapter 2 and Chapter 3, which concentrated on hypothesis testing for one and two groups, respectively. While those chapters primarily addressed pairwise comparisons, we will now shift our focus multiple comparisons:\nAs a side note, the workflow guiding this chapter, as referenced in Figure 1.1, will provide a structured approach for applying both one-way and two-way ANOVA to the same A/B/n dataset (see Section 4.1).\nThe simulated dataset discussed in this chapter relates to an experimental context known as A/B/n testing, which is an expansion of traditional A/B testing as previously discussed. In a typical A/B testing, participants are randomly assigned to one of two strategies, referred to as treatments: treatment \\(A\\) (the control treatment) and treatment \\(B\\) (the experimental treatment). This approach enables us to infer causation concerning the following inquiry:\nIn an ANOVA setting, the outcome must be continuous. The primary goal of A/B testing is to determine whether there is a statistically significant difference between treatments \\(A\\) and \\(B\\) concerning the outcome. Additionally, because we are conducting a proper randomized experiment, we can infer causation (which goes further than mere association), as treatment randomization enables us to get rid of the effect of further confounders.\nWhen conducting experiments with more than two treatments in A/B testing, the experiment is referred to as A/B/n testing. In this case, the “n” does not indicate the sample size; rather, it simply represents any number of additional treatments beyond treatments \\(A\\) and \\(B\\). With this clarification, we can now proceed with our simulated dataset.\nTable 4.1: First 100 rows of our A/B/n simulated data.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ANOVA-related Tests for $k$ Continuous Population Means</span>"
    ]
  },
  {
    "objectID": "book/chapter4-anova.html#sec-ANOVA-dataset",
    "href": "book/chapter4-anova.html#sec-ANOVA-dataset",
    "title": "4  ANOVA-related Tests for \\(k\\) Continuous Population Means",
    "section": "",
    "text": "Will changing from treatment \\(A\\) to treatment \\(B\\) cause my outcome of interest, \\(Y\\), to increase (or decrease, if that is the case)?\n\n\n\n\nHeads-up on confounding!\n\n\nIn causal inference, confounding refers to the mixing of effects between the outcome of interest, denoted as \\(Y\\), the randomized factor \\(X\\) (which is a two-level factor in A/B testing, corresponding to treatment \\(A\\) and treatment \\(B\\)), and a third, uncontrollable factor known as the confounder \\(C\\). This confounder is associated with the factor \\(X\\) and independently affects the outcome \\(Y\\), as shown by Figure 4.2.\n\n\n\n\n\nFigure 4.2: Diagram depicting confounding (Rodríguez-Arelis et al. 2024).\n\n\n\n\n\n\n\nImage by Pabitra Kaity via Pixabay.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ANOVA-related Tests for $k$ Continuous Population Means</span>"
    ]
  },
  {
    "objectID": "book/chapter4-anova.html#sec-one-way-ANOVA",
    "href": "book/chapter4-anova.html#sec-one-way-ANOVA",
    "title": "4  ANOVA-related Tests for \\(k\\) Continuous Population Means",
    "section": "\n4.2 One-way ANOVA",
    "text": "4.2 One-way ANOVA\n\n4.2.1 Study Design\n\n4.2.2 Data Collection and Wrangling\n\n4.2.3 Exploratory Data Analysis\n\n4.2.4 Testing Settings\n\n4.2.5 Hypothesis Definitions\n\n4.2.6 Test Flavour and Components\n\n4.2.7 Inferential Conclusions\n\n4.2.8 Storytelling",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ANOVA-related Tests for $k$ Continuous Population Means</span>"
    ]
  },
  {
    "objectID": "book/chapter4-anova.html#sec-two-way-ANOVA",
    "href": "book/chapter4-anova.html#sec-two-way-ANOVA",
    "title": "4  ANOVA-related Tests for \\(k\\) Continuous Population Means",
    "section": "\n4.3 Two-way ANOVA",
    "text": "4.3 Two-way ANOVA\n\n4.3.1 Study Design\n\n4.3.2 Data Collection and Wrangling\n\n4.3.3 Exploratory Data Analysis\n\n4.3.4 Testing Settings\n\n4.3.5 Hypothesis Definitions\n\n4.3.6 Test Flavour and Components\n\n4.3.7 Inferential Conclusions\n\n4.3.8 Storytelling",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ANOVA-related Tests for $k$ Continuous Population Means</span>"
    ]
  },
  {
    "objectID": "book/chapter4-anova.html#sec-chapter-4-summary",
    "href": "book/chapter4-anova.html#sec-chapter-4-summary",
    "title": "4  ANOVA-related Tests for \\(k\\) Continuous Population Means",
    "section": "\n4.4 Chapter Summary",
    "text": "4.4 Chapter Summary\n\n\n\n\nFisher, R. A. 1925. Statistical Methods for Research Workers. Edinburgh Oliver & Boyd.\n\n\nKennedy-Shaffer, Lee. 2024. “Teaching the Difficult Past of Statistics to Improve the Future.” Journal of Statistics and Data Science Education 32 (1): 108–19. https://doi.org/10.1080/26939169.2023.2224407.\n\n\nMacKenzie, D. A. 1981. Statistics in Britain, 1865-1930: The Social Construction of Scientific Knowledge. Edinburgh University Press.\n\n\nRodríguez-Arelis, G. Alexi, Daniel Chen, Benjamin Bloem-Redd, Tiffany Timbers, and Vincenzo Coia. 2024. “DSCI 554: Experimentation and Causal Inference.” https://ubc-mds.github.io/DSCI_554_exper-causal-inf/README.html.\n\n\nTabery, James, and Sahotra Sarkar. 2015. “R. A. Fisher, Lancelot Hogben, and the ‘Competition’ for the Chair of Social Biology at the London School of Economics in 1930: Correcting the Legend.” Notes and Records: The Royal Society Journal of the History of Science 69 (4): 437–46. https://doi.org/10.1098/rsnr.2014.0065.\n\n\nTarran, Brian. 2020. “Award ‘Retired’ Over R. A. Fisher’s Links to Eugenics.” Significance 17 (4): 2–3. https://doi.org/10.1111/1740-9713.01411.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ANOVA-related Tests for $k$ Continuous Population Means</span>"
    ]
  },
  {
    "objectID": "book/chapter3-two-pop.html",
    "href": "book/chapter3-two-pop.html",
    "title": "3  Tests for Two Continuous Population Mean",
    "section": "",
    "text": "3.1 Two sample Student’s t-test for Independent Samples\nThis chapter introduces statistical tests designed to compare two samples which is a fundamental task in data analysis across many disciplines. Whether you’re comparing average recovery times between two medical treatments, student test scores under different teaching methods, comparing the proportion among two samples, or reaction times under varying stress conditions, these methods help determine whether observed differences are statistically significant or simply due to chance.\nIn this chapter, we review tests for comparing two continuous population means under two conditions: when the populations are independent and when they are dependent. Throughout the sections below, we provide details about these tests and required formula for each case. Broadly speaking, there are two main types of tests to compare the means between two continuous populations:\nThe choice of test depends on the structure of your data. This chapter introduces both types of comparisons, beginning with independent samples. Each section includes definitions, theoretical background, and R/Python code examples using real or simulated data sets to help ground the concepts in practice. We also review the theoretical background and exmaple codes to test two proportions.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tests for Two Continuous Population Mean</span>"
    ]
  },
  {
    "objectID": "book/chapter3-two-pop.html#two-sample-students-t-test-for-independent-samples",
    "href": "book/chapter3-two-pop.html#two-sample-students-t-test-for-independent-samples",
    "title": "3  Tests for Two Continuous Population Mean",
    "section": "",
    "text": "3.1.1 Review\nIn this section we talk about two sample student’s t-test for independent samples. Independent samples arise when the observations in one group do not influence or relate to the observations in the other. In statistical terms we call this two independent samples. A classic example from educational research is described below:\nSuppose you’re interested in whether a new method of teaching introductory physics improves student performance and learning experience. To investigate this, you decide to test the method at two universities: the University of British Columbia (UBC) and Simon Fraser University (SFU). You apply the new teaching method at SFU and compare the results to students taught with the traditional method at UBC.\nIn this scenario, students at UBC and SFU form two distinct, unrelated groups. Since the students are not paired or matched across schools, and each individual belongs to only one group, the samples are independent. Note that the samples are drawn from two independent population: students at UBC and SFU, respectively.\nLet us assume that each population has an unknown average or mean physics score denoted by:\n\\[\n    \\mu_1 \\quad \\text{(mean for UBC)}, \\quad \\mu_2 \\quad \\text{(mean for SFU)}.\n\\]\nSince we do not have access to all students’ grades, we take a random sample from each school. Suppose:\n\nFrom UBC (Population 1), we obtain a sample of size \\(n\\), denoted as: \\[X_1, X_2, \\ldots, X_n\\]\nFrom SFU (Population 2), we obtain a sample of size \\(m\\), denoted as: \\[Y_1, Y_2, \\ldots, Y_m\\]\n\nNote that the sample sizes \\(n\\) and \\(m\\) do not necessarily have to be equal. Now, the central question becomes:\nIs there a statistically significant difference between the mean physics scores among two groups?\nIn formal terms, we test the hypotheses:\n\\[H_0: \\mu_1 = \\mu_2 \\quad \\text{versus} \\quad H_A: \\mu_1 \\ne \\mu_2\\] Now that we reviewed the test concept, let’s try to understand it in a read data set. The steps below follows closely with the roadmap that we introduced in [LINK HERE].\n\n3.1.2 Study design\nFor this example, we will be using Auto data set from ISLR package. This data set contains gas mileage, horsepower, and other information for 392 vehicles. Some of variables of interest are: 1) cylinders an integer (numerical) value between 4 and 8 which indicates the number of cylinders of car, and 2) horsepower which shows engine horsepower. You may wondering if the mean of horsepower in cars with 8 cylinders is statistically different than the means in cars with 4 cylinders?\n\n3.1.3 Data Collection and Wrangling\nTo answer this question, we obtain the data set which is available in ISLR package. Note that we consider this data a random sample from population of cars. First we create a new copy of this data set to avoid touching the actual data (this is optional). Also we filter rows to those cars with 4 or 8 cylinders only.\n\n# Get a copy of data set\nauto_data &lt;- Auto\n\n# Filter rows to cars with 4 or 8 cylinders\nauto_data &lt;- auto_data %&gt;% filter(cylinders %in% c(4,8) )\n\nFinally, we randomly create test and train set from this data set. We use a proportion of 50-50 between train and test.\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Splitting the data set into train and test sets\ntrain_indices &lt;- sample(seq_len(nrow(auto_data)), size = 0.50 * nrow(auto_data))\ntrain_auto &lt;- auto_data[train_indices, ]\ntest_auto &lt;- auto_data[-train_indices, ]\n\n\n3.1.4 Explanatory Data Analysis\nOnce we have the data and it is split into training and test sets, the next step is to begin exploratory data analysis (EDA) on train set. This step is crucial, as it helps us gain a better understanding of the distribution of variables in our data set. The horsepower variable in data set is a numerical variable. The cylinders variable is an integer variable that helps to divide observations into two groups.\nIn particular, we are interested in the distribution of horsepower in two different groups (cars with 4 cylinders vs cars with 8 cylinders). Using a histogram for this variable is a good choice as we have a variable with numerical values.\n\n\n\n\n\n\n\n\nWe also look at some descriptive statistics of horsepower in both groups for better understanding of data. The descriptive statistics in cars with 4 cylinders:\n\nsummary(train_auto %&gt;% filter(cylinders == 4) %&gt;% select(horsepower))\n\n   horsepower    \n Min.   : 46.00  \n 1st Qu.: 68.00  \n Median : 78.50  \n Mean   : 78.33  \n 3rd Qu.: 88.00  \n Max.   :113.00  \n\n\nand with 8 cylinders:\n\nsummary(train_auto %&gt;% filter(cylinders == 8) %&gt;% select(horsepower))\n\n   horsepower \n Min.   :105  \n 1st Qu.:140  \n Median :150  \n Mean   :160  \n 3rd Qu.:175  \n Max.   :225  \n\n\nLooking at summary statistics, there is a bit of overlap between distribution of horsepower among two groups but it does not seem to be much. In fact they seem to be quite separated. Also there is a clear different in their mean and the following plot also confirms this:\n\n\n\n\n\n\n\n\n\n3.1.5 Testing Settings\nWe use a significant level of \\(\\alpha = 0.05\\) to run the test. Considering the data we have is a sample from a population of cars we have the following:\n\n\n\\(\\mu_{1}\\) is the mean of horsepower for cars with 4 cylinders in the population.\n\n\\(\\mu_{2}\\) is the mean of horsepower for cars with 8 cylinders in the population.\n\n3.1.6 Hypothesis Definitions\nWe now define the null and alternative hypothesis. Recall the main inquiry we had:\nYou may wondering if the average of horsepower in cars with 4 cylinders is statistically different than the means in cars with 8 cylinders?\nThis translates into the following null and alternative hypotheses:\n\\[H_0: \\mu_{1} = \\mu_{2} \\quad vs \\quad H_a: \\mu_{1} \\neq \\mu_{2}\\]\nNote that the alternative hypothesis is two-sided, as our question does not favor either group and only asks whether the means are different (i.e., group one could be less than or greater than group two). Also the hypothesis tests the unknown parameters in the population which are \\(\\mu_{1}\\) and \\(\\mu_{2}\\).\n\n3.1.7 Test Flavour and Components\nTo test this hypothesis, we use the two-sample student’s t-test for independent samples, which compares the sample means and incorporates variability within and between the samples. Note that in this case the samples are independent as clearly cars with 4 cylinders are independent from cars with 8 cylinders.\nNow we need to compute a test statistic from the sample. Assuming equal population variances, the test statistic is:\n\\[t = \\frac{(\\bar{X} - \\bar{Y})}{S_p \\sqrt{\\frac{1}{n} + \\frac{1}{m}}}\\] where:\n\n\n\\(\\bar{X}\\) is the mean of horsepower for cars with 4 cylinders in the sample\n\n\\(\\bar{Y}\\) is the mean of horsepower for cars with 8 cylinders in the sample\n\n\\(S_p\\) is the , computed as:\n\\(S_p = \\sqrt{\\frac{(n - 1)S_X^2 + (m - 1)S_Y^2}{n + m - 2}}\\)\n\n\\(S_X^2\\) and \\(S_Y^2\\) are the sample variances of the two groups.\n\n\n\nHeads-up!\n\n\nNote that all elements in this formula (statistic) are computed based on sample.\n\n\n\n\nTip:\n\n\nThe assumption in this test is that variances among two groups are equal meaning that if we look at the random variable of horsepower in both populations, the variance of this random variable is roughly equal in two groups (cars with 4 cylinders and cars with 8 cylinders).\nNote that we do not have access to population and this is rather an assumption that we make with consultation with experts or justifying it based on previous studies. We will introduce the test without equal variance assumption in the next section.\nThere are some statistical methods designed to test if the variances of different groups are the same or not. Similar to any hypothesis testing, these tests work on a random sample from the population to run the test. Some of the tests are F-test for Equality of Variances, Levene’s Test, and Bartlett’s Test.\n\n\n\n3.1.8 Inferential Conclusions\nAs you can see, the test statistic computes the difference between \\(\\bar{X}\\) and \\(\\bar{Y}\\) and scale it based on the variance of this difference. Now the question is whether this difference is significant or not? In order to answer this question we need to know the behavior of statistic that we defined (\\(t\\)) and have a better understanding of what are typical values of this statistic. Knowing the distribution of this statistic helps us to compute \\(\\textit{p-value}\\) of the test as follows:\n\\[\\textit{p-value} = 2 \\times Pr(T_{n+m-2} \\ge |t|)\\]\nLooking at the formula, we can see that we are essentially calculating how much is it likely to see an observation as big as \\(t\\) or as extreme as \\(t\\) (which we computed from our sample).\n\n\nHeads-up!\n\n\nNote that \\(t\\) itself is a random variable as it would change from sample to sample.\n\n\n\n\nTip:\n\n\nWe skipped the theory behind it but under the assumption that null hypothesis is correct (i.e. \\(\\mu_1=\\mu_2\\)) then the test statistic defined above (\\(t\\)) follows a t-distribution with \\(n + m -2\\) degrees of freedom (which we denote it by \\(T_{n+m-2}\\)).\nNote: The probability is multiplied by two since we have a two sided hypothesis (alternative is \\(\\mu_1 \\neq \\mu_2\\)). For a one sided test (when alternative hypothesis is \\(\\mu_1 &gt; \\mu_2\\) or \\(\\mu_1 &lt; \\mu_2\\)) we do not need to multiply by two.\nNow we compare the \\(\\textit{p-value}\\) to our significance level. If the \\(\\textit{p-value}\\) is less than the significance level, then we have evidence against the null hypothesis. The reasoning is as follows: we performed the calculation under the assumption that the null hypothesis is true. If the null hypothesis is true, then the test statistic we computed should follow a \\(t\\)-distribution with \\(n + m - 2\\) degrees of freedom. If the p-value is smaller than our chosen significance level, this means it is unlikely that our observed result comes from a \\(t\\)-distribution with \\(n + m - 2\\) degrees of freedom. In other words, it is unlikely that the null hypothesis is correct.\n\n\nNote that our observation from the sample might still lead us to an incorrect conclusion (since there is variability among samples). Our tolerance for this type of error is determined by the significance level. If \\(\\textit{p-value}\\) is not less than significant level then we do not have any evidence to reject the null hypothesis. Now let us see how to run the two-sample test in R and Python. Note that for the purpose of hypothesis testing we now use test data to avoid double dipping.\n\n3.1.9 How to run the test in R and Python?\nThe following lines of code in tabset show you how to run the test in R or Python. Note that there are two ways of running this test in R as shown below. They both give the same result and you are welcome to use either of them. Here is a quick explanation from a coding perspective:\n\nIn Option 1, we first select the cars with 4 or 8 cylinders and save them in a vector (cylinders_4 and cylinders_8). We then use t.test function to run the test.\nIn Option 2, we use a formula to tell R what is the variable that records the outcome of interest (in this example horsepower variable) and what is the grouping variable (in this example cylinders). This approach is more concise and easier to read, especially when working directly with a data frame. Note that we need to let R know where it can find horsepower and cylinders which we do by setting data = test_auto.\n\n\n\nR Code - Option 1\nR Code - Option 2\nPython Code\n\n\n\n\n# Create a vector to hold horsepower values for cars with 4 cylinders\ncylinders_4 &lt;- test_auto %&gt;% filter(cylinders == 4) %&gt;% select(horsepower)\n\n# Create a vector to hold horsepower values for cars with 8 cylinders\ncylinders_8 &lt;- test_auto %&gt;% filter(cylinders == 8) %&gt;% select(horsepower)\n\n# Run the test\nt.test(x = cylinders_4, y = cylinders_8, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  cylinders_4 and cylinders_8\nt = -21.344, df = 149, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -85.12730 -70.70086\nsample estimates:\nmean of x mean of y \n  78.2381  156.1522 \n\n\n\n\n\n# Use the formula horsepower ~ cylinders to run the test \nt.test(horsepower ~ cylinders, data = test_auto, var.equal=TRUE)\n\n\n    Two Sample t-test\n\ndata:  horsepower by cylinders\nt = -21.344, df = 149, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group 4 and group 8 is not equal to 0\n95 percent confidence interval:\n -85.12730 -70.70086\nsample estimates:\nmean in group 4 mean in group 8 \n        78.2381        156.1522 \n\n\n\n\n\nfrom scipy import stats\nimport pandas as pd\n\n# Read test_auto dataframe in Python as df dataframe\ndf = pd.read_csv('data/test_auto.csv')\n\n# Select cars with 4 and 8 cylinders\ncylinders_4 = df[df[\"cylinders\"] == 4][\"horsepower\"]\ncylinders_8 = df[df[\"cylinders\"] == 8][\"horsepower\"]\n\n# Run the test\nt_stat, p_val = stats.ttest_ind(cylinders_4, cylinders_8, equal_var = True)\n\n# Print t statistic value\nprint(f\"T-statistic: {t_stat}\")\n\nT-statistic: -21.34403814660459\n\n# Print p-value of the test\nprint(f\"P-value: {p_val}\")\n\nP-value: 3.6294706302411423e-47\n\n\n\n\n\nIn order to run this test, similar to what we learned in (LINK to chapter 1) we can use t.test function in R. The function can be used to perform one or two sample t-tests. The relevant arguments of the function are as follows:\n\n\nx is (non-empty) numeric vector of data values.\n\ny is also (non-empty) numeric vector of data values (can be NULL if you run a one sample test).\n\nvar.equal is a binary value (TRUE/FALSE) to indicate if R needs to assume equal variance or not.\n\nIn both outputs, we can see the following:\n\nt is the test statistic.\ndf is the degrees of freedom for the test.\n\np-value is the p-value of the test. Note that, by default, this is for a two-sided test. If you need to conduct a one-sided test, you can either divide the p-value by two or use the alternative argument in the t.test function.\n\n95 percent confidence interval provides the 95% confidence interval for the parameter of \\(\\mu_1 - \\mu_2\\).\nsample estimates gives the sample means for each group.\n\nNote: By default the value of var.equal is FALSE. We manully set it to TRUE to implement equal variance assumption in our test.\n\n3.1.10 Storytelling\nFinally, based on the sample we have and the analysis we conducted, we can draw a conclusion about our initial question: Is the mean horsepower of cars with 8 cylinders statistically different from that of cars with 4 cylinders? We observed that the \\(p-\\textit{value}\\) of the test was extremely small compared to the significance level \\(\\alpha = 0.05\\). This provides evidence against the null hypothesis. In simple terms, this means: There appears to be a noticeable difference in the average horsepower between cars with 4 cylinders and those with 8 cylinders.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tests for Two Continuous Population Mean</span>"
    ]
  },
  {
    "objectID": "book/chapter3-two-pop.html#two-sample-welchs-t-test-for-independent-samples",
    "href": "book/chapter3-two-pop.html#two-sample-welchs-t-test-for-independent-samples",
    "title": "3  Tests for Two Continuous Population Mean",
    "section": "\n3.2 Two sample Welch’s t-test for independent samples",
    "text": "3.2 Two sample Welch’s t-test for independent samples\n\n3.2.1 Review\nIn this section we talk about two sample Welch’s t-test for independent samples. This test is very similar to two sample Student’s t-test for independent samples that we described with a caveat. The two samples are still independent but the only difference is the equal variance assumption. We use this test if we do not have any reason or evidence to believe that the variance of variable of interest is the same among two groups in the population.\n\n3.2.2 Study Design\nWe will be using Auto data set from ISLR package in this section too. Now the main statistical question of interest remains the same as before: You may wondering if the mean of horsepower in cars with 8 cylinders is statistically different than the means in cars with 4 cylinders? but we do not make an equal variance assumption anymore. Now we are applying a two sample Welch’s t-test for independent samples.\n\n3.2.3 Data Collection and Wrangling\nTo answer this question, we obtain the data set which is available in ISLR package. The following codes are exactly the same as before and are shown here as a review.\n\n# Get a copy of data set\nauto_data &lt;- Auto\n\n# Filter rows to cars with 4 or 8 cylinders\nauto_data &lt;- auto_data %&gt;% filter(cylinders %in% c(4,8) )\n\nFinally, we randomly create test and train set from this data set. We use a proportion of 50-50 between train and test.\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Splitting the data set into train and test sets\ntrain_indices &lt;- sample(seq_len(nrow(auto_data)), size = 0.50 * nrow(auto_data))\ntrain_auto &lt;- auto_data[train_indices, ]\ntest_auto &lt;- auto_data[-train_indices, ]\n\n\n3.2.4 Explanatory Data Analysis\nOnce we have the data and it is split into training and test sets, the next step is to begin exploratory data analysis (EDA) on train set. Recall that the cylinders variable is an integer variable that helps to divide observations into two groups.\nWe are still interested in the distribution of horsepower in two different groups (cars with 4 cylinders vs cars with 8 cylinders). Using a histogram for this variable is a good choice as we have a variable with numerical values.\nThe following lines of code are the same as previous section as we are working on the same data. This is shown as a reminder.\n\n\n\n\n\n\n\n\nWe also look at some descriptive statistics of horsepower in both groups for better understanding of data. The descriptive statistics in cars with 4 cylinders:\n\nsummary(train_auto %&gt;% filter(cylinders == 4) %&gt;% select(horsepower))\n\n   horsepower    \n Min.   : 46.00  \n 1st Qu.: 68.00  \n Median : 78.50  \n Mean   : 78.33  \n 3rd Qu.: 88.00  \n Max.   :113.00  \n\n\nand with 8 cylinders:\n\nsummary(train_auto %&gt;% filter(cylinders == 8) %&gt;% select(horsepower))\n\n   horsepower \n Min.   :105  \n 1st Qu.:140  \n Median :150  \n Mean   :160  \n 3rd Qu.:175  \n Max.   :225  \n\n\nOur conclusion remains the same. Looking at summary statistics, there is a bit of overlap between distribution of horsepower among two groups but it does not seem to be much. In fact they seem to be quite separated. Also there is a clear different in their mean and the following plot also confirms this:\n\n\n\n\n\n\n\n\n\n3.2.5 Testing Settings\nWe use a significant level of \\(\\alpha = 0.05\\) to run the test. Considering the data we have is a sample from a population of cars we have the following:\n\n\n\\(\\mu_{1}\\) is the mean of horsepower for cars with 4 cylinders in the population.\n\n\\(\\mu_{2}\\) is the mean of horsepower for cars with 8 cylinders in the population.\n\n3.2.6 Hypothesis Definitions\nWe now define the null and alternative hypothesis. Recall the main inquiry we had:\nYou may wondering if the average of horsepower in cars with 4 cylinders is statistically different than the means in cars with 8 cylinders?\nThis translates into the following null and alternative hypotheses:\n\\[H_0: \\mu_{1} = \\mu_{2} \\quad vs \\quad H_a: \\mu_{1} \\neq \\mu_{2}\\]\nNote that the alternative hypothesis is two-sided, as our question does not favor either group and only asks whether the means are different (i.e., group one could be less than or greater than group two). Also the hypothesis tests the unknown parameters in the population which are \\(\\mu_{1}\\) and \\(\\mu_{2}\\).\n\n3.2.7 Test Flavour and Components\nAs noted before we use Welch’s t-test if the assumption of equal variances is questionable. This test adjusts the standard error and degrees of freedom (df) of the test accordingly. As a result the test statistic and df of the test are different. The Welch’s test statistic is computed as:\n\\[t = \\frac{\\bar{X} - \\bar{Y}}{\\sqrt{\\frac{S_X^2}{n} + \\frac{S_Y^2}{m}}}\\]\nwhere:\n\n\n\\(\\bar{X}\\) is the mean of horsepower for cars with 4 cylinders in the sample\n\n\\(\\bar{Y}\\) is the mean of horsepower for cars with 8 cylinders in the sample\n\n\\(S_X^2\\) and \\(S_Y^2\\) are the sample variances of the two groups.\n\n\\(n\\) and \\(m\\) are the sample sizes in two groups (not necessarily the same).\n\n\n\nQuick review!\n\n\nNote that, as before, all elements in this formula (statistic) are computed based on the sample. Additionally, the assumption of unequal variance between two populations can be tested using a variety of statistical tests. We do not discuss these tests in this book as the focus of this book lies elsewhere.\n\n\n\n3.2.8 Inferential Conclusions\nAs you can see, the test statistic computes the difference between averages of two samples and adjusts it based on the variance of their differences. The only change from Student’s t-test is the variance that is being used in the denominator. Again the question is whether this difference is significant or not? In order to answer this question we need to know the behavior of statistic that we defined and have a better understanding of what are typical values of this statistic. Knowing the distribution of this statistic helps us to compute the \\(p-value\\) of the test as follows:\n\\[\\textit{p-value} = 2 \\times Pr(T_{\\nu} \\ge |t|)\\]\n\n\nTip on degrees of freedom!\n\n\nThe Greek sign \\(\\nu\\) is used here to show the degree of freedom of the t-distribution and is computed as\n\\[\\nu = \\frac{\\left( \\frac{s_1^2}{n} + \\frac{s_2^2}{m} \\right)^2}\n{\\frac{\\left( \\frac{s_1^2}{n} \\right)^2}{n - 1} + \\frac{\\left( \\frac{s_2^2}{m} \\right)^2}{m - 1}}\\]\nWe skipped the theory behind it but under the assumption that null hypothesis is correct, the test statistic defined above still follows a t-distribution but with a different degrees of freedom. Note that this degree of freedom is not necessarily an integer number (could be a real number).\n\n\n\n3.2.9 How to run the test in R and Python?\nThe following lines of code in tabset show you how to run the Welch’s test in R or Python.\n\n\nA quick reminder!\n\n\n\nIn Option 1, we first select the cars with 4 or 8 cylinders and save them in a vector (cylinders_4 and cylinders_8). We then use t.test function to run the test.\nIn Option 2, we use a formula to tell R what is the variable that records the outcome of interest (in this example horsepower variable) and what is the grouping variable (in this example cylinders). This approach is more concise and easier to read, especially when working directly with a data frame. Note that we need to let R know where it can find horsepower and cylinders which we do by setting data = test_auto.\n\n\n\n\n\nR Code - Option 1\nR Code - Option 2\nPython Code\n\n\n\n\n# Create a vector to hold horsepower values for cars with 4 cylinders\ncylinders_4 &lt;- test_auto %&gt;% filter(cylinders == 4) %&gt;% select(horsepower)\n\n# Create a vector to hold horsepower values for cars with 8 cylinders\ncylinders_8 &lt;- test_auto %&gt;% filter(cylinders == 8) %&gt;% select(horsepower)\n\n# Run the test\nt.test(x = cylinders_4, y = cylinders_8, var.equal = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  cylinders_4 and cylinders_8\nt = -16.92, df = 55.789, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -87.13950 -68.68866\nsample estimates:\nmean of x mean of y \n  78.2381  156.1522 \n\n\n\n\n\n# Use the formula horsepower ~ cylinders to run the test \nt.test(horsepower ~ cylinders, data = test_auto, var.equal = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  horsepower by cylinders\nt = -16.92, df = 55.789, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group 4 and group 8 is not equal to 0\n95 percent confidence interval:\n -87.13950 -68.68866\nsample estimates:\nmean in group 4 mean in group 8 \n        78.2381        156.1522 \n\n\n\n\n\nfrom scipy import stats\nimport pandas as pd\n\n# Read test_auto dataframe in Python as df dataframe\ndf = pd.read_csv('data/test_auto.csv')\n\n# Select cars with 4 and 8 cylinders\ncylinders_4 = df[df[\"cylinders\"] == 4][\"horsepower\"]\ncylinders_8 = df[df[\"cylinders\"] == 8][\"horsepower\"]\n\n# Run the test\nt_stat, p_val = stats.ttest_ind(cylinders_4, cylinders_8, equal_var = False)\n\n# Print t statistic value\nprint(f\"T-statistic: {t_stat}\")\n\nT-statistic: -16.919952924079897\n\n# Print p-value of the test\nprint(f\"P-value: {p_val}\")\n\nP-value: 1.2443553344442986e-23\n\n\n\n\n\nIn order to run this test, similar to what we learned in (LINK to chapter 1) we can use t.test function in R. The function can be used to perform one or two sample t-tests. The relevant arguments of the function are as follows:\n\n\nx is (non-empty) numeric vector of data values.\n\ny is also (non-empty) numeric vector of data values (can be NULL if you run a one sample test).\n\nvar.equal is a binary value (TRUE/FALSE) to indicate if R needs to assume equal variance or not.\n\nIn both outputs, we can see the following:\n\nt is the test statistic.\ndf is the degrees of freedom for the test.\n\np-value is the p-value of the test. Note that, by default, this is for a two-sided test. If you need to conduct a one-sided test, you can either divide the p-value by two or use the alternative argument in the t.test function.\n\n95 percent confidence interval provides the 95% confidence interval for the parameter of \\(\\mu_1 - \\mu_2\\).\nsample estimates gives the sample means for each group.\n\nNote: By default the value of var.equal is FALSE. We manully set it to FALSE to implement the test without equal variance assumption.\n\n3.2.10 Storytelling\nFinally, based on the sample we have and the analysis we conducted, we can draw a conclusion about our initial question: Is the mean horsepower of cars with 8 cylinders statistically different from that of cars with 4 cylinders? We observed that the \\(p-\\textit{value}\\) of the test was extremely small compared to the significance level \\(\\alpha = 0.05\\). This provides evidence against the null hypothesis. In simple terms, this means: There appears to be a noticeable difference in the average horsepower between cars with 4 cylinders and those with 8 cylinders.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tests for Two Continuous Population Mean</span>"
    ]
  },
  {
    "objectID": "book/chapter3-two-pop.html#two-sample-z-test-for-independent-samples",
    "href": "book/chapter3-two-pop.html#two-sample-z-test-for-independent-samples",
    "title": "3  Tests for Two Continuous Population Mean",
    "section": "\n3.3 Two sample z-test for Independent Samples",
    "text": "3.3 Two sample z-test for Independent Samples\n\n3.3.1 Review\nIn the tests we have seen so far, we estimated the variance of each group using the sample variance, i.e., \\(S^2\\). This approach is realistic, as in most cases we do not know the population variance of our variable of interest. However, if the population variance for each group is known, we can incorporate this information into our test.\nSuppose you are analyzing wage differences between high school and college graduates using a large labor market data set. A government labor agency previously conducted extensive research and reported that the true population variances of hourly wages for both groups should be as follows:\n\nPopulation variance of wages among high school graduates: \\(\\sigma_1^2 = 75\\)\n\nPopulation variance of wages among college graduates: \\(\\sigma_2^2 = 60\\)\n\n\nNote that this is the population variance and not the sample. You want to assess whether the average wage differs between the two groups. Since the population variances are known (e.g., from reliable historical studies or large scale sampling in previous studies), a two-sample z-test is appropriate for this case. We treat these groups as independent samples, since each person’s wage is recorded once and belongs to a distinct education level.\nSince we do not have access to the wages of all individuals in each education group, we take a random sample from each population. Suppose:\n\nFrom the population of high school graduates (Population 1), we obtain a sample of size \\(n\\), denoted as:\n\n\\[X_1, X_2, \\ldots, X_n\\]\n\nFrom the population of college graduates (Population 2), we obtain a sample of size \\(m\\), denoted as:\n\n\\[Y_1, Y_2, \\ldots, Y_m\\] Note that the sample sizes \\(n\\) and \\(m\\) do not need to be equal. Also, we assume that the population variances are known and denoted as:\n\n\n\\(\\sigma_1^2\\): the known population variance for high school graduates\n\n\n\\(\\sigma_2^2\\): the known population variance for college graduates\n\nNow, the central question becomes Is there a statistically significant difference between the mean wages of high school and college graduates? In formal terms, we test the hypotheses:\n\\[\nH_0: \\mu_1 = \\mu_2 \\quad \\text{versus} \\quad H_A: \\mu_1 \\ne \\mu_2\n\\] where \\(\\mu_1\\) is the population mean of wage in high school graduates and \\(\\mu_2\\) is the population mean of wage in college graduates.\n\n3.3.2 Study Design\nFor this example, we will be using the Wage data set from the ISLR2 package. This data set contains information about wages and demographic characteristics for 3,000 workers in the Mid-Atlantic region of the United States. Some of the variables of interest are:\n\neducation, a categorical variable that records the highest level of education completed by the individual (e.g., “HS Grad”, “College Grad”), and\nwage, a continuous variable representing the individual’s hourly wage in USD.\n\nYou may be wondering: Is the mean wage for college graduates statistically different from the mean wage for high school graduates?\nTo answer this question, we will compare the sample means of these two groups using a two-sample z-test under the assumption that the population variances are known. We use the Wage data set to extract wage data for two groups:\n\nHigh school graduates: education == \"HS Grad\"\nCollege graduates: education == \"College Grad\"\n\n3.3.3 Data Collection and Wrangling\nTo answer this question, we obtain the data set which is available in the ISLR2 package. Note that we consider this data a random sample from the population of working adults. First, we create a new copy of this data set to avoid modifying the original data (this step is optional). Then, we filter the rows to keep only individuals who are either high school graduates or college graduates.\n\n# Get a copy of data set\nwage_data &lt;- Wage\n\n# Filter rows to keep only HS Grad and College Grad\nwage_data &lt;- wage_data %&gt;% filter(education %in% c(\"2. HS Grad\", \"4. College Grad\"))\n\nFinally, we randomly split the data set into training and testing sets, using a 50-50 proportion between train and test. This allows us to conduct our test using a subset of the data while reserving the rest for potential follow-up analysis.\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Splitting the data set into train and test sets\ntrain_indices &lt;- sample(seq_len(nrow(wage_data)), size = 0.50 * nrow(wage_data))\ntrain_wage &lt;- wage_data[train_indices, ]\ntest_wage &lt;- wage_data[-train_indices, ]\n\n\n3.3.4 Exploratory Data Analysis\nOnce we have the data and it is split into training and test sets, the next step is to begin exploratory data analysis (EDA) on the training set. This step is crucial, as it helps us gain a better understanding of the distribution of variables in our data set. The wage variable is a numerical variable that represents hourly earnings. The education variable is a categorical variable that helps us divide observations into two groups.\nIn particular, we are interested in the distribution of wage in two different groups (high school graduates vs college graduates). Using a histogram for this variable is a good choice as it allows us to visually inspect how the wages vary within and between these two education levels.\n\n\n\n\n\n\n\n\nWe also look at some descriptive statistics of wage in both groups for better understanding of the data. The descriptive statistics for high school graduates:\n\nsummary(train_wage %&gt;% filter(education == \"2. HS Grad\") %&gt;% select(wage))\n\n      wage       \n Min.   : 23.27  \n 1st Qu.: 78.39  \n Median : 94.07  \n Mean   : 97.19  \n 3rd Qu.:111.72  \n Max.   :318.34  \n\n\nand for college graduates:\n\nsummary(train_wage %&gt;% filter(education == \"4. College Grad\") %&gt;% select(wage))\n\n      wage       \n Min.   : 40.41  \n 1st Qu.: 97.49  \n Median :118.88  \n Mean   :122.83  \n 3rd Qu.:141.78  \n Max.   :277.80  \n\n\nLooking at these summary statistics, we can see that the wage distributions for the two education groups have some overlap, and there does not appear to be a large difference in their centers. In fact, the mean wage for college graduates is only slightly higher, and this is not immediately obvious from the plots.\nThere appears to be some observations with higher wage values in College Grad group compared to others. The following density plot provides additional visual support for this observation:\n\n# Density plot of wage by education group\ntrain_wage %&gt;%\n  ggplot(aes(x = wage, fill = education)) +\n  geom_density(alpha = 0.5) +\n  labs(title = 'Wage Distribution by Education Level',\n       x = 'Wage (USD/hour)',\n       y = 'Density',\n       fill = \"Education\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n3.3.5 Testing Settings\nWe use a significance level of \\(\\alpha = 0.05\\) to conduct the hypothesis test. Since the data we have is a sample from a larger population of workers, we define the following population parameters:\n\n\n\\(\\mu_{1}\\) is the mean wage of individuals with a high school education in the population.\n\n\n\\(\\mu_{2}\\) is the mean wage of individuals with a college education in the population.\n\nOur goal is to test whether the population mean wage differs between these two educational groups.\n\n3.3.6 Hypothesis Definitions\nWe now define the null and alternative hypothesis. Recall the main inquiry we had:\nIs the mean wage for college graduates statistically different from the mean wage for high school graduates?\nThis translates into the following null and alternative hypotheses:\n\\[H_0: \\mu_{1} = \\mu_{2} \\quad vs \\quad H_a: \\mu_{1} \\neq \\mu_{2}\\]\n\n3.3.7 Test Flavour and Components\nTo test this hypothesis, we use the two-sample z-test for independent samples with known population variances, which compares the sample means and incorporates the known variability within each population. Note that the samples are independent. The test statistic for this test is computed as:\n\\[\nz = \\frac{\\bar{X} - \\bar{Y}}{\\sqrt{\\frac{\\sigma_1^2}{n} + \\frac{\\sigma_2^2}{m}}}\n\\]\nwhere:\n\n\n\\(\\bar{X}\\) is the mean wage of individuals with a high school education in the sample.\n\n\\(\\bar{Y}\\) is the mean wage of individuals with a college education in the sample.\n\n\\(\\sigma_1^2\\) and \\(\\sigma_2^2\\) are the known population variances of the two groups\n\n\\(n\\) and \\(m\\) are the sample sizes of the two groups\n\nBecause population variances are known, the standard error of the difference in sample means is computed directly from the population variances, avoiding the need to estimate variance from the samples.\n\n3.3.8 Inferential Conclusions\nAs you can see, the test statistic computes the difference between \\(\\bar{X}\\) and \\(\\bar{Y}\\) and scales it based on the known variance of this difference. Now the question is whether this difference is significant or not? To answer this, we need to understand the behavior of the statistic we defined (\\(z\\)) and what typical values it can take.\nAs we shown before, knowing the distribution of this statistic allows us to compute the \\(\\textit{p-value}\\) of the test as follows:\n\\[\n\\textit{p-value} = 2 \\times Pr(|Z| \\ge |z|)\n\\]\nLooking at the formula, we are essentially calculating how likely it is to observe a value as extreme as \\(z\\) under the null hypothesis.\n\n\nHeads-up!\n\n\nNote that \\(z\\) itself is a random variable that would vary from sample to sample.\n\n\n\n\nTip:\n\n\nUnder the assumption that the null hypothesis is correct (i.e., \\(\\mu_1 = \\mu_2\\)), the test statistic \\(z\\) follows the standard normal distribution that textbooks usually denote it by \\(N(0,1)\\). The first element is mean (0) and the second one is the standard deviation (1).\nNote: The probability is multiplied by two because we are conducting a two-sided test (alternative hypothesis: \\(\\mu_1 \\neq \\mu_2\\)). For a one-sided test (e.g., \\(\\mu_1 &gt; \\mu_2\\) or \\(\\mu_1 &lt; \\mu_2\\)) this multiplication is not needed.\nWe compare the \\(\\textit{p-value}\\) to our significance level \\(\\alpha\\). If the \\(\\textit{p-value}\\) is less than \\(\\alpha\\), then we have evidence against the null hypothesis. The reasoning is: assuming the null hypothesis is true, the test statistic should follow a standard normal distribution. A very small p-value means our observed \\(z\\) is unlikely under this distribution, and so it is unlikely the null hypothesis is correct.\n\n\n\n3.3.9 How to run the two-sample z-test in R and Python\n\nThe following examples show how to implement the two-sample z-test for independent samples with known population variances in both R and Python using the Wage data set.\n\n\nImportant reminder!\n\n\n\nNote that we know the population variances \\(\\sigma_1^2 = 75\\) for high school graduates and \\(\\sigma_2^2 = 60\\) for college graduates from previous studies.\nThe test statistic \\(z\\) is calculated by z.test function from BSDA package which have a similar input and output to t.test function.\n\n\n\n\n\nR Code\nPython Code\n\n\n\n\n# Filter test_wage data to create two groups: High school graduates and college graduates\nhs_wages &lt;- test_wage %&gt;% filter(education == \"2. HS Grad\") %&gt;% pull(wage)\ncol_wages &lt;- test_wage %&gt;% filter(education == \"4. College Grad\") %&gt;% pull(wage)\n\n# Set the known population variances\nsigma2_hs &lt;- 75\nsigma2_col &lt;- 60\n\n# Run two-sample z-test with known variances using z.test function from BSDA package\nresult &lt;- z.test(\n  x = hs_wages,\n  y = col_wages,\n  sigma.x = sqrt(sigma2_hs),  # standard deviation for group 1\n  sigma.y = sqrt(sigma2_col), # standard deviation for group 2\n  alternative = \"two.sided\"\n)\n\n# Print results\nprint(result)\n\n\n    Two-sample z-Test\n\ndata:  hs_wages and col_wages\nz = -55.239, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -32.72362 -30.48102\nsample estimates:\nmean of x mean of y \n 94.29543 125.89775 \n\n\n\n\n\nimport pandas as pd\nimport numpy as np\n\n# Read data set\ndf = pd.read_csv('data/test_wage.csv')\n\n\n\n\nIn order to run the two-sample z-test with known population variances, we use the z.test function from the BSDA package in R. This function is designed to handle one and two sample z-tests when population standard deviations are known. The key arguments of z.test for a two-sample test are:\n\n\nx: a numeric vector of data values for group 1.\n\ny: a numeric vector of data values for group 2.\n\nsigma_x: the known population standard deviation for group 1.\n\nsigma_y: the known population standard deviation for group 2.\n\nalternative: specifies the alternative hypothesis; \"two.sided\" by default for a two-sided test.\n\nNote: sigma_x and sigma_y expects the standard deviation of each group and not the variance. As a result in the R code in tabset we passed sqrt(sigma2_hs) and sqrt(sigma2_col).\nWhen you run the test, the output includes:\n\n\nstatistic: the calculated z test statistic.\n\np.value: the p-value for the test based on the standard normal distribution.\n\nconf.int: the confidence interval for the difference in means \\(\\mu_1 - \\mu_2\\).\n\nestimate: the sample means for each group.\n\nNote: The z.test function assumes that the population standard deviations are known and uses them directly to compute the test statistic and confidence interval. This differs from tests that estimate variance from the samples, such as t-tests that we have been studying so far.\n\n3.3.10 Storytelling",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tests for Two Continuous Population Mean</span>"
    ]
  },
  {
    "objectID": "book/chapter3-two-pop.html#two-sample-t-test-for-paired-samples",
    "href": "book/chapter3-two-pop.html#two-sample-t-test-for-paired-samples",
    "title": "3  Tests for Two Continuous Population Mean",
    "section": "\n3.4 Two sample t-test for Paired Samples",
    "text": "3.4 Two sample t-test for Paired Samples\n\n3.4.1 Review\nIn this section, we discuss the two sample t-test for paired samples which is used when we have two sets of related observations. Unlike the two-sample t-tests for independent samples that we discussed so far (such as the Student’s or Welch’s t-test), the paired t-test is appropriate when the two samples are dependent. This means each observation in one sample can be naturally paired with an observation in the other. Examples of such are before-and-after measurements on the same subjects, or matched subjects across two different conditions. The key idea is that the test evaluates whether the mean difference between paired observations is significantly different from zero.\n\n\nWhen to use this test!\n\n\nWe use the paired sample t-test when:\n\nThe data consist of paired observations.\nThe differences between pairs are approximately normally distributed or at least symmetric (especially important for small sample sizes).\nAnd the measurement scale is continuous.\n\n\n\nPaired samples arise when each observation in one group is matched or linked to an observation in the other group. This structure is typical in before-and-after studies, matched-subject designs, or repeated measures on the same individuals. A classic example comes from health sciences.\nSuppose you are investigating whether a new diet plan reduces blood pressure. You recruit a group of participants and record their blood pressure before starting the diet. After following the diet for two months, you measure their blood pressure again. In this scenario, each participant contributes two measurements: one before the intervention and one after. Note that these measurements are not independent as they come from the same person. Therefore we treat them as paired.\nTo formulate the problem and hypothesis, let us assume that each individual has two measurements:\n\nBefore the diet: \\(X_1, X_2, \\ldots, X_n\\)\nAfter the diet: \\(Y_1, Y_2, \\ldots, Y_n\\)\n\nNote that in this case the sample size is the same (in both before and after diet sample we have \\(n\\) observations). We call this a paired sample. Since the samples are paired, we define the difference for each individual as follows:\n\\[D_i = Y_i - X_i \\quad \\textit{for} \\quad i = 1,2, \\ldots, n\\] Each \\(D_i\\) is the difference of blood pressure after and before using new diet for the \\(i\\)-th person. Now the main statistical question is:\nIs there a statistically significant difference in the mean blood pressure before and after the diet?\nIn other words, we test the following hypothesis:\n\\[H_0: \\mu_D = 0 \\quad \\text{versus} \\quad H_A: \\mu_D \\ne 0\\]\n\n\nWhat is \\(\\mu_D\\) as a parameter here?\n\n\nHere the notation of \\(\\mu_D\\) is the population mean of the differences of \\(D_i\\) which is an unknown parameter in the population. To test this hypothesis, we use the paired t-test, which is essentially a one-sample t-test on the differences \\(D_1, D_2, \\ldots, D_n\\). We test \\(\\mu_D=0\\) because if there is an actual effect of diet on blood pressure, we expect the null hypothesis to be rejected.\n\n\nThe test statistic for this hypothesis testing is:\n\\[t = \\frac{\\bar{D}}{s_D / \\sqrt{n}}\\]\nwhere:\n\n\n\\(\\bar{D}\\) is the sample mean of the differences,\n\n\\(s_D\\) is the sample standard deviation of the differences,\n\n\\(n\\) is the number of pairs.\n\nThe standard deviation of the differences is calculated as:\n\\[s_D = \\sqrt{ \\frac{1}{n - 1} \\sum_{i=1}^n (D_i - \\bar{D})^2 }\\]\nUnder the null hypothesis, the test statistic follows a t-distribution with \\(n-1\\) degrees of freedom. For this test, we can compute the \\(\\textit{p-value}\\) as:\n\\[\\textit{p-value} = 2 \\times \\Pr(T_{n - 1} \\ge |t|)\\]\n\n\nRemember!\n\n\nWhen we run this test, we operate under the assumption that:\n\neither the sample size is large enough (we are thinking about \\(n=30\\) at least) so that central limit theorem assumptions work well, or\nthe distribution of our sample in each group is normal or symmetric enough.\n\nIf the normality assumption is also not satisfied (e.g., due to skewed distributions or outliers) or we have a very small sample size, we may turn to a non-parametric alternative, such as the Mann–Whitney–Wilcoxon test, which compares the ranks of the observations across groups rather than the raw values but this book will not cover it. You can read more about it LINK.\n\n\n\n3.4.2 Study Design\nWe will be using PrisonStress data set from PairedData package in this section",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tests for Two Continuous Population Mean</span>"
    ]
  },
  {
    "objectID": "book/chapter3-two-pop.html#tests-for-two-population-proportions",
    "href": "book/chapter3-two-pop.html#tests-for-two-population-proportions",
    "title": "3  Tests for Two Continuous Population Mean",
    "section": "\n3.5 Tests for Two Population Proportions",
    "text": "3.5 Tests for Two Population Proportions\n\n3.5.1 Review\n\n3.5.2 Study Design\n\n3.5.3 Data Collection and Wrangling\n\n3.5.4 Exploratory Data Analysis\n\n3.5.5 Testing Settings\n\n3.5.6 Hypothesis Definitions\n\n3.5.7 Test Flavour and Components\n\n3.5.8 Inferential Conclusions\n\n3.5.9 How to run the two-sample z-test in R and Python\n\n\n3.5.10 Storytelling",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tests for Two Continuous Population Mean</span>"
    ]
  }
]