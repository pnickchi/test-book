[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Mini Test Book (in development)",
    "section": "",
    "text": "Preface\nWe have experienced this sense of overwhelm throughout our academic journeys as well. However, we also understand that statistical inference is a powerful tool for gaining insights into complex populations across various fields of study. Whether analyzing electoral preferences in political science or assessing the effectiveness of innovative medical treatments in randomized clinical trials, the applications are extensive. Hence, in response to these challenges, we have created this mini-book as a handy resource to help structure and simplify the learning of different fundamental hypothesis tests. Our goal is to present these concepts in a reader-friendly manner while clearly explaining the necessary statistical jargon, making these inferential methods accessible to a broader audience.\nNote that, after conducting extensive research into the available educational literature, we discovered that there is no comprehensive resource that explains various inferential methods simultaneously using two essential programming languages in the field of data science: R and Python. Furthermore, we could not find reproducible and transparent tools that would enable learners to implement and adapt these methods in their own computational environments. Based on our teaching experience, these shortcomings hinder effective learning in the practice of statistical inference, especially given the numerous tests required to achieve mastery.\nTo address this gap, we have developed a bilingual resource in both R and Python, which features a common test workflow consisting of eight distinct stages applicable to each hypothesis test: study design, data collection and wrangling, exploratory data analysis, testing settings, hypothesis definitions, test flavour and components, inferential conclusions, and storytelling. Additionally, all the tests we discuss are organized through different mind maps to help readers visualize their learning process. Finally, by offering this mini-book as an Open Educational Resource (OER) in Quarto via a GitHub repository, we aim to inspire and empower academic communities worldwide to share and adapt this knowledge to suit their specific needs.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#g.-alexi-rodríguez-arelis",
    "href": "index.html#g.-alexi-rodríguez-arelis",
    "title": "The Mini Test Book (in development)",
    "section": "G. Alexi Rodríguez-Arelis",
    "text": "G. Alexi Rodríguez-Arelis\n\n\n\n\n\nI’m an Assistant Professor of Teaching in the Department of Statistics and Master of Data Science at the University of British Columbia (UBC). Throughout my academic and professional journey, I’ve been involved in diverse fields, such as credit risk management, statistical consulting, and data science teaching. My doctoral research in statistics is primarily focused on computer experiments that emulate scientific and engineering systems via Gaussian stochastic processes (i.e., kriging regression). I’m incredibly passionate about teaching regression topics while combining statistical and machine learning contexts.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#kate-manskaia",
    "href": "index.html#kate-manskaia",
    "title": "The Mini Test Book (in development)",
    "section": "Kate Manskaia",
    "text": "Kate Manskaia",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#payman-nickchi",
    "href": "index.html#payman-nickchi",
    "title": "The Mini Test Book (in development)",
    "section": "Payman Nickchi",
    "text": "Payman Nickchi\n\n\n\n\n\nI am a Postdoctoral Research and Teaching Fellow in the Department of Statistics and the Master of Data Science (MDS) program at the University of British Columbia (UBC). I completed my PhD in Statistics at Simon Fraser University (SFU), where my research focused on biostatistics and goodness-of-fit tests using empirical distribution functions. I am currently teaching statistical courses in the MDS program at UBC. My passion for statistics, teaching, and data science led me to this role. Outside of work, I enjoy swimming and capturing the night sky through astrophotography.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "book/privacy-policy.html",
    "href": "book/privacy-policy.html",
    "title": "Website Privacy Policy",
    "section": "",
    "text": "Information Collection and Use\nYour privacy is important to us. This policy outlines how this online textbook created for courses at the University of British Columbia (UBC) (“we,” “us,” or “our”) collects, uses, and protects your information.\nWe use Google Analytics, a web analytics service provided by Google, LLC. (“Google”). Google Analytics uses cookies to help analyze how students interact with the textbook, including tracking which sections are accessed most frequently. Information generated by cookies about your use of our website (including IP address) will be transmitted to and stored by Google on servers in the United States.\nGoogle will use this information solely for evaluating textbook usage, compiling usage reports to enhance the educational effectiveness of the textbook, and providing related services.\nYou may refuse the use of cookies by selecting the appropriate settings in your browser; however, please note this may affect your textbook browsing experience.",
    "crumbs": [
      "Website Privacy Policy"
    ]
  },
  {
    "objectID": "book/privacy-policy.html#personal-information",
    "href": "book/privacy-policy.html#personal-information",
    "title": "Website Privacy Policy",
    "section": "Personal Information",
    "text": "Personal Information\nWe do not collect personally identifiable information through Google Analytics. Any personally identifiable information, such as your name and email address, would only be collected if voluntarily submitted for specific educational purposes (e.g., feedback or course-related inquiries). We will never sell or distribute your personal information to third parties.\nFor any questions or concerns, please contact us at alexrod@stat.ubc.ca.",
    "crumbs": [
      "Website Privacy Policy"
    ]
  },
  {
    "objectID": "book/intro.html",
    "href": "book/intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 The Test Workflow\nThe statement above summarizes the essence of our testing workflow, which requires a detailed examination in this section. Primarily, it is crucial to understand that mastering all hypothesis tests involves more than just knowing their mathematical formulas or coding functions; it requires a disciplined and structured process. Whether we are evaluating evidence against a null hypothesis—the status quo of our population parameter(s) of interest—or reporting the uncertainty of an estimated effect, the workflow outlined by Figure 1.1 is intended to align your main inferential inquiries with the most suitable test flavour. Regardless of the flavour chosen, this workflow is designed to ensure that our conclusions are not only statistically valid but also based on clear and purposeful reasoning.\nThe workflow for hypothesis testing consists of eight stages, which will be discussed in detail in the following sections:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "book/intro.html#sec-test-workflow",
    "href": "book/intro.html#sec-test-workflow",
    "title": "1  Introduction",
    "section": "",
    "text": "There is a single test workflow for many different flavours!\n\n\n\n\n\nImage by Manfred Stege via Pixabay.\n\n\n\n\nStudy design: This initial stage, referred to as the main inferential inquiries, outlines the primary questions we aim to answer through our analysis.\nData collection and wrangling: The inquiries established in the first stage will guide the design of our data collection, utilizing a specific sampling scheme. Once the data is collected, it must be wrangled and split into two sets: training and test.\nExploratory data analysis: In this stage, we classify variables to provide preliminary insights using descriptive statistics and visualizations via the training set.\nTesting settings: We must revisit the significance level used in our power analysis (i.e., the procedure used to obtain the minimum sample size \\(n\\) of data points to be collected). Additionally, we need to list all modelling parameters that will be tested.\nHypothesis definitions: With the modelling parameters to test, we need to define our hypotheses: the null hypothesis versus the alternative hypothesis. These should be framed in relation to the main inferential inquiries.\nTest flavour and components: At this stage, we choose the most appropriate test flavour. Depending on whether the test is classical or simulation-based, we will then identify the necessary components to compute the critical values or \\(p\\)-values (via the test set) for the next stage.\nInferential conclusions: The goal of this stage is to determine whether we should reject the null hypothesis based on the critical values or \\(p\\)-values obtained.\nStorytelling: Finally, communicate the findings through a clear and engaging narrative that is accessible to your stakeholders.\n\n\n\n\n\n\n\nFigure 1.1: A hypothesis testing workflow structured in eight stages: study design, data collection and wrangling, exploratory data analysis, testing settings, hypothesis definitions, test flavour and components, inferential conclusions, and storytelling\n\n\n\n\n1.1.1 Study Design\n\n\n\n\nImage by Manfred Stege via Pixabay.\n\n\n\n\n1.1.2 Data Collection and Wrangling\n\n\n\nImage by Manfred Steger via Pixabay.\n\n\n\n\n1.1.3 Exploratory Data Analysis\n\n\n\nImage by Manfred Stege via Pixabay.\n\n\n\n\n1.1.4 Testing Settings\n\n\n\nImage by Manfred Steger via Pixabay.\n\n\n\n\n1.1.5 Hypothesis Definitions\n\n\n\nImage by Manfred Steger via Pixabay.\n\n\n\n\n1.1.6 Test Flavour and Components\n\n\n\nImage by Manfred Steger via Pixabay.\n\n\n\n\n1.1.7 Inferential Conclusions\n\n\n\nImage by Manfred Steger via [Pixabay](https://pixabay.com/vectors/pixel-cells-pixel-digital-3704070/.\n\n\n\n\n1.1.8 Storytelling\n\n\n\nImage by Manfred Stege via Pixabay.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "book/intro.html#sec-test-mind-map",
    "href": "book/intro.html#sec-test-mind-map",
    "title": "1  Introduction",
    "section": "1.2 The Test Mind Map",
    "text": "1.2 The Test Mind Map\n\n\n\n\n\n\n\n\nmindmap\n  root((Frequentist\n  Hypothesis \n  Testings\n  ))\n    Simulation Based&lt;br/&gt;Tests\n    Classical&lt;br/&gt;Tests\n      (Chapter 2: &lt;br/&gt;Tests for One&lt;br/&gt;Continuous&lt;br/&gt;Population Mean)\n        {{Unbounded&lt;br/&gt;Response}}\n        {{Proportion between&lt;br/&gt;0 and 1&lt;br/&gt;obtained from a &lt;br/&gt;Binary Response}}\n      (Chapter 3: &lt;br/&gt;Tests for Two&lt;br/&gt;Continuous&lt;br/&gt;Population Means)\n        Two&lt;br/&gt;Independent&lt;br/&gt;Populations\n          {{Unbounded&lt;br/&gt;Responses}}\n          {{Proportions between&lt;br/&gt;0 and 1&lt;br/&gt;obtained from two &lt;br/&gt;Binary Responses}}\n        Two&lt;br/&gt;Related&lt;br/&gt;Populations or&lt;br/&gt;Measurements\n          {{Unbounded&lt;br/&gt;Responses}}\n      (Chapter 4: ANOVA related &lt;br/&gt;Tests for&lt;br/&gt;k Continuous&lt;br/&gt;Population Means)\n        {{Unbounded&lt;br/&gt;Responses}}\n\n\n\n\n\n\n\n\nFigure 1.2: A general hypothesis testing mind map outlining all techniques explored in this book. Depending on the overall approach to be used, these techniques are divided into two broad categories: classical and simulation-based tests.\n\n\n\n\n\n\n\nTukey, John W. 1962. “The Future of Data Analysis.” The Annals of Mathematical Statistics 33 (1): 1–67. https://doi.org/10.1214/aoms/1177704711.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "book/chapter1.html",
    "href": "book/chapter1.html",
    "title": "Chapter 1: Tests for One Continuous Population Mean",
    "section": "",
    "text": "One-sample z-test for the mean\nThis chapter introduces statistical tests designed to analyze a single sample, which is a fundamental task in data analysis across many disciplines. Whether you’re evaluating whether the average recovery time from a treatment differs from a known standard, assessing whether student test scores exceed a benchmark, or testing if the proportion of success in a group differs from an expected rate, these methods help determine whether the observed values are statistically significant or simply due to chance.\nThere are several statistical tests used to evaluate hypotheses about a single sample. The appropriate test depends on the type of variable (mean or proportion), sample size, and whether population parameters like variance are known.\nWe test whether a population mean equals a specific value. The right test depends on:\nIn this chapter, we focus on statistical tests used to evaluate hypotheses about a single population mean or proportion, based on sample data. These tests help determine whether a sample provides sufficient evidence to conclude that the population mean (or proportion) differs from a specified value.\nWe cover two cases for the mean — depending on whether the population variance is known or unknown — and one test for binary outcomes where we’re testing a population proportion.\nKey tests include:\nUse this test when: - The population variance σ² is known, and - The sample comes from a normally distributed population, or the sample size is large (typically ( n )).\nThe test statistic is:\n\\[ z = \\frac{\\bar{x} - \\mu_0}{\\sigma / \\sqrt{n}} \\]\nWhere: - ( \\(\\bar{x}\\) ) is the sample mean\n- ( \\(\\mu_0\\) ) is the hypothesized population mean\n- ( \\(\\sigma\\) ) is the known population standard deviation\n- ( n ) is the sample size\nWe compare the calculated ( z )-value to a standard normal distribution to compute a p-value or make a decision based on a critical value.",
    "crumbs": [
      "Chapter 1: Tests for One Continuous Population Mean"
    ]
  },
  {
    "objectID": "book/chapter1.html#one-sample-t-test-for-the-mean",
    "href": "book/chapter1.html#one-sample-t-test-for-the-mean",
    "title": "Chapter 1: Tests for One Continuous Population Mean",
    "section": "One-sample t-test for the mean",
    "text": "One-sample t-test for the mean\nUse this test when: - The population variance is unknown, and - The sample is either normally distributed or large enough to rely on the central limit theorem.\nImagine you want to assess whether a new method of teaching introductory physics improves student performance compared to the traditional method previously used. To explore this, you test the new method at the University of British Columbia (UBC) and compare the results to historical data from students who were taught using the traditional approach. This historical data serves as your reference value.\nSuppose the population has an unknown average physics score, denoted as:\n\\[\n\\mu \\quad \\text{(mean physics score at UBC)}\n\\]\nSince we do not have access to the grades of all students, we take a random sample from the population. Let this sample consist of \\(n\\) students, with observed scores:\n\\[\nX_1, X_2, \\dots, X_n\n\\]\nThe central question becomes:\n\nIs the mean physics score in our sample statistically different from a given reference value?\n\nIf, for example, the historical average physics score is known to be 75, then our question becomes more specific:\n\nIs the mean physics score in the sample statistically different from 75?\n\nHypotheses\nWe can formally express this with the following hypotheses:\n\n\nNull hypothesis \\(H_0\\): \\(\\mu = 75\\)\n\n\nAlternative hypothesis \\(H_1\\): \\(\\mu \\ne 75\\)\n\n\nUnder the null hypothesis, we assume that the average score under the new method is equal to the historical average of 75. If the null is rejected, we conclude that there is a statistically significant difference, suggesting that the new method may lead to either higher or lower average performance.\nThe test statistic is:\n\\[t = \\frac{\\bar{x} - \\mu_0}{s / \\sqrt{n}}\\]\nWhere: - ( s ) is the sample standard deviation (used instead of ( \\(\\sigma\\) ))\nThis statistic follows a t-distribution with ( n - 1 ) degrees of freedom.\nStudy Design\nIn this example we use the Palmer Station Penguins dataset collected by the LTER in Antarctica (2007 – 2009).\nThe dataset spans three penguin species and includes continuous variables such as flipper length, bill size, and body mass.\n\nResearch question:Is the average flipper length of penguins significantly different from 200 mm?\n\nData Collection & Wrangling\nWe obtain the dataset Palmer Station Penguins dataset collected by the ‘LTER’\n\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load dataset\npenguins = sns.load_dataset(\"penguins\")\n\n# Drop rows with missing values\npenguins_clean = penguins.dropna()\n\n# 80/20 train–test split\ntrain_set, test_set = train_test_split(\n    penguins_clean, test_size=0.2, random_state=42\n)\n\nExploratory Data Analysis (EDA)\nBefore conducting the statistical test, we begin with an exploratory analysis to understand the distribution and characteristics of the flipper_length_mm variable.\nFirst, we examine summary statistics such as the mean, standard deviation, and quartiles. This helps us get a sense of the central tendency and spread of the data:\n\nprint(train_set[\"flipper_length_mm\"].describe())\n\ncount    266.00000\nmean     201.00000\nstd       13.91592\nmin      172.00000\n25%      190.00000\n50%      197.00000\n75%      213.00000\nmax      231.00000\nName: flipper_length_mm, dtype: float64\n\n\nNext, we visualize the distribution of flipper lengths using a histogram. This allows us to assess whether the data are approximately symmetric and whether any outliers are present:\n\nimport matplotlib.pyplot as plt\n\ntrain_set[\"flipper_length_mm\"].hist(edgecolor=\"black\", color=\"skyblue\")\nplt.title(\"Distribution of Flipper Length (mm)\")\nplt.xlabel(\"Flipper Length (mm)\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n\n\n\n\n\n\nTo explore the relationship between flipper length and another continuous variable, we create a scatter plot of flipper length versus body mass. This helps us visually assess whether larger penguins tend to have longer flippers, and whether this relationship is linear or varies across ranges:\n\nplt.scatter(\n    train_set[\"body_mass_g\"],\n    train_set[\"flipper_length_mm\"],\n    alpha=0.6\n)\nplt.title(\"Body Mass vs. Flipper Length\")\nplt.xlabel(\"Body Mass (g)\")\nplt.ylabel(\"Flipper Length (mm)\")\nplt.show()\n\n\n\n\n\n\n\nNow, we can perform one‑Sample t-Test\n\nimport scipy.stats as stats\n\nt_stat, p_value = stats.ttest_1samp(\n    train_set[\"flipper_length_mm\"], popmean=200\n)\nprint(f\"t = {t_stat:.3f},  p = {p_value:.4f}\")\n\nt = 1.172,  p = 0.2422\n\n\nA one-sample t-test was conducted to determine whether the average flipper length of penguins is significantly different from 200 mm. Based on a training sample, the test produced a t-statistic of t and a p-value of p.\nGiven a significance level of 0.05, if the p-value is less than 0.05, we reject the null hypothesis and conclude that the average flipper length is significantly different from 200 mm. If not, we do not have sufficient evidence to say it differs.",
    "crumbs": [
      "Chapter 1: Tests for One Continuous Population Mean"
    ]
  },
  {
    "objectID": "book/chapter1.html#one-sample-z-test-for-proportions",
    "href": "book/chapter1.html#one-sample-z-test-for-proportions",
    "title": "Chapter 1: Tests for One Continuous Population Mean",
    "section": "One-sample z-test for proportions",
    "text": "One-sample z-test for proportions\nUse this test when: - The variable is binary (success/failure, yes/no, etc.), and - You want to test a population proportion ( p ), using a large enough sample.\nThe test statistic is:\n\\[z = \\frac{\\hat{p} - p_0}{\\sqrt{p_0(1 - p_0)/n}}\\]\nWhere: - ( \\(\\hat{p}\\) ) is the sample proportion\n- ( \\(p_0\\) ) is the hypothesized population proportion\n- ( \\(n\\) ) is the sample size\nThis test assumes ( \\(np_0 \\geq 5\\) ) and ( \\(n(1 - p_0)\\) \\(\\geq\\) 5 ) to justify the normal approximation to the binomial distribution.",
    "crumbs": [
      "Chapter 1: Tests for One Continuous Population Mean"
    ]
  },
  {
    "objectID": "book/chapter2.html",
    "href": "book/chapter2.html",
    "title": "Chapter 2: Tests for Two Continuous Population Mean",
    "section": "",
    "text": "Two sample Student’s t-test for Independent Samples\nThis chapter introduces statistical tests designed to compare two samples which is a fundamental task in data analysis across many disciplines. Whether you’re comparing average recovery times between two medical treatments, student test scores under different teaching methods, comparing the proportion among two samples, or reaction times under varying stress conditions, these methods help determine whether observed differences are statistically significant or simply due to chance.\nIn this chapter, we review tests for comparing two continuous population means under two conditions: when the populations are independent and when they are dependent. Throughout the sections below, we provide details about these tests and required formula for each case. Broadly speaking, there are two main types of tests to compare the means between two continuous populations:\nThe choice of test depends on the structure of your data. This chapter introduces both types of comparisons, beginning with independent samples. Each section includes definitions, theoretical background, and R/Python code examples using real or simulated datasets to help ground the concepts in practice. We also review the theoretical background and exmaple codes to test two proportions.",
    "crumbs": [
      "Chapter 2: Tests for Two Continuous Population Mean"
    ]
  },
  {
    "objectID": "book/chapter2.html#two-sample-students-t-test-for-independent-samples",
    "href": "book/chapter2.html#two-sample-students-t-test-for-independent-samples",
    "title": "Chapter 2: Tests for Two Continuous Population Mean",
    "section": "",
    "text": "Review\nIn this section we talk about two sample student’s t-test for independent samples. Independent samples arise when the observations in one group do not influence or relate to the observations in the other. In statistical terms we call this two independent samples. A classic example from educational research is described below:\nSuppose you’re interested in whether a new method of teaching introductory physics improves student performance and learning experience. To investigate this, you decide to test the method at two universities: the University of British Columbia (UBC) and Simon Fraser University (SFU). You apply the new teaching method at SFU and compare the results to students taught with the traditional method at UBC.\nIn this scenario, students at UBC and SFU form two distinct, unrelated groups. Since the students are not paired or matched across schools, and each individual belongs to only one group, the samples are independent. Note that the samples are drawn from two independent population: students at UBC and SFU, respectively.\nLet us assume that each population has an unknown average or mean physics score denoted by:\n\\[\n    \\mu_1 \\quad \\text{(mean for UBC)}, \\quad \\mu_2 \\quad \\text{(mean for SFU)}.\n\\]\nSince we do not have access to all students’ grades, we take a random sample from each school. Suppose:\n\nFrom UBC (Population 1), we obtain a sample of size \\(n\\), denoted as: \\[X_1, X_2, \\ldots, X_n\\]\nFrom SFU (Population 2), we obtain a sample of size \\(m\\), denoted as: \\[Y_1, Y_2, \\ldots, Y_m\\]\n\nNote that the sample sizes \\(n\\) and \\(m\\) do not necessarily have to be equal. Now, the central question becomes:\nIs there a statistically significant difference between the mean physics scores among two groups?\nIn formal terms, we test the hypotheses:\n\\[H_0: \\mu_1 = \\mu_2 \\quad \\text{versus} \\quad H_A: \\mu_1 \\ne \\mu_2\\] Now that we reviewed the test concept, let’s try to understand it in a read dataset. The steps below follows closely with the roadmap that we introduced in [LINK HERE].\nStudy design\nFor this example, we will be using Auto dataset from ISLR package. This dataset contains gas mileage, horsepower, and other information for 392 vehicles. Some of variables of interest are: 1) cylinders an integer (numerical) value between 4 and 8 which indicates the number of cylinders of car, and 2) horsepower which shows engine horsepower. You may wondering if the mean of horsepower in cars with 8 cylinders is statistically different than the means in cars with 4 cylinders?\nData Collection and Wrangling\nTo answer this question, we obtain the dataset which is available in ISLR package. Note that we consider this data a random sample from population of cars. First we creat a new copy of this dataset to avoid touching the actual data (this is optional). Also we filter rows to those cars with 4 or 8 cylinders only.\n\n# Get a copy of dataset\nauto_data &lt;- Auto\n\n# Filter rows to cars with 4 or 8 cylinders\nauto_data &lt;- auto_data %&gt;% filter(cylinders %in% c(4,8) )\n\nFinally, we randomly create test and train set from this dataset. We use a proportion of 50-50 between train and test.\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Splitting the dataset into train and test sets\ntrain_indices &lt;- sample(seq_len(nrow(auto_data)), size = 0.50 * nrow(auto_data))\ntrain_auto &lt;- auto_data[train_indices, ]\ntest_auto &lt;- auto_data[-train_indices, ]\n\nExplanatory Data Analysis\nOnce we have the data and it is split into training and test sets, the next step is to begin exploratory data analysis (EDA) on train set. This step is crucial, as it helps us gain a better understanding of the distribution of variables in our dataset. The horsepower variable in dataset is a numerical variable. The cylinders variable is an integer variable that helps to divide observations into two groups.\nIn particular, we are interested in the distribution of horsepower in two different groups (cars with 4 cylinders vs cars with 8 cylinders). Using a histogram for this variable is a good choice as we have a variable with numerical values.\n\nggplot(train_auto, aes(x = horsepower)) +\n  geom_histogram(fill = \"steelblue\", color = \"white\", bins = 20) +\n  facet_wrap(~ cylinders, nrow = 1) +\n  labs(title = \"Side-by-side histogram of horsepower by number of cylinders\",\n       x = \"Horsepower\",\n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\nWe also look at some descriptive statistics of horsepower in both groups for better understanding of data. The descriptive statistics in cars with 4 cylinders:\n\nsummary(train_auto %&gt;% filter(cylinders == 4) %&gt;% select(horsepower))\n\n   horsepower    \n Min.   : 46.00  \n 1st Qu.: 68.00  \n Median : 78.50  \n Mean   : 78.33  \n 3rd Qu.: 88.00  \n Max.   :113.00  \n\n\nand with 8 cylinders:\n\nsummary(train_auto %&gt;% filter(cylinders == 8) %&gt;% select(horsepower))\n\n   horsepower \n Min.   :105  \n 1st Qu.:140  \n Median :150  \n Mean   :160  \n 3rd Qu.:175  \n Max.   :225  \n\n\nLooking at summary statistics, there is a bit of overlap between distribution of horsepower among two groups but it does not seem to be much. In fact they seem to be quite separated. Also there is a clear different in their mean and the following plot also confirms this:\n\nggplot(train_auto, aes(x = horsepower, color = factor(cylinders), fill = factor(cylinders))) +\n  geom_density(alpha = 0.4) +\n  labs(title = \"Density plot of horsepower by number of cylinders\",\n       x = \"Horsepower\",\n       y = \"Density\",\n       color = \"Cylinders\",\n       fill = \"Cylinders\") +\n  theme_minimal()\n\n\n\n\n\n\n\nTesting Settings\nWe use a significant level of \\(\\alpha = 0.05\\) to run the test. Considering the data we have is a sample from a population of cars we have the following:\n\n\n\\(\\mu_{1}\\) is the mean of horsepower for cars with 4 cylinders in the population.\n\n\\(\\mu_{2}\\) is the mean of horsepower for cars with 8 cylinders in the population.\nHypothesis Definitions\nWe now define the null and alternative hypothesis. Recall the main inquiry we had:\nYou may wondering if the average of horsepower in cars with 4 cylinders is statistically different than the means in cars with 8 cylinders?\nThis translates into the following null and alternative hypotheses:\n\\[H_0: \\mu_{1} = \\mu_{2} \\quad vs \\quad H_a: \\mu_{1} \\neq \\mu_{2}\\]\nNote that the alternative hypothesis is two-sided, as our question does not favor either group and only asks whether the means are different (i.e., group one could be less than or greater than group two). Also the hypothesis tests the unknown parameters in the population which are \\(\\mu_{1}\\) and \\(\\mu_{2}\\).\nTest Flavour and Components\nTo test this hypothesis, we use the two-sample student’s t-test for independent samples, which compares the sample means and incorporates variability within and between the samples. Note that in this case the samples are independent as clearly cars with 4 cylinders are independent from cars with 8 cylinders.\nThe assumption in this test is that variances among two groups are equal meaning that if we look at the random variable of horsepower in both populations, the variance of this random variable is roughly equal in two groups (cars with 4 cylinders and cars with 8 cylinders). Note that we do not have access to population and this is rather an assumption that we make with consultation with experts or justifying it based on previous studies. We will introduce the test without equal variance assumption in the next section.\nNow we need to compute a test statistic from the sample. Assuming equal population variances, the test statistic is:\n\\[t = \\frac{(\\bar{X} - \\bar{Y})}{S_p \\sqrt{\\frac{1}{n} + \\frac{1}{m}}}\\]\nwhere:\n\n\n\\(\\bar{X}\\) is the mean of horsepower for cars with 4 cylinders in the sample\n\n\\(\\bar{Y}\\) is the mean of horsepower for cars with 8 cylinders in the sample\n\n\\(S_p\\) is the , computed as:\n\\(S_p = \\sqrt{\\frac{(n - 1)S_X^2 + (m - 1)S_Y^2}{n + m - 2}}\\)\n\n\\(S_X^2\\) and \\(S_Y^2\\) are the sample variances of the two groups.\n\nNote that all elements in this formula (statistic) are computed based on sample.\nInferential Conclusions\nAs you can see, the test statistic computes the difference between \\(\\bar{X}\\) and \\(\\bar{Y}\\) and scale it based on the variance of this difference. Now the question is whether this difference is significant or not? In order to answer this question we need to know the behavior of statistic that we defined (\\(t\\)) and have a better understanding of what are typical values of this statistic. Note that \\(t\\) itself is a random variable as it would change from sample to sample.\nWe skipped the theory behind it but under the assumption that null hypothesis is correct (i.e. \\(\\mu_1=\\mu_2\\)) then the test statistic defined above (\\(t\\)) follows a t-distribution with \\(n + m -2\\) degrees of freedom (which we denote it by \\(T_{n+m-2}\\)). Knowing the distribution of this statistic helps us to compute \\(\\textit{p-value}\\) of the test as follows:\n\\[\\textit{p-value} = 2 \\times Pr(T_{n+m-2} \\ge |t|)\\]\nLooking at the formula, we can see that we are essentially calculating how much is it likely to see an observation as big as \\(t\\) or as extreme as \\(t\\) (which we computed from our sample). We come back to this point in the next paragraph.\nNote: The probability is multiplied by two since we have a two sided hypothesis (alternative is \\(\\mu_1 \\neq \\mu_2\\)). For a one sided test (when alternative hypothesis is \\(\\mu_1 &gt; \\mu_2\\) or \\(\\mu_1 &lt; \\mu_2\\)) we do not need to multiply by two.\nNow we compare the \\(\\textit{p-value}\\) to our significance level. If the \\(\\textit{p-value}\\) is less than the significance level, then we have evidence against the null hypothesis. The reasoning is as follows: we performed the calculation under the assumption that the null hypothesis is true. If the null hypothesis is true, then the test statistic we computed should follow a \\(t\\)-distribution with \\(n + m - 2\\) degrees of freedom. If the p-value is smaller than our chosen significance level, this means it is unlikely that our observed result comes from a \\(t\\)-distribution with \\(n + m - 2\\) degrees of freedom. In other words, it is unlikely that the null hypothesis is correct.\nNote that our observation from the sample might still lead us to an incorrect conclusion (since there is variability among samples). Our tolerance for this type of error is determined by the significance level. If \\(\\textit{p-value}\\) is not less than significant level then we do not have any evidence to reject the null hypothesis. Now let us see how to run the two-sample test in R and Python. Note that for the purpose of hypothesis testing we now use test data to avoid double dipping.\nHow to run the test in R and Python?\nThe following lines of code in tabset show you how to run the test in R or Python. Note that there are two ways of running this test in R as shown below. They both give the same result and you are welcome to use either of them.\n\n\nR Code - Option 1\nR Code - Option 2\nPython Code\n\n\n\n\n# Create a vector to hold horsepower values for cars with 4 cylinders\ncylinders_4 &lt;- test_auto %&gt;% filter(cylinders == 4) %&gt;% select(horsepower)\n\n# Create a vector to hold horsepower values for cars with 8 cylinders\ncylinders_8 &lt;- test_auto %&gt;% filter(cylinders == 8) %&gt;% select(horsepower)\n\n# Run the test\nt.test(x = cylinders_8, y = cylinders_4, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  cylinders_8 and cylinders_4\nt = 21.344, df = 149, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 70.70086 85.12730\nsample estimates:\nmean of x mean of y \n 156.1522   78.2381 \n\n\n\n\n\n# Use the formula horsepower ~ cylinders to run the test \nt.test(horsepower ~ cylinders, data = test_auto, var.equal=TRUE)\n\n\n    Two Sample t-test\n\ndata:  horsepower by cylinders\nt = -21.344, df = 149, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group 4 and group 8 is not equal to 0\n95 percent confidence interval:\n -85.12730 -70.70086\nsample estimates:\nmean in group 4 mean in group 8 \n        78.2381        156.1522 \n\n\n\n\n\nimport os as os\n\n\n\n\nIn order to run this test, similar to what we learned in (LINK to chapter 1) we can use t.test function in R. The function can be used to perform one or two sample t-tests. The relevant arguments of the function are as follows:\n\n\nx is (non-empty) numeric vector of data values.\n\ny is also (non-empty) numeric vector of data values (can be NULL if you run a one sample test).\n\nvar.equal is a binary value (TRUE/FALSE) to indicate if R needs to assume equal variance or not.\n\nIn both outputs, we can see the following:\n\nt is the test statistic.\ndf is the degrees of freedom for the test.\n\np-value is the p-value of the test. Note that, by default, this is for a two-sided test. If you need to conduct a one-sided test, you can either divide the p-value by two or use the alternative argument in the t.test function.\n\n95 percent confidence interval provides the 95% confidence interval for the parameter of \\(\\mu_1 - \\mu_2\\).\nsample estimates gives the sample means for each group.\n\nNote: By default the value of var.equal is FALSE. We manully set it to TRUE to implement equal variance assumption in our test.\nStorytelling\n\nTBD",
    "crumbs": [
      "Chapter 2: Tests for Two Continuous Population Mean"
    ]
  },
  {
    "objectID": "book/chapter2.html#two-sample-welchs-t-test-for-independent-samples",
    "href": "book/chapter2.html#two-sample-welchs-t-test-for-independent-samples",
    "title": "Chapter 2: Tests for Two Continuous Population Mean",
    "section": "Two sample Welch’s t-test for independent samples",
    "text": "Two sample Welch’s t-test for independent samples\nReview\nIn this section we talk about two sample Welch’s t-test for independent samples. This test is very similar to two sample Student’s t-test for independent samples that we described with a caveat. The two samples are still independent but the only difference is the equal variance assumption. We use this test if we do not have any reason or evidence to believe that the variance of variable of interest is the same among two groups in the population.\nStudy Design\nWe will be using Auto dataset from ISLR package in this section too. Now the main statistical question of interest remains the same as before: You may wondering if the mean of horsepower in cars with 8 cylinders is statistically different than the means in cars with 4 cylinders? but we do not make an equal variance assumption anymore. Now we are applying a two sample Welch’s t-test for independent samples.\nData Collection and Wrangling\nTo answer this question, we obtain the dataset which is available in ISLR package. The following codes are exactly the same as before and are shown here as a review.\n\n# Get a copy of dataset\nauto_data &lt;- Auto\n\n# Filter rows to cars with 4 or 8 cylinders\nauto_data &lt;- auto_data %&gt;% filter(cylinders %in% c(4,8) )\n\nFinally, we randomly create test and train set from this dataset. We use a proportion of 50-50 between train and test.\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Splitting the dataset into train and test sets\ntrain_indices &lt;- sample(seq_len(nrow(auto_data)), size = 0.50 * nrow(auto_data))\ntrain_auto &lt;- auto_data[train_indices, ]\ntest_auto &lt;- auto_data[-train_indices, ]\n\nExplanatory Data Analysis\nOnce we have the data and it is split into training and test sets, the next step is to begin exploratory data analysis (EDA) on train set. Recall that the cylinders variable is an integer variable that helps to divide observations into two groups.\nWe are still interested in the distribution of horsepower in two different groups (cars with 4 cylinders vs cars with 8 cylinders). Using a histogram for this variable is a good choice as we have a variable with numerical values.\nThe following lines of code are the same as previous section as we are working on the same data. This is shown as a reminder.\n\nggplot(train_auto, aes(x = horsepower)) +\n  geom_histogram(fill = \"steelblue\", color = \"white\", bins = 20) +\n  facet_wrap(~ cylinders, nrow = 1) +\n  labs(title = \"Side-by-side histogram of horsepower by number of cylinders\",\n       x = \"Horsepower\",\n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\nWe also look at some descriptive statistics of horsepower in both groups for better understanding of data. The descriptive statistics in cars with 4 cylinders:\n\nsummary(train_auto %&gt;% filter(cylinders == 4) %&gt;% select(horsepower))\n\n   horsepower    \n Min.   : 46.00  \n 1st Qu.: 68.00  \n Median : 78.50  \n Mean   : 78.33  \n 3rd Qu.: 88.00  \n Max.   :113.00  \n\n\nand with 8 cylinders:\n\nsummary(train_auto %&gt;% filter(cylinders == 8) %&gt;% select(horsepower))\n\n   horsepower \n Min.   :105  \n 1st Qu.:140  \n Median :150  \n Mean   :160  \n 3rd Qu.:175  \n Max.   :225  \n\n\nOur conclusion remains the same. Looking at summary statistics, there is a bit of overlap between distribution of horsepower among two groups but it does not seem to be much. In fact they seem to be quite separated. Also there is a clear different in their mean and the following plot also confirms this:\n\nggplot(train_auto, aes(x = horsepower, color = factor(cylinders), fill = factor(cylinders))) +\n  geom_density(alpha = 0.4) +\n  labs(title = \"Density plot of horsepower by number of cylinders\",\n       x = \"Horsepower\",\n       y = \"Density\",\n       color = \"Cylinders\",\n       fill = \"Cylinders\") +\n  theme_minimal()\n\n\n\n\n\n\n\nTesting Settings\nWe use a significant level of \\(\\alpha = 0.05\\) to run the test. Considering the data we have is a sample from a population of cars we have the following:\n\n\n\\(\\mu_{1}\\) is the mean of horsepower for cars with 4 cylinders in the population.\n\n\\(\\mu_{2}\\) is the mean of horsepower for cars with 8 cylinders in the population.\nHypothesis Definitions\nWe now define the null and alternative hypothesis. Recall the main inquiry we had:\nYou may wondering if the average of horsepower in cars with 4 cylinders is statistically different than the means in cars with 8 cylinders?\nThis translates into the following null and alternative hypotheses:\n\\[H_0: \\mu_{1} = \\mu_{2} \\quad vs \\quad H_a: \\mu_{1} \\neq \\mu_{2}\\]\nNote that the alternative hypothesis is two-sided, as our question does not favor either group and only asks whether the means are different (i.e., group one could be less than or greater than group two). Also the hypothesis tests the unknown parameters in the population which are \\(\\mu_{1}\\) and \\(\\mu_{2}\\).\nTest Flavour and Components\nAs noted before we use Welch’s t-test if the assumption of equal variances is questionable. This test adjusts the standard error and degrees of freedom (df) of the test accordingly. As a result the test statistic and df of the test are different. The Welch’s test statistic is computed as:\n\\[t = \\frac{\\bar{X} - \\bar{Y}}{\\sqrt{\\frac{S_X^2}{n} + \\frac{S_Y^2}{m}}}\\]\nwhere:\n\n\n\\(\\bar{X}\\) is the mean of horsepower for cars with 4 cylinders in the sample\n\n\\(\\bar{Y}\\) is the mean of horsepower for cars with 8 cylinders in the sample\n\n\\(S_X^2\\) and \\(S_Y^2\\) are the sample variances of the two groups.\n\n\\(n\\) and \\(m\\) are the sample sizes in two groups (not necessarily the same).\n\nNote that similar to before all elements in this formula (statistic) are computed based on sample.\nInferential Conclusions\nWe skipped the theory behind it but under the assumption that null hypothesis is correct, the test statistic defined above still follows a t-distribution but with a different degrees of freedom. The degree of freedom when we do not make equal variance assumption is:\n\\[\\nu = \\frac{\\left( \\frac{s_1^2}{n} + \\frac{s_2^2}{m} \\right)^2}\n{\\frac{\\left( \\frac{s_1^2}{n} \\right)^2}{n - 1} + \\frac{\\left( \\frac{s_2^2}{m} \\right)^2}{m - 1}}\\]\nNote that this degree of freedom is not necessarily an integer number (could be a real number).\nHow to run the test in R and Python?\nThe following lines of code in tabset show you how to run the Welch’s test in R or Python. Note that there are two ways of running this test in R as shown below. They both give the same result and you are welcome to use either of them.\n\n\nR Code - Option 1\nR Code - Option 2\nPython Code\n\n\n\n\n# Create a vector to hold horsepower values for cars with 4 cylinders\ncylinders_4 &lt;- test_auto %&gt;% filter(cylinders == 4) %&gt;% select(horsepower)\n\n# Create a vector to hold horsepower values for cars with 8 cylinders\ncylinders_8 &lt;- test_auto %&gt;% filter(cylinders == 8) %&gt;% select(horsepower)\n\n# Run the test\nt.test(x = cylinders_8, y = cylinders_4, var.equal = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  cylinders_8 and cylinders_4\nt = 16.92, df = 55.789, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 68.68866 87.13950\nsample estimates:\nmean of x mean of y \n 156.1522   78.2381 \n\n\n\n\n\n# Use the formula horsepower ~ cylinders to run the test \nt.test(horsepower ~ cylinders, data = test_auto, var.equal = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  horsepower by cylinders\nt = -16.92, df = 55.789, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group 4 and group 8 is not equal to 0\n95 percent confidence interval:\n -87.13950 -68.68866\nsample estimates:\nmean in group 4 mean in group 8 \n        78.2381        156.1522 \n\n\n\n\n\nimport os as os\n\n\n\n\nIn order to run this test, similar to what we learned in (LINK to chapter 1) we can use t.test function in R. The function can be used to perform one or two sample t-tests. The relevant arguments of the function are as follows:\n\n\nx is (non-empty) numeric vector of data values.\n\ny is also (non-empty) numeric vector of data values (can be NULL if you run a one sample test).\n\nvar.equal is a binary value (TRUE/FALSE) to indicate if R needs to assume equal variance or not.\n\nIn both outputs, we can see the following:\n\nt is the test statistic.\ndf is the degrees of freedom for the test.\n\np-value is the p-value of the test. Note that, by default, this is for a two-sided test. If you need to conduct a one-sided test, you can either divide the p-value by two or use the alternative argument in the t.test function.\n\n95 percent confidence interval provides the 95% confidence interval for the parameter of \\(\\mu_1 - \\mu_2\\).\nsample estimates gives the sample means for each group.\n\nNote: By default the value of var.equal is FALSE. We manully set it to FALSE to implement the test without equal variance assumption.\nStorytelling\n\nTBD\nAll from here is under development",
    "crumbs": [
      "Chapter 2: Tests for Two Continuous Population Mean"
    ]
  },
  {
    "objectID": "book/chapter2.html#paired-samples",
    "href": "book/chapter2.html#paired-samples",
    "title": "Chapter 2: Tests for Two Continuous Population Mean",
    "section": "Paired Samples",
    "text": "Paired Samples\nPaired samples arise when each observation in one group is matched or linked to an observation in the other group. This structure is typical in before-and-after studies, matched-subject designs, or repeated measures on the same individuals. A classic example comes from health sciences.\nSuppose you’re investigating whether a new diet plan reduces blood pressure. You recruit a group of participants and record their blood pressure before starting the diet. After following the diet for two months, you measure their blood pressure again. In this scenario, each participant contributes two measurements: one before the intervention and one after. These measurements are not independent as they come from the same person. Therefore we treat them as paired.\nTo formulate the problem and hypothesis, let us assume that each individual has two measurements:\n\nBefore the diet: \\(X_1, X_2, \\ldots, X_n\\)\nAfter the diet: \\(Y_1, Y_2, \\ldots, Y_n\\)\n\nNote that in this case the sample size is the same (in both before and after diet sample we have \\(n\\) observations). We call this a paired sample. Since the samples are paired, we define the difference for each individual as follows:\n\\[D_i = Y_i - X_i \\quad \\textit{for} \\quad i = 1,2, \\ldots, n\\] Each \\(D_i\\) is the difference of blood pressure after and before using new diet. The main statistical question now is:\nIs there a statistically significant difference in the mean blood pressure before and after the diet?\nIn other words, we test the following hypothesis:\n\\[H_0: \\mu_D = 0 \\quad \\text{versus} \\quad H_A: \\mu_D \\ne 0\\] Here the notation of \\(\\mu_D\\) is the population mean of the differences of \\(D_i\\) which is an unknown parameter in the population. To test this hypothesis, we use the paired t-test, which is essentially a one-sample t-test on the differences \\(D_1, D_2, \\ldots, D_n\\). We test \\(\\mu_D=0\\) because if there is an actual effect of diet on blood pressure, we expect the null hypothesis to be rejected.\nThe test statistic for this hypothesis testing is:\n\\[t = \\frac{\\bar{D}}{s_D / \\sqrt{n}}\\]\nwhere:\n\n\n\\(\\bar{D}\\) is the sample mean of the differences,\n\n\\(s_D\\) is the sample standard deviation of the differences,\n\n\\(n\\) is the number of pairs.\n\nThe standard deviation of the differences is calculated as:\n\\[s_D = \\sqrt{ \\frac{1}{n - 1} \\sum_{i=1}^n (D_i - \\bar{D})^2 }\\]\nUnder the null hypothesis, the test statistic follows a t-distribution with \\(n-1\\) degrees of freedom. For this test, we can compute the \\(\\textit{p-value}\\) as:\n\\[\\textit{p-value} = 2 \\times \\Pr(T_{n - 1} \\ge |t|)\\]\nWhen we run t-test, we operate under the assumption that: 1) either the sample size is large enough (we are thinking about \\(n=30\\) at least) so that central limit theorem assumptions work well, or 2) the distribution of our sample in each group is normal or symmetric enough.\nIf the normality assumption is also not satisfied (e.g., due to skewed distributions or outliers) or we have a very small sample size, we may turn to a non-parametric alternative, such as the Mann–Whitney–Wilcoxon test, which compares the ranks of the observations across groups rather than the raw values but this book will not cover it. You can read more about it LINK.",
    "crumbs": [
      "Chapter 2: Tests for Two Continuous Population Mean"
    ]
  },
  {
    "objectID": "book/chapter3.html",
    "href": "book/chapter3.html",
    "title": "Chapter 3: ANOVA-related Tests for \\(k\\) Continuous Population Means",
    "section": "",
    "text": "mindmap\n  root((Frequentist\n  Hypothesis \n  Testings\n  ))\n    Simulation Based&lt;br/&gt;Tests\n    Classical&lt;br/&gt;Tests\n      (Chapter 1: &lt;br/&gt;Tests for One&lt;br/&gt;Continuous&lt;br/&gt;Population Mean)\n      (Chapter 2: &lt;br/&gt;Tests for Two&lt;br/&gt;Continuous&lt;br/&gt;Population Means)\n      (Chapter 3: &lt;br/&gt;ANOVA-related &lt;br/&gt;Tests for&lt;br/&gt;k Continuous&lt;br/&gt;Population Means)\n        {{Unbounded&lt;br/&gt;Responses}}\n          One&lt;br/&gt;Factor type&lt;br/&gt;Feature\n            )One way&lt;br/&gt;ANOVA(\n          Two&lt;br/&gt;Factor type&lt;br/&gt;Features\n            )Two way&lt;br/&gt;ANOVA(\n\n\n\n\n\n\n\n\nFigure 1: A specific hypothesis testing mind map outlining the techniques explored in this chapter, which include ANOVA-related tests for \\(k\\) population means.",
    "crumbs": [
      "Chapter 3: ANOVA-related Tests for $k$ Continuous Population Means"
    ]
  },
  {
    "objectID": "book/references.html",
    "href": "book/references.html",
    "title": "References",
    "section": "",
    "text": "Tukey, John W. 1962. “The Future of Data\nAnalysis.” The Annals of Mathematical Statistics\n33 (1): 1–67. https://doi.org/10.1214/aoms/1177704711.",
    "crumbs": [
      "References"
    ]
  }
]