{
  "hash": "8fde76eaacb9972f75c7a08c570b9dc7",
  "result": {
    "engine": "knitr",
    "markdown": "<!-- Google tag (gtag.js) -->\n<script async src=\"https://www.googletagmanager.com/gtag/js?id=G-DZWGQVJSHE\"></script>\n<script>\n  window.dataLayer = window.dataLayer || [];\n  function gtag(){dataLayer.push(arguments);}\n  gtag('js', new Date());\n  gtag('config', 'G-DZWGQVJSHE');\n</script>\n\n# ANOVA-related Tests for $k$ Continuous Population Means {#sec-anova}\n\n\n\n\n\n\n\n\n\n\n\n\n\n::::: LO\n::: LO-header\nLearning Objectives\n:::\n\n::: LO-container\nBy the end of this chapter, you will be able to:\n\n-   Explain how analysis of variance (ANOVA) **partitions** total variation into **between-group** and **within-group** components.\n-   Interpret the meaning of the $F$-statistic and its role in testing mean differences across groups.\n-   Describe the difference between **main effects** and **interaction effects** in a two-way ANOVA.\n-   Identify potential **interaction patterns** via appropriate plotting when conducting a two-way ANOVA.\n-   Conduct one-way and two-way ANOVA in a **reproducible manner** using the hypothesis testing workflow via `R` and `Python`.\n-   Identify the assumptions underlying one-way and two-way ANOVA, including **independence**, **normality**, and **homoscedasticity**.\n-   Evaluate **model diagnostics** to assess whether ANOVA assumptions are met.\n:::\n:::::\n\nIt is time to expand our hypothesis testing framework from comparing two population means to a generalized approach for $k$ population means by exploring **analysis of variance (ANOVA)**. ANOVA is a foundational test in frequentist statistics designed to compare means across multiple populations under specific distributional assumptions, which we will examine in this chapter. Originally formalized by Ronald A. Fisher [@fisher1925], ANOVA extends the concept of the two-sample $t$-test by partitioning the total variability of our outcome of interest into components attributable to **main effects**, **interactions**, and **random error**. This partitioning enables us to determine whether observed differences in groups are improbable to appear under the null hypothesis, which states that all groups share the same population mean.\n\n::: {#fig-test-chapter-3-mindmap}\n\n\n\n\n\n```{mermaid}\nmindmap\n  root((Frequentist\n  Hypothesis \n  Testings\n  ))\n    Simulation Based<br/>Tests\n    Classical<br/>Tests\n      (Chapter 1: <br/>Tests for One<br/>Continuous<br/>Population Mean)\n      (Chapter 2: <br/>Tests for Two<br/>Continuous<br/>Population Means)\n      (Chapter 3: <br/>ANOVA-related <br/>Tests for<br/>k Continuous<br/>Population Means)\n        {{Unbounded<br/>Responses}}\n          One<br/>Factor type<br/>Feature\n            )One way<br/>ANOVA(\n          Two<br/>Factor type<br/>Features\n            )Two way<br/>ANOVA(\n```\n\n\n\n\n\n\nA specific hypothesis testing mind map outlining the techniques explored in this chapter, which include ANOVA-related tests for $k$ population means.\n:::\n\n::::: Heads-up\n::: Heads-up-header\nHeads-up on some historical background in statistics!\n:::\n\n::: Heads-up-container\nWhile Ronald A. Fisher (1890–1962) is rightly recognized as a significant figure in modern statistics for developing key concepts such as ANOVA, it is imperative to recognize the broader context of his legacy. Beyond his pioneering contributions to statistics, Fisher was also a prominent advocate of eugenics, a movement that promoted pseudoscientific ideas about human heredity and social hierarchy. His involvement with the eugenics community is well documented [@mackenzie1981]. These views have been called out by certain members of the scientific community [@tarran2020]. That said, we (the authors of this mini-book) consider that students and scholars need to distinguish Fisher’s statistical insights from the unethical ideologies he supported, while also acknowledging the social responsibility to critique the historical misuse of science.\n\nFisher’s statistical work remains central to frequentist inference. However, educators and researchers must confront the historical connection between statistical innovation and eugenic thinking in early 20th-century science [@tabery2015]. By explicitly addressing this context, we can acknowledge the rigour of Fisher’s methodological contributions while rejecting the discriminatory worldviews he promoted. This approach aligns with contemporary efforts to ensure that teaching statistics is grounded not only in subject matter accuracy but also in ethical reflection and historical accountability [@kennedyshaffer02024].\n:::\n:::::\n\nThis chapter builds on the concepts introduced in the earlier works by @sec-one-continuous-mean and @sec-two-continuous-means, which concentrated on hypothesis testing for one and two groups, respectively. While those chapters primarily addressed pairwise comparisons, we will now shift our focus to multiple comparisons:\n\n- The **one-way ANOVA**, discussed in @sec-one-way-ANOVA, will assume a **single categorical factor with** $k$ levels. This approach allows us to test whether at least one group mean is significantly different from the others.\n- In contrast, the **two-way ANOVA**, from @sec-two-way-ANOVA, will incorporate an **additional categorical factor with** $m$ levels, permitting the analysis of both main effects and interaction effects. Interaction terms in ANOVA are especially useful for revealing cases where the effect of one factor depends on the level of another, a situation often encountered in complex experimental designs.\n\nAs a side note, the workflow guiding this chapter, as referenced in @fig-hypothesis-testing-workflow, will provide a structured approach for applying both one-way and two-way ANOVA to their respective A/B/n datasets (see @sec-ANOVA-datasets).\n\n::::: Heads-up\n::: Heads-up-header\nHeads-up on the importance of ANOVA in data science!\n:::\n\n::: Heads-up-container\nIn modern data science, ANOVA remains significant, particularly in **A/B/n testing** (the generalization of **A/B testing** to multiple treatments). This approach allows for the simultaneous evaluation of various treatment variations or designs. ANOVA is valued for its interpretability and its flexibility in handling both **balanced** designs (where there is an equal number of replicates for each experimental treatment) and **unbalanced** designs (where there are unequal numbers of replicates). These strengths have solidified its role in both academic research and practical applications.\n\n![Image by [*Manfred Steger*](https://pixabay.com/users/manfredsteger-1848497/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3699345) via [*Pixabay*](https://pixabay.com/vectors/pixel-cells-download-data-transfer-3947910/).](img/pulling.png){width=\"80%\"}\n:::\n:::::\n\n## The ANOVA Datasets {#sec-ANOVA-datasets}\n\nThe **simulated datasets** discussed in this chapter relate to an experimental context known as A/B/n testing, which is an expansion of traditional A/B testing as previously discussed. In a typical A/B testing, participants are randomly assigned to one of two strategies, referred to as treatments: treatment $A$ (the **control treatment**) and treatment $B$ (the **experimental treatment**). This approach enables us to infer **causation** concerning the following inquiry:\n\n> **Will changing from treatment** $A$ to treatment $B$ cause my outcome of interest, $Y$, to increase (or decrease, if that is the case)?\n\nIn an ANOVA setting, the outcome must be **continuous**. The primary goal of A/B testing is to determine whether there is a statistically significant difference between treatments $A$ and $B$ concerning the outcome. Additionally, because we are conducting a proper randomized experiment, we can infer causation (which goes further than mere association), as treatment randomization enables us to get rid of the effect of further **confounders**.\n\n::::: Heads-up\n::: Heads-up-header\nHeads-up on confounding!\n:::\n\n::: Heads-up-container\nIn causal inference, confounding refers to the mixing of effects between the outcome of interest, denoted as $Y$, the randomized factor $X$ (which is a two-level factor in A/B testing, corresponding to treatment $A$ and treatment $B$), and a third, uncontrollable factor known as the confounder $C$. This confounder is associated with the factor $X$ and independently affects the outcome $Y$, as shown by @fig-confounding.\n\n![Diagram depicting confounding [@DSCI554].](img/confounding.png){#fig-confounding fig-align=\"center\" width=\"70%\"}\n:::\n:::::\n\nWhen conducting experiments with more than two treatments in A/B testing, the experiment is referred to as **A/B/n testing**. In this case, the \"*n*\" does not indicate the sample size; rather, it simply represents any number of additional treatments beyond treatments $A$ and $B$. With this clarification, we can now proceed with our simulated datasets.\n\n![Image by [*Pabitra Kaity*](https://pixabay.com/users/pabitrakaity-7844390/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=6370790) via [*Pixabay*](https://pixabay.com/illustrations/ads-digital-marketing-advertisements-6370790/).](img/ads.png){fig-align=\"center\" width=\"50%\"}\n\n\n## One-way ANOVA {#sec-one-way-ANOVA}\n\n### Study Design {#sec-one-way-ANOVA-study-design}\n\n### Data Collection and Wrangling {#sec-one-way-ANOVA-data-collection-wrangling}\n\n::: {.panel-tabset}\n\n## **`R` Code**\n\n``` {.r}\n# Loading dataset\nOneWay_ABn_customer_data <- read.csv(\"data/ABn_customer_data_one_factor.csv\")\n\n# Showing the first 100 customers of the A/B/n testing\nhead(OneWay_ABn_customer_data, n = 100)\n```\n\n## **`Python` Code**\n\n``` {.python}\n# Importing library\nimport pandas as pd\n\n# Loading dataset\nOneWay_ABn_customer_data = pd.read_csv(\"data/ABn_customer_data_one_factor.csv\")\n\n# Showing the first 100 customers of the A/B/n testing\nprint(OneWay_ABn_customer_data.head(100))\n```\n\n:::\n\n::: {.panel-tabset}\n\n## **`R` Output**\n\n\n\n\n\n\n::: {#tbl-ANOVA-ABn-data-r-one .cell tbl-cap='First 100 rows of our A/B/n simulated data with webpage design as a standalone experimental factor.'}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-355dcfc6c329fc99e9ce\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-355dcfc6c329fc99e9ce\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\"],[58.23,59.27,64.93000000000001,60.22,60.41,65.42,61.46,56,57.83,58.59,63.87,61.14,61.27,60.35,58.24,65.65000000000001,61.57,53.78,62.22,58.5,56.62,59.31,56.76,57.7,58.02,54.67,62.65,60.49,56.4,63.96,61.35,59.07,62.83,62.78,62.6,62.18,61.75,59.8,59.03,58.8,57.8,59.34,56,66.86,63.82,56.45,58.73,58.52,62.47,59.74,60.8,59.91,59.86,64.33,59.29,64.8,55.1,61.85,60.39,60.68,61.2,58.41,58.95,56.78,56.61,60.96,61.42,60.17,62.92,66.48,58.45,52.7,63.18,57.76,57.82,63.24,59.1,56.14,60.57,59.56,60.02,61.22,58.83,62.04,59.3,61.05,63.47,61.38,58.97,63.63,63.14,61.73,60.75,58.01,64.3,58.1,66.92,64.84999999999999,59.25,56.75]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th>webpage_design<\\/th>\\n      <th>conversion_score<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"dom\":\"ltipr\",\"autoWidth\":true,\"columnDefs\":[{\"className\":\"dt-left\",\"targets\":\"_all\"},{\"width\":\"200px\",\"targets\":\"_all\"},{\"name\":\"webpage_design\",\"targets\":0},{\"name\":\"conversion_score\",\"targets\":1}],\"order\":[],\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\n\n\n## **`Python` Output**\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {#tbl-ANOVA-ABn-data-py-one .cell tbl-cap='First 100 rows of our A/B/n simulated data with webpage design as a standalone experimental factor.'}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-222f7979e188da2b3fb9\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-222f7979e188da2b3fb9\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\"],[58.23,59.27,64.93000000000001,60.22,60.41,65.42,61.46,56,57.83,58.59,63.87,61.14,61.27,60.35,58.24,65.65000000000001,61.57,53.78,62.22,58.5,56.62,59.31,56.76,57.7,58.02,54.67,62.65,60.49,56.4,63.96,61.35,59.07,62.83,62.78,62.6,62.18,61.75,59.8,59.03,58.8,57.8,59.34,56,66.86,63.82,56.45,58.73,58.52,62.47,59.74,60.8,59.91,59.86,64.33,59.29,64.8,55.1,61.85,60.39,60.68,61.2,58.41,58.95,56.78,56.61,60.96,61.42,60.17,62.92,66.48,58.45,52.7,63.18,57.76,57.82,63.24,59.1,56.14,60.57,59.56,60.02,61.22,58.83,62.04,59.3,61.05,63.47,61.38,58.97,63.63,63.14,61.73,60.75,58.01,64.3,58.1,66.92,64.84999999999999,59.25,56.75]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th>webpage_design<\\/th>\\n      <th>conversion_score<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"dom\":\"ltipr\",\"autoWidth\":true,\"columnDefs\":[{\"className\":\"dt-left\",\"targets\":\"_all\"},{\"width\":\"200px\",\"targets\":\"_all\"},{\"name\":\"webpage_design\",\"targets\":0},{\"name\":\"conversion_score\",\"targets\":1}],\"order\":[],\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\n\n\n:::\n\n\n::: {.panel-tabset}\n\n## **`R` Code**\n\n``` {.r}\n# Loading libraries\nlibrary(tidyverse)\nlibrary(rsample)\n\n# Seed for reproducibility\nset.seed(123)\n\n# Randomly splitting into training and testing sets by webpage_design\nOneWay_ABn_customer_data_splitting <- initial_split(OneWay_ABn_customer_data,\n  prop = 0.5, strata = webpage_design\n)\n\n# Assigning data points to training and testing sets\nOneWay_ABn_training <- training(OneWay_ABn_customer_data_splitting)\nOneWay_ABn_testing <- testing(OneWay_ABn_customer_data_splitting)\n\n# Sanity check\ncat(\"Training shape:\", dim(OneWay_ABn_training), \"\\n\")\ncat(\"Testing shape:\", dim(OneWay_ABn_testing), \"\\n\\n\")\ncat(\"Training proportions:\\n\")\nprint(prop.table(table(OneWay_ABn_training$webpage_design)))\ncat(\"\\nTesting proportions:\\n\")\nprint(prop.table(table(OneWay_ABn_testing$webpage_design)))\n```\n\n## **`Python` Code**\n\n``` {.python}\n# Importing library\nfrom sklearn.model_selection import train_test_split\n\n# Seed for reproducibility\nrandom_state = 123\n\n# Randomly splitting into training and testing sets by webpage_design\nOneWay_ABn_training, OneWay_ABn_testing = train_test_split(\n    OneWay_ABn_customer_data,\n    test_size=0.5,\n    stratify=OneWay_ABn_customer_data[\"webpage_design\"],\n    random_state=random_state\n)\n\n# Sanity check\nprint(\"Training shape:\", OneWay_ABn_training.shape)\nprint(\"Testing shape:\", OneWay_ABn_testing.shape)\nprint(\"\\nTraining proportions:\")\nprint(OneWay_ABn_training[\"webpage_design\"].value_counts(normalize=True))\nprint(\"\\nTesting proportions:\")\nprint(OneWay_ABn_testing[\"webpage_design\"].value_counts(normalize=True))\n```\n\n:::\n\n::: {.panel-tabset}\n\n## **`R` Output**\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining shape: 300 2 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting shape: 300 2 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining proportions:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n       D1        D2        D3 \n0.3333333 0.3333333 0.3333333 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nTesting proportions:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n       D1        D2        D3 \n0.3333333 0.3333333 0.3333333 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n## **`Python` Output**\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining shape: (300, 2)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting shape: (300, 2)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nTraining proportions:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nwebpage_design\nD2    0.333333\nD3    0.333333\nD1    0.333333\nName: proportion, dtype: float64\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nTesting proportions:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nwebpage_design\nD1    0.333333\nD3    0.333333\nD2    0.333333\nName: proportion, dtype: float64\n```\n\n\n:::\n:::\n\n\n\n\n\n\n:::\n\n### Exploratory Data Analysis {#sec-one-way-ANOVA-EDA}\n\n::: {.panel-tabset}\n\n## **`R`**\n\n\n\n\n\n\n::: {#tbl-one-summary-stats-r .cell tbl-cap='Descriptive statistics of one-factor A/B/n testing via training set.'}\n\n```{.r .cell-code}\n# Computing summaries\nOneWay_summary_table <- OneWay_ABn_training |>\n  group_by(webpage_design) |>\n  summarise(\n    mean_conversion = round(mean(conversion_score), 2),\n    sd_conversion = round(sd(conversion_score), 2),\n    n = n()\n  ) |>\n  arrange(webpage_design)\nOneWay_summary_table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 4\n  webpage_design mean_conversion sd_conversion     n\n  <chr>                    <dbl>         <dbl> <int>\n1 D1                        60.1          2.9    100\n2 D2                        60.4          3.05   100\n3 D3                        60.3          3.05   100\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## **`Python`**\n\n\n\n\n\n\n::: {#tbl-one-summary-stats-py .cell tbl-cap='Descriptive statistics of one-factor A/B/n testing via training set.'}\n\n```{.python .cell-code}\n# Importing library\nimport numpy as np\n\n# Importing R training set via R library reticulate\nOneWay_ABn_training = r.OneWay_ABn_training\n\nOneWay_summary_table = (\n    OneWay_ABn_training\n    .groupby(\"webpage_design\")\n    .agg(\n        mean_conversion=(\"conversion_score\", lambda x: round(np.mean(x), 2)),\n        sd_conversion=(\"conversion_score\", lambda x: round(np.std(x, ddof=1), 2)),\n        n=(\"conversion_score\", \"count\")\n    )\n    .reset_index()\n    .sort_values(\"webpage_design\")\n)\nOneWay_summary_table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  webpage_design  mean_conversion  sd_conversion    n\n0             D1            60.11           2.90  100\n1             D2            60.35           3.05  100\n2             D3            60.28           3.05  100\n```\n\n\n:::\n:::\n\n\n\n\n\n\n:::\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Histograms of conversion score by webpage design via training data.](chapter4-anova_files/figure-html/fig-hist-webpage-design-one-1.png){#fig-hist-webpage-design-one width=1344}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Side-by-side boxplots of conversion score by webpage design via training data.](chapter4-anova_files/figure-html/fig-boxplot-webpage-design-one-1.png){#fig-boxplot-webpage-design-one width=1344}\n:::\n:::\n\n\n\n\n\n\n\n### Testing Settings {#sec-one-way-ANOVA-testing-settings}\n\n### Hypothesis Definitions {#sec-one-way-ANOVA-hypothesis-definitions}\n\n### Test Flavour and Components {#sec-one-way-ANOVA-test-flavour}\n\n::: {.panel-tabset}\n\n## **`R`**\n\n\n\n\n\n\n::: {#tbl-one-fitting-r .cell tbl-cap='One-way ANOVA: Conversion score by webpage design via testing set.'}\n\n```{.r .cell-code}\n# Loading library\nlibrary(broom)\n\n# Running one-way ANOVA\nOneWay_aov <- aov(conversion_score ~ webpage_design,\n  data = OneWay_ABn_testing\n)\n\n# Displaying full one-way ANOVA table\ntidy(OneWay_aov) |>\n  mutate_if(is.numeric, round, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  term              df   sumsq meansq statistic p.value\n  <chr>          <dbl>   <dbl>  <dbl>     <dbl>   <dbl>\n1 webpage_design     2    0.49   0.24      0.03    0.98\n2 Residuals        297 2901.     9.77     NA      NA   \n```\n\n\n:::\n:::\n\n\n\n\n\n\n## **`Python`**\n\n\n\n\n\n\n::: {#tbl-one-fitting-py .cell tbl-cap='One-way ANOVA: Conversion score by webpage design via testing set.'}\n\n```{.python .cell-code}\n# Importing library\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\n\n# Importing R testing set via R library reticulate\nOneWay_ABn_testing = r.OneWay_ABn_testing\n\n# Running one-way ANOVA\nOneWay_model = ols('conversion_score ~ C(webpage_design)', data=OneWay_ABn_testing).fit()\nOneWay_aov = sm.stats.anova_lm(OneWay_model, typ=2)\n\n# Displaying full one-way ANOVA table\nOneWay_aov = OneWay_aov.round(2)\nOneWay_aov\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                    sum_sq     df     F  PR(>F)\nC(webpage_design)     0.49    2.0  0.03    0.98\nResidual           2900.76  297.0   NaN     NaN\n```\n\n\n:::\n:::\n\n\n\n\n\n\n:::\n\n### Inferential Conclusions {#sec-one-way-ANOVA-inferential-conclusions}\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Diagnostic Q-Q plot for one-way ANOVA of conversion score by webpage design via residuals.](chapter4-anova_files/figure-html/fig-q-q-plot-one-way-1.png){#fig-q-q-plot-one-way width=1344}\n:::\n:::\n\n\n\n\n\n\n::: {.panel-tabset}\n\n## **`R`**\n\n\n\n\n\n\n::: {#tbl-one-shapiro-wilks-r .cell tbl-cap='Shapiro–Wilks normality test for one-way ANOVA via residuals.'}\n\n```{.r .cell-code}\n# Extracting residuals\nOneWay_resid <- residuals(OneWay_aov)\n\n# Running Shapiro–Wilk test\nOneWay_shapiro <- shapiro.test(OneWay_resid)\n\n# Displaying outputs\ntidy(OneWay_shapiro) |>\n  mutate_if(is.numeric, round, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  statistic p.value method                     \n      <dbl>   <dbl> <chr>                      \n1      0.99     0.3 Shapiro-Wilk normality test\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## **`Python`**\n\n\n\n\n\n\n::: {#tbl-one-shapiro-wilks-py .cell tbl-cap='Shapiro–Wilks normality test for one-way ANOVA via residuals.'}\n\n```{.python .cell-code}\n# Importing library\nfrom scipy.stats import shapiro\n\n# Extracting residuals\nOneWay_resid = OneWay_model.resid\n\n# Running Shapiro–Wilk tests\nOneWay_shapiro = shapiro(OneWay_resid)\n\n# Displaying outputs\nOneWay_shapiro = pd.DataFrame({\n    \"W Statistic\": [round(OneWay_shapiro.statistic, 2)],\n    \"p-value\": [round(OneWay_shapiro.pvalue, 2)]\n})\nOneWay_shapiro\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   W Statistic  p-value\n0         0.99      0.3\n```\n\n\n:::\n:::\n\n\n\n\n\n\n:::\n\n::: {.panel-tabset}\n\n## **`R`**\n\n\n\n\n\n\n::: {#tbl-one-levene-r .cell tbl-cap='Levene’s test for homogeneity of variances for one-way ANOVA via testing data.'}\n\n```{.r .cell-code}\n# Loading library\nlibrary(car)\n\n# Running Levene test\nOneWay_levene <- leveneTest(conversion_score ~ as.factor(webpage_design),\n  data = OneWay_ABn_testing\n)\n\n# Displaying outputs\ntidy(OneWay_levene) |>\n  mutate_if(is.numeric, round, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n  statistic p.value    df df.residual\n      <dbl>   <dbl> <dbl>       <dbl>\n1      0.26    0.77     2         297\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## **`Python`**\n\n\n\n\n\n\n::: {#tbl-one-levene-py .cell tbl-cap='Levene’s test for homogeneity of variances for one-way ANOVA via testing data.'}\n\n```{.python .cell-code}\n# Importing library\nfrom scipy.stats import levene\n\n# Running Levene test\ngroups_OneWay = [group[\"conversion_score\"].values for _, group in OneWay_ABn_testing.groupby(\"webpage_design\")]\nstat1, p1 = levene(*groups_OneWay)\n\n# Displaying outputs\nOneWay_levene = pd.DataFrame({\n    \"Levene Statistic\": [round(stat1, 2)],\n    \"p-value\": [round(p1, 2)]\n})\nOneWay_levene\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Levene Statistic  p-value\n0              0.26     0.77\n```\n\n\n:::\n:::\n\n\n\n\n\n\n:::\n\n### Storytelling {#sec-one-way-ANOVA-storytelling}\n\n## Two-way ANOVA {#sec-two-way-ANOVA}\n\n### Study Design {#sec-two-way-ANOVA-study-design}\n\n### Data Collection and Wrangling {#sec-two-way-ANOVA-data-collection-wrangling}\n\n::: {.panel-tabset}\n\n## **`R` Code**\n\n``` {.r}\n# Loading dataset\nTwoWay_ABn_customer_data <- read.csv(\"data/ABn_customer_data_two_factors.csv\")\n\n# Showing the first 100 customers of the A/B/n testing\nhead(TwoWay_ABn_customer_data, n = 100)\n```\n\n## **`Python` Code**\n\n``` {.python}\n# Loading dataset\nTwoWay_ABn_customer_data = pd.read_csv(\"data/ABn_customer_data_two_factors.csv\")\n\n# Showing the first 100 customers of the A/B/n testing\nprint(TwoWay_ABn_customer_data(100))\n```\n\n:::\n\n::: {.panel-tabset}\n\n## **`R` Output**\n\n\n\n\n\n\n::: {#tbl-ANOVA-ABn-data-r-two .cell tbl-cap='First 100 rows of our A/B/n simulated data with webpage design and discount framing as a experimental factors.'}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-108e9e741a3e46725297\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-108e9e741a3e46725297\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\"],[\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\"],[46.76,48.08,55.23,49.28,49.52,55.86,50.84,43.94,46.25,47.22,53.9,50.44,50.6,49.44,46.78,56.15,50.99,41.13,51.81,47.11,44.73,48.13,44.9,46.08,46.5,42.25,52.35,49.61,44.45,54.02,50.71,47.82,52.58,52.51,52.29,51.75,51.22,48.75,47.78,47.48,46.22,48.17,43.94,57.68,53.83,44.51,47.39,47.13,52.12,48.67,50.01,48.89,48.83,54.47,48.1,55.07,42.8,51.34,49.5,49.86,50.52,46.99,47.67,44.93,44.71,50.21,50.79,49.21,52.69,57.2,47.04,39.76,53.02,46.16,46.25,53.1,47.86,44.12,49.73,48.44,49.02,50.54,47.52,51.58,48.12,50.33,53.39,50.74,47.7,53.6,52.97,51.19,49.95,46.49,54.44,46.6,57.75,55.13,48.06,44.89]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th>webpage_design<\\/th>\\n      <th>discount_framing<\\/th>\\n      <th>conversion_score<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"dom\":\"ltipr\",\"autoWidth\":true,\"columnDefs\":[{\"className\":\"dt-left\",\"targets\":\"_all\"},{\"width\":\"200px\",\"targets\":\"_all\"},{\"name\":\"webpage_design\",\"targets\":0},{\"name\":\"discount_framing\",\"targets\":1},{\"name\":\"conversion_score\",\"targets\":2}],\"order\":[],\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\n\n\n## **`Python` Output**\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {#tbl-ANOVA-ABn-data-py-two .cell tbl-cap='First 100 rows of our A/B/n simulated data with webpage design and discount framing as a experimental factors.'}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-5d39040379231a97595a\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-5d39040379231a97595a\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\",\"D1\"],[\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\",\"Low\"],[46.76,48.08,55.23,49.28,49.52,55.86,50.84,43.94,46.25,47.22,53.9,50.44,50.6,49.44,46.78,56.15,50.99,41.13,51.81,47.11,44.73,48.13,44.9,46.08,46.5,42.25,52.35,49.61,44.45,54.02,50.71,47.82,52.58,52.51,52.29,51.75,51.22,48.75,47.78,47.48,46.22,48.17,43.94,57.68,53.83,44.51,47.39,47.13,52.12,48.67,50.01,48.89,48.83,54.47,48.1,55.07,42.8,51.34,49.5,49.86,50.52,46.99,47.67,44.93,44.71,50.21,50.79,49.21,52.69,57.2,47.04,39.76,53.02,46.16,46.25,53.1,47.86,44.12,49.73,48.44,49.02,50.54,47.52,51.58,48.12,50.33,53.39,50.74,47.7,53.6,52.97,51.19,49.95,46.49,54.44,46.6,57.75,55.13,48.06,44.89]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th>webpage_design<\\/th>\\n      <th>discount_framing<\\/th>\\n      <th>conversion_score<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"dom\":\"ltipr\",\"autoWidth\":true,\"columnDefs\":[{\"className\":\"dt-left\",\"targets\":\"_all\"},{\"width\":\"200px\",\"targets\":\"_all\"},{\"name\":\"webpage_design\",\"targets\":0},{\"name\":\"discount_framing\",\"targets\":1},{\"name\":\"conversion_score\",\"targets\":2}],\"order\":[],\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\n\n\n:::\n\n\n\n::: {.panel-tabset}\n\n## **`R` Code**\n\n``` {.r}\n# Seed for reproducibility\nset.seed(123)\n\n# Create a combined stratification variable\nTwoWay_ABn_customer_data <- TwoWay_ABn_customer_data |>\n  mutate(strata = interaction(webpage_design, discount_framing))\n\n# Randomly splitting into training and testing sets by both factors\nTwoWay_ABn_customer_data_splitting <- initial_split(\n  TwoWay_ABn_customer_data,\n  prop = 0.5,\n  strata = strata\n)\n\n# Assigning data points to training and testing sets\nTwoWay_ABn_training <- training(TwoWay_ABn_customer_data_splitting)\nTwoWay_ABn_testing  <- testing(TwoWay_ABn_customer_data_splitting)\n\n# Sanity check\ncat(\"Training shape:\", dim(TwoWay_ABn_training), \"\\n\")\ncat(\"Testing shape:\", dim(TwoWay_ABn_testing), \"\\n\\n\")\n\ncat(\"Training proportions:\\n\")\nprint(prop.table(table(TwoWay_ABn_training$webpage_design, TwoWay_ABn_training$discount_framing)))\n\ncat(\"\\nTesting proportions:\\n\")\nprint(prop.table(table(TwoWay_ABn_testing$webpage_design, TwoWay_ABn_testing$discount_framing)))\n```\n\n## **`Python` Code**\n\n``` {.python}\n# Seed for reproducibility\nrandom_state = 123\n\n# Create a combined stratification variable\nTwoWay_ABn_customer_data[\"strata\"] = (\n    TwoWay_ABn_customer_data[\"webpage_design\"].astype(str)\n    + \"_\"\n    + TwoWay_ABn_customer_data[\"discount_framing\"].astype(str)\n)\n\n# Randomly splitting into training and testing sets by both factors\nTwoWay_ABn_training, TwoWay_ABn_testing = train_test_split(\n    TwoWay_ABn_customer_data,\n    test_size=0.5,\n    stratify=TwoWay_ABn_customer_data[\"strata\"],\n    random_state=random_state\n)\n\n# Sanity check\nprint(\"Training shape:\", TwoWay_ABn_training.shape)\nprint(\"Testing shape:\", TwoWay_ABn_testing.shape)\n\nprint(\"\\nTraining proportions:\")\nprint(TwoWay_ABn_training.groupby([\"webpage_design\", \"discount_framing\"]).size().div(len(TwoWay_ABn_training)))\n\nprint(\"\\nTesting proportions:\")\nprint(TwoWay_ABn_testing.groupby([\"webpage_design\", \"discount_framing\"]).size().div(len(TwoWay_ABn_testing)))\n```\n\n:::\n\n::: {.panel-tabset}\n\n## **`R` Output**\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining shape: 600 4 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting shape: 600 4 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining proportions:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    \n          High       Low\n  D1 0.1666667 0.1666667\n  D2 0.1666667 0.1666667\n  D3 0.1666667 0.1666667\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nTesting proportions:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    \n          High       Low\n  D1 0.1666667 0.1666667\n  D2 0.1666667 0.1666667\n  D3 0.1666667 0.1666667\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## **`Python` Output**\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining shape: (600, 4)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting shape: (600, 4)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nTraining proportions:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nwebpage_design  discount_framing\nD1              High                0.166667\n                Low                 0.166667\nD2              High                0.166667\n                Low                 0.166667\nD3              High                0.166667\n                Low                 0.166667\ndtype: float64\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nTesting proportions:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nwebpage_design  discount_framing\nD1              High                0.166667\n                Low                 0.166667\nD2              High                0.166667\n                Low                 0.166667\nD3              High                0.166667\n                Low                 0.166667\ndtype: float64\n```\n\n\n:::\n:::\n\n\n\n\n\n\n:::\n\n### Exploratory Data Analysis {#sec-two-way-ANOVA-EDA}\n\n::: {.panel-tabset}\n\n## **`R`**\n\n\n\n\n\n\n::: {#tbl-two-summary-stats-r .cell tbl-cap='Descriptive statistics of two-factor A/B/n testing via training set.'}\n\n```{.r .cell-code}\n# Computing summaries\nTwoWay_summary_table <- TwoWay_ABn_training |>\n  group_by(webpage_design, discount_framing) |>\n  summarise(\n    mean_conversion = round(mean(conversion_score), 2),\n    sd_conversion = round(sd(conversion_score), 2),\n    n = n()\n  ) |>\n  arrange(webpage_design, discount_framing)\nTwoWay_summary_table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n# Groups:   webpage_design [3]\n  webpage_design discount_framing mean_conversion sd_conversion     n\n  <chr>          <chr>                      <dbl>         <dbl> <int>\n1 D1             High                        66.1          3.79   100\n2 D1             Low                         48.5          3.89   100\n3 D2             High                        77.1          3.73   100\n4 D2             Low                         62.8          4.04   100\n5 D3             High                        69.1          4.27   100\n6 D3             Low                         77.0          3.91   100\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## **`Python`**\n\n\n\n\n\n\n::: {#tbl-two-summary-stats-py .cell tbl-cap='Descriptive statistics of two-factor A/B/n testing via training set.'}\n\n```{.python .cell-code}\n# Importing R training set via R library reticulate\nTwoWay_ABn_training = r.TwoWay_ABn_training\n\n# Computing summaries\nTwoWay_summary_table = (\n    TwoWay_ABn_training\n    .groupby([\"webpage_design\", \"discount_framing\"])\n    .agg(\n        mean_conversion=(\"conversion_score\", lambda x: round(np.mean(x), 2)),\n        sd_conversion=(\"conversion_score\", lambda x: round(np.std(x, ddof=1), 2)),\n        n=(\"conversion_score\", \"count\")\n    )\n    .reset_index()\n    .sort_values([\"webpage_design\", \"discount_framing\"])\n)\nTwoWay_summary_table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  webpage_design discount_framing  mean_conversion  sd_conversion    n\n0             D1             High            66.10           3.79  100\n1             D1              Low            48.54           3.89  100\n2             D2             High            77.07           3.73  100\n3             D2              Low            62.83           4.04  100\n4             D3             High            69.14           4.27  100\n5             D3              Low            76.95           3.91  100\n```\n\n\n:::\n:::\n\n\n\n\n\n\n:::\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Histograms of conversion score by webpage design and discount framing via training data.](chapter4-anova_files/figure-html/fig-hist-webpage-design-two-1.png){#fig-hist-webpage-design-two width=1344}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Side-by-side boxplots of conversion score by webpage design and discount framing via training data.](chapter4-anova_files/figure-html/fig-boxplot-webpage-design-two-1.png){#fig-boxplot-webpage-design-two width=1344}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Interaction plot of conversion score by webpage design and discount framing via training data.](chapter4-anova_files/figure-html/fig-interaction-plot-1.png){#fig-interaction-plot width=1344}\n:::\n:::\n\n\n\n\n\n\n### Testing Settings {#sec-two-way-ANOVA-testing-settings}\n\n### Hypothesis Definitions {#sec-two-way-ANOVA-hypothesis-definitions}\n\n### Test Flavour and Components {#sec-two-way-ANOVA-test-flavour}\n\n::: {.panel-tabset}\n\n## **`R`**\n\n\n\n\n\n\n::: {#tbl-two-fitting-r .cell tbl-cap='Two-way ANOVA: Conversion score by webpage design and discount framing via testing set.'}\n\n```{.r .cell-code}\n# Running two-way ANOVA\nTwoWay_aov <- aov(conversion_score ~ webpage_design * discount_framing,\n  data = TwoWay_ABn_testing\n)\n\n# Displaying full two-way ANOVA table\nTwoWay_aov <- tidy(TwoWay_aov) |>\n  mutate(across(where(is.numeric) & !matches(\"p.value\"), ~ round(.x, 2)))\nTwoWay_aov\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 6\n  term                               df  sumsq  meansq statistic    p.value\n  <chr>                           <dbl>  <dbl>   <dbl>     <dbl>      <dbl>\n1 webpage_design                      2 26750. 13375.       817.  3.00e-171\n2 discount_framing                    1  8140.  8140.       497.  1.72e- 80\n3 webpage_design:discount_framing     2 18207.  9103.       556.  7.93e-137\n4 Residuals                         594  9723.    16.4       NA  NA        \n```\n\n\n:::\n:::\n\n\n\n\n\n\n## **`Python`**\n\n\n\n\n\n\n::: {#tbl-two-fitting-py .cell tbl-cap='Two-way ANOVA: Conversion score by webpage design and discount framing via testing set.'}\n\n```{.python .cell-code}\n# Importing R testing set via R library reticulate\nTwoWay_ABn_testing = r.TwoWay_ABn_testing\n\n# Running two-way ANOVA\nTwoWay_model = ols('conversion_score ~ C(webpage_design) * C(discount_framing)', data=TwoWay_ABn_testing).fit()\nTwoWay_aov = sm.stats.anova_lm(TwoWay_model, typ=2)\n\n# Round all numeric columns except p-values\ncols_to_round = [c for c in TwoWay_aov.columns if c != \"PR(>F)\"]\nTwoWay_aov[cols_to_round] = TwoWay_aov[cols_to_round].round(2)\n\n# Displaying full two-way ANOVA table\nTwoWay_aov\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                         sum_sq     df       F         PR(>F)\nC(webpage_design)                      26749.51    2.0  817.05  3.002041e-171\nC(discount_framing)                     8139.80    1.0  497.25   1.718558e-80\nC(webpage_design):C(discount_framing)  18206.69    2.0  556.12  7.926552e-137\nResidual                                9723.46  594.0     NaN            NaN\n```\n\n\n:::\n:::\n\n\n\n\n\n\n:::\n\n### Inferential Conclusions {#sec-two-way-ANOVA-inferential-conclusions}\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Diagnostic Q-Q plot for two-way ANOVA of conversion score by webpage design and discount framing via residuals.](chapter4-anova_files/figure-html/fig-q-q-plot-two-way-1.png){#fig-q-q-plot-two-way width=1344}\n:::\n:::\n\n\n\n\n\n\n::: {.panel-tabset}\n\n## **`R`**\n\n\n\n\n\n\n::: {#tbl-two-shapiro-wilks-r .cell tbl-cap='Shapiro–Wilks normality test for two-way ANOVA via residuals.'}\n\n```{.r .cell-code}\n# Extracting residuals\nTwoWay_resid <- residuals(TwoWay_aov)\n\n# Running Shapiro–Wilk test\nTwoWay_shapiro <- shapiro.test(TwoWay_resid)\n\n# Displaying outputs\ntidy(TwoWay_shapiro) |>\n  mutate_if(is.numeric, round, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  statistic p.value method                     \n      <dbl>   <dbl> <chr>                      \n1         1    0.19 Shapiro-Wilk normality test\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## **`Python`**\n\n\n\n\n\n\n::: {#tbl-two-shapiro-wilks-py .cell tbl-cap='Shapiro–Wilks normality test for two-way ANOVA via residuals.'}\n\n```{.python .cell-code}\n# Extracting residuals\nTwoWay_resid = TwoWay_model.resid\n\n# Running Shapiro–Wilk tests\nTwoWay_shapiro = shapiro(TwoWay_resid)\n\n# Displaying outputs\nTwoWay_shapiro = pd.DataFrame({\n    \"W Statistic\": [round(TwoWay_shapiro.statistic, 2)],\n    \"p-value\": [round(TwoWay_shapiro.pvalue, 2)]\n})\nTwoWay_shapiro\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   W Statistic  p-value\n0          1.0     0.19\n```\n\n\n:::\n:::\n\n\n\n\n\n\n:::\n\n::: {.panel-tabset}\n\n## **`R`**\n\n\n\n\n\n\n::: {#tbl-two-levene-r .cell tbl-cap='Levene’s test for homogeneity of variances for two-way ANOVA via testing data.'}\n\n```{.r .cell-code}\n# Loading library\nlibrary(car)\n\n# Running Levene test\nTwoWay_levene <- leveneTest(conversion_score ~ as.factor(webpage_design) * as.factor(discount_framing),\n  data = TwoWay_ABn_testing\n)\n\n# Displaying outputs\ntidy(TwoWay_levene) |>\n  mutate_if(is.numeric, round, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n  statistic p.value    df df.residual\n      <dbl>   <dbl> <dbl>       <dbl>\n1      1.92    0.09     5         594\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## **`Python`**\n\n\n\n\n\n\n::: {#tbl-two-levene-py .cell tbl-cap='Levene’s test for homogeneity of variances for two-way ANOVA via testing data.'}\n\n```{.python .cell-code}\n# Running Levene test\nTwoWay_ABn_testing[\"group\"] = TwoWay_ABn_testing[\"webpage_design\"].astype(str) + \"_\" + TwoWay_ABn_testing[\"discount_framing\"].astype(str)\ngroups_TwoWay = [group[\"conversion_score\"].values for _, group in TwoWay_ABn_testing.groupby(\"group\")]\nstat1, p1 = levene(*groups_TwoWay)\n\n# Displaying outputs\nTwoWay_levene = pd.DataFrame({\n    \"Levene Statistic\": [round(stat1, 2)],\n    \"p-value\": [round(p1, 2)]\n})\nTwoWay_levene\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Levene Statistic  p-value\n0              1.92     0.09\n```\n\n\n:::\n:::\n\n\n\n\n\n\n:::\n\n### Storytelling {#sec-two-way-ANOVA-storytelling}\n\n## Chapter Summary {#sec-chapter-4-summary}\n",
    "supporting": [
      "chapter4-anova_files\\figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<link href=\"../site_libs/datatables-css-0.0.0/datatables-crosstalk.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/datatables-binding-0.33/datatables.js\"></script>\n<script src=\"../site_libs/jquery-3.6.0/jquery-3.6.0.min.js\"></script>\n<link href=\"../site_libs/dt-core-1.13.6/css/jquery.dataTables.min.css\" rel=\"stylesheet\" />\n<link href=\"../site_libs/dt-core-1.13.6/css/jquery.dataTables.extra.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/dt-core-1.13.6/js/jquery.dataTables.min.js\"></script>\n<link href=\"../site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}