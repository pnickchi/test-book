<!-- Google tag (gtag.js) -->

```{=html}
<script async src="https://www.googletagmanager.com/gtag/js?id=G-DZWGQVJSHE"></script>
```

```{=html}
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-DZWGQVJSHE');
</script>
```

```{r, echo = FALSE}
#| label: setup
#| include: false
library(tidyverse)
library(ISLR)
```

# Tests for Two Continuous Population Mean {#sec-two-continuous-means}

This chapter introduces statistical tests designed to compare two samples which is a fundamental task in data analysis across many disciplines. Whether you're comparing average recovery times between two medical treatments, student test scores under different teaching methods, comparing the proportion among two samples, or reaction times under varying stress conditions, these methods help determine whether observed differences are statistically significant or simply due to chance.

::: {#fig-test-chapter-2-mindmap}
```{mermaid}
mindmap
  root((Frequentist
  Hypothesis 
  Testings
  ))
    Simulation Based<br/>Tests
    Classical<br/>Tests
      (Chapter 1: <br/>Tests for One<br/>Continuous<br/>Population Mean)
      (Chapter 2: <br/>Tests for Two<br/>Continuous<br/>Population Means)
        Two<br/>Independent<br/>Populations
          {{Unbounded<br/>Responses}}
            Unknown<br/>Population<br/>Variances
              Population<br/>Variances<br/>are assumed<br/>to be Equal
                )Two sample<br/>Student's t test<br/>for Independent<br/>Samples(
              Population<br/>Variances<br/>are assumed<br/>to be Unequal
                )Two sample<br/>Welch's t test<br/>for Independent<br/>Samples(
            Known<br/>Population<br/>Variances
              )Two sample z test<br/>for Independent<br/>Samples(
          {{Proportions between<br/>0 and 1<br/>obtained from two <br/>Binary Responses}}
            )Two sample z test<br/>for Independent<br/>Samples(
        Two<br/>Related<br/>Populations or<br/>Measurements
          {{Unbounded<br/>Responses}}
            )Two sample t test<br/>for Paired<br/>Samples(
      (Chapter 3: <br/>ANOVA-related <br/>Tests for<br/>k Continuous<br/>Population Means)
```

A specific hypothesis testing mind map outlining the techniques explored in this chapter, which are classical tests for two continuous population means.
:::

In this chapter, we review tests for comparing two continuous population means under two conditions: when the populations are independent and when they are dependent. Throughout the sections below, we provide details about these tests and required formula for each case. Broadly speaking, there are two main types of tests to compare the means between two continuous populations:

-   Independent samples, where the observations in one group are unrelated to those in the other, and
-   Paired (or dependent) samples, where observations are naturally matched in some way, such as before-and-after measurements.

The choice of test depends on the structure of your data. This chapter introduces both types of comparisons, beginning with independent samples. Each section includes definitions, theoretical background, and R/Python code examples using real or simulated datasets to help ground the concepts in practice. We also review the theoretical background and exmaple codes to test two proportions.

## Two sample Student's t-test for Independent Samples

### Review

In this section we talk about two sample student's t-test for independent samples. Independent samples arise when the observations in one group do not influence or relate to the observations in the other. In statistical terms we call this two independent samples. A classic example from educational research is described below:

Suppose you're interested in whether a new method of teaching introductory physics improves student performance and learning experience. To investigate this, you decide to test the method at two universities: the University of British Columbia (UBC) and Simon Fraser University (SFU). You apply the new teaching method at SFU and compare the results to students taught with the traditional method at UBC.

In this scenario, students at UBC and SFU form two distinct, unrelated groups. Since the students are not paired or matched across schools, and each individual belongs to only one group, the samples are independent. Note that the samples are drawn from two independent population: students at UBC and SFU, respectively.

Let us assume that each population has an unknown average or mean physics score denoted by:

$$
    \mu_1 \quad \text{(mean for UBC)}, \quad \mu_2 \quad \text{(mean for SFU)}.
$$

Since we do not have access to all students' grades, we take a random sample from each school. Suppose:

-   From UBC (Population 1), we obtain a sample of size $n$, denoted as: $$X_1, X_2, \ldots, X_n$$

-   From SFU (Population 2), we obtain a sample of size $m$, denoted as: $$Y_1, Y_2, \ldots, Y_m$$

Note that the sample sizes $n$ and $m$ do not necessarily have to be equal. Now, the central question becomes:

**Is there a statistically significant difference between the mean physics scores among two groups?**

In formal terms, we test the hypotheses:

$$H_0: \mu_1 = \mu_2 \quad \text{versus} \quad H_A: \mu_1 \ne \mu_2$$
Now that we reviewed the test concept, let's try to understand it in a read dataset. The steps below follows closely with the roadmap that we introduced in [LINK HERE].

### Study design

For this example, we will be using `Auto` dataset from `ISLR` package. This dataset contains gas mileage, horsepower, and other information for 392 vehicles. Some of variables of interest are: 1) `cylinders` an integer (numerical) value between 4 and 8 which indicates the number of cylinders of car, and 2) `horsepower` which shows engine horsepower. You may wondering **if the mean of horsepower in cars with 8 cylinders is statistically different than the means in cars with 4 cylinders?**

### Data Collection and Wrangling

To answer this question, we obtain the dataset which is available in `ISLR` package. Note that we consider this data a random sample from population of cars. First we creat a new copy of this dataset to avoid touching the actual data (this is optional). Also we filter rows to those cars with 4 or 8 cylinders only.

```{r}
# Get a copy of dataset
auto_data <- Auto

# Filter rows to cars with 4 or 8 cylinders
auto_data <- auto_data %>% filter(cylinders %in% c(4,8) )
```

Finally, we randomly create test and train set from this dataset. We use a proportion of 50-50 between train and test.   

```{r}
# Set seed for reproducibility
set.seed(123)

# Splitting the dataset into train and test sets
train_indices <- sample(seq_len(nrow(auto_data)), size = 0.50 * nrow(auto_data))
train_auto <- auto_data[train_indices, ]
test_auto <- auto_data[-train_indices, ]
```


### Explanatory Data Analysis

Once we have the data and it is split into training and test sets, the next step is to begin exploratory data analysis (EDA) on train set. This step is crucial, as it helps us gain a better understanding of the distribution of variables in our dataset. The `horsepower` variable in dataset is a numerical variable. The `cylinders` variable is an integer variable that helps to divide observations into two groups.

In particular, we are interested in the distribution of `horsepower` in two different groups (cars with 4 cylinders vs cars with 8 cylinders). Using a histogram for this variable is a good choice as we have a variable with numerical values.

```{r echo=FALSE}
ggplot(train_auto, aes(x = horsepower)) +
  geom_histogram(fill = "steelblue", color = "white", bins = 20) +
  facet_wrap(~ cylinders, nrow = 1) +
  labs(title = "Side-by-side histogram of horsepower by number of cylinders",
       x = "Horsepower",
       y = "Count") +
  theme_minimal()
```

We also look at some descriptive statistics of horsepower in both groups for better understanding of data. The descriptive statistics in cars with 4 cylinders:

```{r}
summary(train_auto %>% filter(cylinders == 4) %>% select(horsepower))
```

and with 8 cylinders:

```{r}
summary(train_auto %>% filter(cylinders == 8) %>% select(horsepower))
```

Looking at summary statistics, there is a bit of overlap between distribution of `horsepower` among two groups but it does not seem to be much. In fact they seem to be quite separated. Also there is a clear different in their mean and the following plot also confirms this:


```{r echo=FALSE}
ggplot(train_auto, aes(x = horsepower, color = factor(cylinders), fill = factor(cylinders))) +
  geom_density(alpha = 0.4) +
  labs(title = "Density plot of horsepower by number of cylinders",
       x = "Horsepower",
       y = "Density",
       color = "Cylinders",
       fill = "Cylinders") +
  theme_minimal()
```


### Testing Settings

We use a significant level of $\alpha = 0.05$ to run the test. Considering the data we have is a sample from a population of cars we have the following: 

- $\mu_{1}$ is the mean of horsepower for cars with 4 cylinders in the population. 
- $\mu_{2}$ is the mean of horsepower for cars with 8 cylinders in the population. 

### Hypothesis Definitions

We now define the null and alternative hypothesis. Recall the main inquiry we had: 

**You may wondering if the average of horsepower in cars with 4 cylinders is statistically different than the means in cars with 8 cylinders?**

This translates into the following null and alternative hypotheses:

$$H_0: \mu_{1} = \mu_{2} \quad vs \quad H_a: \mu_{1} \neq \mu_{2}$$

Note that the alternative hypothesis is two-sided, as our question does not favor either group and only asks whether the means are different (i.e., group one could be less than or greater than group two). Also the hypothesis tests the unknown parameters in the population which are $\mu_{1}$ and $\mu_{2}$.



### Test Flavour and Components

To test this hypothesis, we use the **two-sample student's t-test for independent samples**, which compares the sample means and incorporates variability within and between the samples. Note that in this case the samples are independent as clearly cars with 4 cylinders are independent from cars with 8 cylinders. 

Now we need to compute a test statistic from the sample. Assuming equal population variances, the test statistic is:

$$t = \frac{(\bar{X} - \bar{Y})}{S_p \sqrt{\frac{1}{n} + \frac{1}{m}}}$$

where:

-   $\bar{X}$ is the mean of horsepower for cars with 4 cylinders in the sample
-   $\bar{Y}$ is the mean of horsepower for cars with 8 cylinders in the sample
-   $S_p$ is the \textbf{pooled standard deviation}, computed as:
  +   $S_p = \sqrt{\frac{(n - 1)S_X^2 + (m - 1)S_Y^2}{n + m - 2}}$
-   $S_X^2$ and $S_Y^2$ are the sample variances of the two groups.


::::: Heads-up
::: Heads-up-header
Heads-up!
:::

::: Heads-up-container
Note that all elements in this formula (statistic) are computed based on sample.
:::
:::::


::::: Tip
::: Tip-header
Tip:
:::


::: Tip-container
The assumption in this test is that variances among two groups are equal meaning that if we look at the random variable of horsepower in both populations, the variance of this random variable is roughly equal in two groups (cars with 4 cylinders and cars with 8 cylinders). 

Note that we do not have access to population and this is rather an assumption that we make with consultation with experts or justifying it based on previous studies. We will introduce the test without equal variance assumption in the next section.

There are some statistical methods designed to test if the variances of different groups are the same or not. Similar to any hypothesis testing, these tests work on a random sample from the population to run the test. Some of the tests are F-test for Equality of Variances, Levene’s Test, and Bartlett’s Test. 
:::
:::::



### Inferential Conclusions

As you can see, the test statistic computes the difference between $\bar{X}$ and $\bar{Y}$ and scale it based on the variance of this difference. Now the question is whether this difference is significant or not? In order to answer this question we need to know the behavior of statistic that we defined ($t$) and have a better understanding of what are typical values of this statistic. Knowing the distribution of this statistic helps us to compute $\textit{p-value}$ of the test as follows:

$$\textit{p-value} = 2 \times Pr(T_{n+m-2} \ge |t|)$$ 

Looking at the formula, we can see that we are essentially calculating how much is it likely to see an observation as big as $t$ or as extreme as $t$ (which we computed from our sample).


::::: Heads-up
::: Heads-up-header
Heads-up!
:::

::: Heads-up-container
Note that $t$ itself is a random variable as it would change from sample to sample. 
:::
:::::


::::: Tip
::: Tip-header
Tip:
:::

::: Tip-container
We skipped the theory behind it but under the assumption that null hypothesis is correct (i.e. $\mu_1=\mu_2$) then the test statistic defined above ($t$) follows a t-distribution with $n + m -2$ degrees of freedom (which we denote it by $T_{n+m-2}$). 

**Note:** The probability is multiplied by two since we have a two sided hypothesis (alternative is $\mu_1 \neq \mu_2$). For a one sided test (when alternative hypothesis is $\mu_1 > \mu_2$ or $\mu_1 < \mu_2$) we do not need to multiply by two.

Now we compare the $\textit{p-value}$ to our significance level. If the $\textit{p-value}$ is less than the significance level, then we have evidence against the null hypothesis. The reasoning is as follows: we performed the calculation under the assumption that the null hypothesis is true. If the null hypothesis is true, then the test statistic we computed should follow a $t$-distribution with $n + m - 2$ degrees of freedom. If the p-value is smaller than our chosen significance level, this means it is unlikely that our observed result comes from a $t$-distribution with $n + m - 2$ degrees of freedom. In other words, it is unlikely that the null hypothesis is correct. 
:::
:::::




Note that our observation from the sample might still lead us to an incorrect conclusion (since there is variability among samples). Our tolerance for this type of error is determined by the significance level. If $\textit{p-value}$ is not less than significant level then we do not have any evidence to reject the null hypothesis. Now let us see how to run the two-sample test in R and Python. Note that for the purpose of hypothesis testing we now use test data to avoid double dipping.


### How to run the test in `R` and `Python`?

The following lines of code in tabset show you how to run the test in `R` or `Python`. Note that there are two ways of running this test in `R` as shown below. They both give the same result and you are welcome to use either of them. Here is a quick explanation from a coding perspective:

- In **Option 1**, we first select the cars with 4 or 8 cylinders and save them in a vector (`cylinders_4` and `cylinders_8`). We then use `t.test` function to run the test.

- In **Option 2**, we use a formula to tell `R` what is the variable that records the outcome of interest (in this example `horsepower` variable) and what is the grouping variable (in this example `cylinders`). This approach is more concise and easier to read, especially when working directly with a data frame. Note that we need to let `R` know where it can find `horsepower` and `cylinders` which we do by setting `data = test_auto`.


::: {.panel-tabset}

### R Code - Option 1

```{r}
# Create a vector to hold horsepower values for cars with 4 cylinders
cylinders_4 <- test_auto %>% filter(cylinders == 4) %>% select(horsepower)

# Create a vector to hold horsepower values for cars with 8 cylinders
cylinders_8 <- test_auto %>% filter(cylinders == 8) %>% select(horsepower)

# Run the test
t.test(x = cylinders_4, y = cylinders_8, var.equal = TRUE)
```

### R Code - Option 2

```{r}
# Use the formula horsepower ~ cylinders to run the test 
t.test(horsepower ~ cylinders, data = test_auto, var.equal=TRUE)
```

```{r echo=FALSE}
write.csv(x = test_auto, file = 'data/test_auto.csv')
```


### Python Code

```{python}
from scipy import stats
import pandas as pd

# Read test_auto dataframe in Python as df dataframe
df = pd.read_csv('data/test_auto.csv')

# Select cars with 4 and 8 cylinders
cylinders_4 = df[df["cylinders"] == 4]["horsepower"]
cylinders_8 = df[df["cylinders"] == 8]["horsepower"]

# Run the test
t_stat, p_val = stats.ttest_ind(cylinders_4, cylinders_8, equal_var = True)

# Print t statistic value
print(f"T-statistic: {t_stat}")

# Print p-value of the test
print(f"P-value: {p_val}")
```
:::

In order to run this test, similar to what we learned in (LINK to chapter 1) we can use `t.test` function in R. The function can be used to perform one or two sample t-tests. The relevant arguments of the function are as follows:

-   `x` is (non-empty) numeric vector of data values.
-   `y` is also (non-empty) numeric vector of data values (can be `NULL` if you run a one sample test).
-   `var.equal` is a binary value (TRUE/FALSE) to indicate if R needs to assume equal variance or not.


In both outputs, we can see the following:

-   `t` is the test statistic.

-   `df` is the degrees of freedom for the test.

`p-value` is the p-value of the test. Note that, by default, this is for a two-sided test. If you need to conduct a one-sided test, you can either divide the p-value by two or use the alternative argument in the t.test function.

-   `95 percent confidence interval` provides the 95% confidence interval for the parameter of $\mu_1 - \mu_2$.

-   `sample estimates` gives the sample means for each group.

**Note:** By default the value of `var.equal` is `FALSE`. We manully set it to `TRUE` to implement equal variance assumption in our test.


### Storytelling

- TBD


## Two sample Welch's t-test for independent samples


### Review

In this section we talk about two sample Welch's t-test for independent samples. This test is very similar to two sample Student's t-test for independent samples that we described with a caveat. The two samples are still independent but the only difference is the equal variance assumption. We use this test if we do not have any reason or evidence to believe that the variance of variable of interest is the same among two groups in the population.


### Study Design

We will be using `Auto` dataset from `ISLR` package in this section too. Now the main statistical question of interest remains the same as before: **You may wondering if the mean of horsepower in cars with 8 cylinders is statistically different than the means in cars with 4 cylinders?** but we do **not** make an equal variance assumption anymore. Now we are applying a two sample Welch's t-test for independent samples.


### Data Collection and Wrangling

To answer this question, we obtain the dataset which is available in `ISLR` package. The following codes are exactly the same as before and are shown here as a review.

```{r}
# Get a copy of dataset
auto_data <- Auto

# Filter rows to cars with 4 or 8 cylinders
auto_data <- auto_data %>% filter(cylinders %in% c(4,8) )
```

Finally, we randomly create test and train set from this dataset. We use a proportion of 50-50 between train and test.   

```{r}
# Set seed for reproducibility
set.seed(123)

# Splitting the dataset into train and test sets
train_indices <- sample(seq_len(nrow(auto_data)), size = 0.50 * nrow(auto_data))
train_auto <- auto_data[train_indices, ]
test_auto <- auto_data[-train_indices, ]
```


### Explanatory Data Analysis

Once we have the data and it is split into training and test sets, the next step is to begin exploratory data analysis (EDA) on train set. Recall that the `cylinders` variable is an integer variable that helps to divide observations into two groups.

We are still interested in the distribution of `horsepower` in two different groups (cars with 4 cylinders vs cars with 8 cylinders). Using a histogram for this variable is a good choice as we have a variable with numerical values.

The following lines of code are the same as previous section as we are working on the same data. This is shown as a reminder.

```{r echo=FALSE}
ggplot(train_auto, aes(x = horsepower)) +
  geom_histogram(fill = "steelblue", color = "white", bins = 20) +
  facet_wrap(~ cylinders, nrow = 1) +
  labs(title = "Side-by-side histogram of horsepower by number of cylinders",
       x = "Horsepower",
       y = "Count") +
  theme_minimal()
```

We also look at some descriptive statistics of horsepower in both groups for better understanding of data. The descriptive statistics in cars with 4 cylinders:

```{r}
summary(train_auto %>% filter(cylinders == 4) %>% select(horsepower))
```

and with 8 cylinders:

```{r}
summary(train_auto %>% filter(cylinders == 8) %>% select(horsepower))
```

Our conclusion remains the same. Looking at summary statistics, there is a bit of overlap between distribution of `horsepower` among two groups but it does not seem to be much. In fact they seem to be quite separated. Also there is a clear different in their mean and the following plot also confirms this:


```{r echo=FALSE}
ggplot(train_auto, aes(x = horsepower, color = factor(cylinders), fill = factor(cylinders))) +
  geom_density(alpha = 0.4) +
  labs(title = "Density plot of horsepower by number of cylinders",
       x = "Horsepower",
       y = "Density",
       color = "Cylinders",
       fill = "Cylinders") +
  theme_minimal()
```

### Testing Settings

We use a significant level of $\alpha = 0.05$ to run the test. Considering the data we have is a sample from a population of cars we have the following: 

- $\mu_{1}$ is the mean of horsepower for cars with 4 cylinders in the population. 
- $\mu_{2}$ is the mean of horsepower for cars with 8 cylinders in the population. 

### Hypothesis Definitions

We now define the null and alternative hypothesis. Recall the main inquiry we had: 

**You may wondering if the average of horsepower in cars with 4 cylinders is statistically different than the means in cars with 8 cylinders?**

This translates into the following null and alternative hypotheses:

$$H_0: \mu_{1} = \mu_{2} \quad vs \quad H_a: \mu_{1} \neq \mu_{2}$$

Note that the alternative hypothesis is two-sided, as our question does not favor either group and only asks whether the means are different (i.e., group one could be less than or greater than group two). Also the hypothesis tests the unknown parameters in the population which are $\mu_{1}$ and $\mu_{2}$.


### Test Flavour and Components

As noted before we use Welch’s t-test if the assumption of equal variances is questionable. This test adjusts the standard error and degrees of freedom (`df`) of the test accordingly. As a result the test statistic and `df` of the test are different. The Welch's test statistic is computed as:

$$t = \frac{\bar{X} - \bar{Y}}{\sqrt{\frac{S_X^2}{n} + \frac{S_Y^2}{m}}}$$

where:

-   $\bar{X}$ is the mean of horsepower for cars with 4 cylinders in the sample
-   $\bar{Y}$ is the mean of horsepower for cars with 8 cylinders in the sample
-   $S_X^2$ and $S_Y^2$ are the sample variances of the two groups.
-   $n$ and $m$ are the sample sizes in two groups (not necessarily the same).


::::: Heads-up
::: Heads-up-header
Quick review!
:::

::: Heads-up-container
Note that, as before, all elements in this formula (statistic) are computed based on the sample. Additionally, the assumption of unequal variance between two populations can be tested using a variety of statistical tests. We do not discuss these tests in this book as the focus of this book lies elsewhere.
:::
:::::




### Inferential Conclusions

As you can see, the test statistic computes the difference between averages of two samples and adjusts it based on the variance of their differences. The only change from Student's t-test is the variance that is being used in the denominator. Again the question is whether this difference is significant or not? In order to answer this question we need to know the behavior of statistic that we defined and have a better understanding of what are typical values of this statistic. Knowing the distribution of this statistic helps us to compute the $p-value$ of the test as follows:

$$\textit{p-value} = 2 \times Pr(T_{\nu} \ge |t|)$$ 



::::: Tip
::: Tip-header
Tip on degrees of freedom!
:::


::: Tip-container
The Greek sign $\nu$ is used here to show the degree of freedom of the t-distribution and is computed as

$$\nu = \frac{\left( \frac{s_1^2}{n} + \frac{s_2^2}{m} \right)^2}
{\frac{\left( \frac{s_1^2}{n} \right)^2}{n - 1} + \frac{\left( \frac{s_2^2}{m} \right)^2}{m - 1}}$$

We skipped the theory behind it but under the assumption that null hypothesis is correct, the test statistic defined above still follows a t-distribution but with a different degrees of freedom. Note that this degree of freedom is not necessarily an integer number (could be a real number).
:::
:::::





### How to run the test in `R` and `Python`?

The following lines of code in tabset show you how to run the Welch's test in `R` or `Python`. 


::::: Heads-up
::: Heads-up-header
A quick reminder!
:::

::: Heads-up-container
- In **Option 1**, we first select the cars with 4 or 8 cylinders and save them in a vector (`cylinders_4` and `cylinders_8`). We then use `t.test` function to run the test.

- In **Option 2**, we use a formula to tell `R` what is the variable that records the outcome of interest (in this example `horsepower` variable) and what is the grouping variable (in this example `cylinders`). This approach is more concise and easier to read, especially when working directly with a data frame. Note that we need to let `R` know where it can find `horsepower` and `cylinders` which we do by setting `data = test_auto`.
:::
:::::



::: {.panel-tabset}

### R Code - Option 1

```{r}
# Create a vector to hold horsepower values for cars with 4 cylinders
cylinders_4 <- test_auto %>% filter(cylinders == 4) %>% select(horsepower)

# Create a vector to hold horsepower values for cars with 8 cylinders
cylinders_8 <- test_auto %>% filter(cylinders == 8) %>% select(horsepower)

# Run the test
t.test(x = cylinders_4, y = cylinders_8, var.equal = FALSE)
```

### R Code - Option 2

```{r}
# Use the formula horsepower ~ cylinders to run the test 
t.test(horsepower ~ cylinders, data = test_auto, var.equal = FALSE)
```


```{r echo=FALSE}
write.csv(x = test_auto, file = 'data/test_auto.csv')
```


### Python Code

```{python}
from scipy import stats
import pandas as pd

# Read test_auto dataframe in Python as df dataframe
df = pd.read_csv('data/test_auto.csv')

# Select cars with 4 and 8 cylinders
cylinders_4 = df[df["cylinders"] == 4]["horsepower"]
cylinders_8 = df[df["cylinders"] == 8]["horsepower"]

# Run the test
t_stat, p_val = stats.ttest_ind(cylinders_4, cylinders_8, equal_var = False)

# Print t statistic value
print(f"T-statistic: {t_stat}")

# Print p-value of the test
print(f"P-value: {p_val}")
```
:::

In order to run this test, similar to what we learned in (LINK to chapter 1) we can use `t.test` function in R. The function can be used to perform one or two sample t-tests. The relevant arguments of the function are as follows:

-   `x` is (non-empty) numeric vector of data values.
-   `y` is also (non-empty) numeric vector of data values (can be `NULL` if you run a one sample test).
-   `var.equal` is a binary value (TRUE/FALSE) to indicate if R needs to assume equal variance or not.


In both outputs, we can see the following:

-   `t` is the test statistic.

-   `df` is the degrees of freedom for the test.

`p-value` is the p-value of the test. Note that, by default, this is for a two-sided test. If you need to conduct a one-sided test, you can either divide the p-value by two or use the alternative argument in the t.test function.

-   `95 percent confidence interval` provides the 95% confidence interval for the parameter of $\mu_1 - \mu_2$.

-   `sample estimates` gives the sample means for each group.

**Note:** By default the value of `var.equal` is `FALSE`. We manully set it to `FALSE` to implement the test without equal variance assumption.


### Storytelling

- TBD



- All from here is under development

## Paired Samples

Paired samples arise when each observation in one group is matched or linked to an observation in the other group. This structure is typical in before-and-after studies, matched-subject designs, or repeated measures on the same individuals. A classic example comes from health sciences.

Suppose you're investigating whether a new diet plan reduces blood pressure. You recruit a group of participants and record their blood pressure **before** starting the diet. **After** following the diet for two months, you measure their blood pressure again. In this scenario, each participant contributes two measurements: one before **the intervention** and one after. These measurements are not independent as they come from the same person. Therefore we treat them as paired.

To formulate the problem and hypothesis, let us assume that each individual has two measurements:

-   Before the diet: $X_1, X_2, \ldots, X_n$

-   After the diet: $Y_1, Y_2, \ldots, Y_n$

Note that in this case the sample size is the same (in both before and after diet sample we have $n$ observations). We call this a paired sample. Since the samples are paired, we define the difference for each individual as follows:

$$D_i = Y_i - X_i \quad \textit{for} \quad i = 1,2, \ldots, n$$ Each $D_i$ is the difference of blood pressure after and before using new diet. The main statistical question now is:

**Is there a statistically significant difference in the mean blood pressure before and after the diet?**

In other words, we test the following hypothesis:

$$H_0: \mu_D = 0 \quad \text{versus} \quad H_A: \mu_D \ne 0$$ Here the notation of $\mu_D$ is the population mean of the differences of $D_i$ which is an unknown parameter in the population. To test this hypothesis, we use the paired t-test, which is essentially a one-sample t-test on the differences $D_1, D_2, \ldots, D_n$. We test $\mu_D=0$ because if there is an actual effect of diet on blood pressure, we expect the null hypothesis to be rejected.

The test statistic for this hypothesis testing is:

$$t = \frac{\bar{D}}{s_D / \sqrt{n}}$$

where:

-   $\bar{D}$ is the sample mean of the differences,
-   $s_D$ is the sample standard deviation of the differences,
-   $n$ is the number of pairs.

The standard deviation of the differences is calculated as:

$$s_D = \sqrt{ \frac{1}{n - 1} \sum_{i=1}^n (D_i - \bar{D})^2 }$$

Under the null hypothesis, the test statistic follows a t-distribution with $n-1$ degrees of freedom. For this test, we can compute the $\textit{p-value}$ as:

$$\textit{p-value} = 2 \times \Pr(T_{n - 1} \ge |t|)$$



 When we run t-test, we operate under the assumption that: 1) either the sample size is large enough (we are thinking about $n=30$ at least) so that central limit theorem assumptions work well, or 2) the distribution of our sample in each group is normal or symmetric enough.

If the normality assumption is also not satisfied (e.g., due to skewed distributions or outliers) or we have a very small sample size, we may turn to a non-parametric alternative, such as the Mann–Whitney–Wilcoxon test, which compares the ranks of the observations across groups rather than the raw values but this book will not cover it. You can read more about it LINK.

