<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-DZWGQVJSHE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-DZWGQVJSHE');
</script>

# Introduction

> **The most important maxim for data analysis to heed, and one which many statisticians seem to have shunned, is this: "Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise."**

<p style="text-align: right;">*John W. Tukey* [-@tukey1962, p. 13]</p>

Data collection worldwide has proven to be a valuable tool for uncovering significant insights across various **populations of interest**. Whether it involves capturing political preferences in a specific demographic ahead of an upcoming election or assessing the effectiveness of an innovative medical treatment through a randomized clinical trial compared to a standard treatment, data plays a crucial role in enhancing our understanding. At times, this understanding can become quite complex, especially when attempting to untangle the relationships between different variables within a given population or even across two or more populations.

![Image by [*Manfred Stege*](https://pixabay.com/users/manfredsteger-1848497/) via [*Pixabay*](https://pixabay.com/vectors/pixel-cells-emotion-bored-6230197/).](img/question.png){width="300"}

In a vast and diverse field like data science, it is crucial to craft effective and transparent solutions that facilitate proper data analysis. However, conducting a full census to collect data from entire populations can often be impractical due to resource limitations such as budget constraints, workforce shortages, or insufficient technical infrastructure. Despite these challenges, our primary objective remains to gain insights about any population of interest via some class of analysis, even when data availability is limited. In this regard, **statistical inference** is a powerful tool that allows us to draw insights even with limited data. That said, it is important to emphasize that the process of statistical inference begins with asking the **right questions**, even before data collection occurs.

In light of this context, we need to establish the appropriate stages of the statistical inference process, along with a useful tool to help select the right hypothesis test based on our specific context, research questions, variable types, and parameters of interest. This is why this mini-book focuses on two key components:

- **A test workflow:** This workflow will primarily guide us in formulating the right questions about our population(s) of interest, which will involve specific parameters. This process will generally proceed with data collection using a specific sampling method, followed by a thorough analysis that includes exploratory data analysis and the **most suitable** hypothesis testing based on our primary question(s). We will conclude the process by presenting a compelling storytelling to our stakeholders. @sec-test-workflow will elaborate further on this workflow.
- **A series of test mind maps:** Since the test workflow ultimately involves selecting the most suitable hypothesis test, we require a form of guidance to choose these tests according to the inferential question(s) we want to address. Therefore, @sec-test-mind-map will introduce our core test mind map from @fig-test-general-mindmap, which will direct us to more detailed mind maps each time we introduce a new chapter.

This mini-book on hypothesis testing is intended to serve as a **practical manual** rather than a traditional statistical textbook. Furthermore, it focuses on providing applied examples in each chapter without any additional exercises for the reader. We aim to explain the necessary mathematical formulas in straightforward language, avoiding formal proofs for these expressions. Additionally, we will establish conventions using admonitions to offer **key insights** and links to **supplementary and more in-depth material**.

::: {.Heads-up}
::::{.Heads-up-header}
Heads-up!
::::
::::{.Heads-up-container}
A key insight (or insights) related to a specific hypothesis test or a stage in the test workflow. The reader is advised to keep this heads-up in mind throughout the showcase of the corresponding example in any given chapter.
::::
:::

::: {.Tip}
::::{.Tip-header}
Tip
::::
::::{.Tip-container}
An idea or ideas that extend beyond the immediate discussion and can offer valuable context and insightful background. Whenever relevant, we will provide references for further reading to deepen understanding and enhance knowledge.
::::
:::

## The Test Workflow {#sec-test-workflow}

> **There is a single test workflow for many different flavours!**

The statement above summarizes the essence of our testing workflow, which requires a detailed examination in this section. Primarily, it is crucial to understand that mastering all hypothesis tests involves more than just knowing their mathematical formulas or coding functions; it requires a disciplined and structured process. Whether we are evaluating evidence against a **null hypothesis**—the status quo of our population parameter(s) of interest—or reporting the uncertainty of an **estimated effect**, the workflow outlined by @fig-hypothesis-testing-workflow is intended to align your main inferential inquiries with the **most suitable test flavour**. Regardless of the flavour chosen, this workflow is designed to ensure that our conclusions are not only statistically valid but also based on clear and purposeful reasoning.

![Image by [*Manfred Stege*](https://pixabay.com/users/manfredsteger-1848497/) via [*Pixabay*](https://pixabay.com/vectors/pixel-cells-teaching-to-learn-wiki-3976301/).](img/board.png){width="475"}

The workflow for hypothesis testing consists of eight stages, which will be discussed in detail in the following sections:

1. **Study design:** This initial stage, referred to as the **main inferential inquiries**, outlines the primary questions we aim to answer through our analysis.
2. **Data collection and wrangling:** The inquiries established in the first stage will guide the design of our data collection, utilizing a specific sampling scheme. Once the data is collected, it must be wrangled and split into two sets: **training** and **test**.
3. **Exploratory data analysis:** In this stage, we classify variables to provide preliminary insights using descriptive statistics and visualizations via the training set.
4. **Testing settings:** We must revisit the **significance level** used in our power analysis (i.e., the procedure used to obtain the minimum sample size $n$ of data points to be collected). Additionally, we need to list all modelling parameters that will be tested.
5. **Hypothesis definitions:** With the modelling parameters to test, we need to define our hypotheses: the **null** hypothesis versus the **alternative** hypothesis. These should be framed in relation to the main inferential inquiries.
6. **Test flavour and components:** At this stage, we choose the most appropriate test flavour and indicate the respective **assumptions**. Depending on whether the test is classical or simulation-based, we will then identify the necessary components to compute the **critical** values or **$p$-values** (via the test set) for the next stage.
7. **Inferential conclusions:** The goal of this stage is to determine whether we should reject the null hypothesis based on the critical values or $p$-values obtained. This stage also includes running the **model diagnostics** to check our corresponding assumptions.
8. **Storytelling:** Finally, communicate the findings through a clear and engaging narrative that is accessible to your stakeholders.

::: {#fig-hypothesis-testing-workflow}
![](img/hypothesis-testing-workflow.png){width="1500"}

A hypothesis testing workflow structured in eight stages: *study design*, *data collection and wrangling*, *exploratory data analysis*, *testing settings*, *hypothesis definitions*, *test flavour and components*, *inferential conclusions*, and *storytelling*.
:::



### Study Design {#sec-study-design}

This is the initial stage of the hypothesis testing workflow, which involves what we refer to as **main inferential inquiries**. These inquiries are typically posed by stakeholders who wish to conduct a study to better understand a specific population of interest and its associated parameters. In practice, these parameters (such as a population mean or variance) are unknown but considered fixed. This approach, where population parameters are treated as fixed yet unknown, is known as the **frequentist paradigm**.

::: {.Heads-up}
::::{.Heads-up-header}
Heads-up on the frequentist paradigm!
::::
::::{.Heads-up-container}
In the frequentist paradigm, statistical inference relies on the concept that probabilities represent **long-run** relative frequencies of events observed through repeated experimentation or observation. In this approach, we estimate population parameters by examining the distribution of outcomes derived from multiple independent realizations of a random process. 

![Image by [*Manfred Stege*](https://pixabay.com/users/manfredsteger-1848497/) via [*Pixabay*](https://pixabay.com/vectors/laptop-games-jigsaw-puzzle-puzzle-7426707/).](img/puzzle.png){width="300"}

Additionally, this paradigm assumes that the parameters governing a population are **fixed but unknown**. As a result, all randomness is attributed to the data-generating process, not to the parameters themselves.
::::
:::

It is essential to clearly define the main inferential inquiries based on the following principles:

- We need to consult stakeholders about what the study aims to understand regarding their population of interest before entering the second workflow stage, which involves data collection through sampling.
- The main inferential inquiries should align with the stakeholders' research questions. These inquiries should be established at the beginning of this workflow stage and must be meaningful and comprehensive enough to guide the entire inferential investigation.

### Data Collection and Wrangling {#sec-data-collection-wrangling}

Once the inferential questions are defined, the next step is to collect and prepare the data for analysis. This stage encompasses sampling strategies to ensure the data is representative of the population and data wrangling to clean and structure the dataset appropriately. 

::: {.Tip}
::::{.Tip-header}
Tip on sampling techniques!
::::
::::{.Tip-container}
It is important to emphasize the need to choose the **most suitable sampling technique** based on the population's structure and the research questions guiding our main inferential inquiries. Making the right choice of sampling technique is essential for ensuring that our inferential results are accurate, precise, and generalizable to the population of interest. Here are some fundamental (though not exhaustive) sampling techniques:

- **Simple random sampling:** Every individual in the population has an equal probability of being sampled. This is the most basic sampling technique and is probabilistically straightforward, but it may be too simplistic for complex populations in practice.
- **Systematic sampling:** If we have a complete list of individuals in our population, we can sample at regular intervals after selecting a random starting point.
- **Stratified sampling:** The population is divided into distinct groups called strata. These strata are defined in function of the characteristics of the individuals (e.g., age, income, education, etc.). Data is then sampled proportionally from each stratum or through optimal allocation.
- **Cluster sampling:** The population is divided into groups known as clusters, such as households or geographic areas. A random sample is then collected from these clusters.

During the stage of data collection and wrangling of our hypothesis workflow, it is crucial to dedicate adequate resources to plan and execute data collection using the most suitable sampling technique. Since the scope of this mini-book does not cover sampling in depth, we recommend reviewing the work by @lohr2021 for more detailed information on various sampling techniques. This resource includes handy practical examples on this vast field.
::::
:::

When it comes to the wrangling aspect of this stage, once we have sampled our data, it is necessary to structure it in a suitable format (e.g., a proper data frame) using our chosen package, such as the `R` [{tidyverse}](https://www.tidyverse.org) [@tidyverse] or  `Python` [{pandas}](https://pypi.org/project/pandas/) [@pandas2024]. After we have wrangled our data, we need to split it into two sets:

- **Training Set.** This set is used solely for exploratory data analysis (EDA) and allows us to gain graphical and descriptive insights into how the sample of individuals behaves concerning our main inferential inquiries.
- **Test Set.** This set is reserved for input in our chosen hypothesis testing to be used.

The data splitting is analogous to the standard practice in machine learning to split our data for model training and testing to prevent data leakage in **predictive inquiries**.

![Image by [*Manfred Steger*](https://pixabay.com/users/manfredsteger-1848497/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3699345) via [*Pixabay*](https://pixabay.com/vectors/pixel-cells-pixel-social-network-3704049/).](img/paint.png){width="525"}

Nevertheless, you might wonder: 

> **Why are we also doing this for an inferential inquiry?** 

Statistically speaking, the practice of data splitting helps avoid what is known as **double dipping**. Double dipping occurs when the same data is used both for exploratory data analysis (EDA) to generate hypotheses and then again for formal statistical testing. Theoretically, and supported by numerical simulations, it has been shown that double-dipping **increases the probability of committing a Type I error**, which occurs when we incorrectly reject the null hypothesis $H_0$ while it is actually true for the population of interest.

For example, consider a one-sample $t$-test in a double-dipping context. We might be tempted to formulate our null and alternative hypotheses based on our observed sample mean. For instance, we could state our hypotheses as follows: $\text{$H_0$: } \mu \geq 10$ (null hypothesis) versus $\text{$H_1$: } \mu < 10$ (alternative hypothesis), based on a sample mean of $\bar{x} = 9.5$. If we were to proceed with the statistical test using this same data, we would be falling into the double-dipping trap!

::: {.Tip}
::::{.Tip-header}
Tip on a further double-dipping resource!
::::
::::{.Tip-container}
Data splitting is generally not a common practice in statistical inference, despite its frequent use in machine learning. Hence, for more information on double-dipping in statistical inference, Chapter 6 from @reinhart2015 offers in-depth insights and practical examples.
::::
:::

### Exploratory Data Analysis {#sec-exploratory-data-analysis}

Once the data is cleaned and structured, it is essential to develop a descriptive understanding of our variables of interest through EDA using the training set. The first step is to classify the variables (e.g., numerical, binary, categorical, ordinal, etc.), which will guide us in selecting the most appropriate descriptive statistics and visualizations to examine the relationships between these variables. For instance, we can explore the distribution of these variables and identify any outliers present in the training set. Note EDA is intended to uncover preliminary trends before conducting formal inferential analysis, and these findings should be communicated to our stakeholders during the final storytelling.

![Image by [*Manfred Stege*](https://pixabay.com/users/manfredsteger-1848497/) via [*Pixabay*](https://pixabay.com/vectors/pixel-cells-lecture-lecturer-3976299/).](img/meeting-1.png){width="400"}

Additionally, the classification of variables during EDA will provide valuable insights for formulating and setting up our hypotheses, while also helping us choose the **right test flavour**. The insights gained from EDA, along with the identified preliminary trends, will shape our expectations for the entire workflow and facilitate a more nuanced statistical interpretation of the main inferential inquiries. Furthermore, EDA aids in justifying our modelling assumptions later in the process. Finally, we must clarify that any insights gained from EDA cannot be generalized to the entire population; they pertain only to the sampled data within the training set.

### Testing Settings {#sec-testing-settings}

This stage allows us to define all our population parameters based on the main inferential inquiries, along with the standards that will guide us through the subsequent stages of the workflow:

1. We need to use the same significance level, denoted as $\alpha$, that was employed in the **power analysis** when planning data collection for our sampling technique. The significance level denotes the probability of committing Type I error as in @tbl-errors (i.e., the probability of encountering a **false positive**).
2. Regarding the population parameters of interest, we should begin with a formal statistical definition using Greek letters (for further information, see @sec-greek-alphabet).

|       | **$H_0$ is true** | **$H_0$ is false** |
|:-----:|:-----:|:-----:|
| **Reject $H_0$** | Type I error (*False positive*) | Correct |
| **Fail to reject $H_0$** | Correct | Type II error (*False negative*) |

: Types of inferential conclusions in a frequentist hypothesis testing. {#tbl-errors .hover}


::: {.Heads-up}
::::{.Heads-up-header}
Heads-up on power analysis!
::::
::::{.Heads-up-container}
In hypothesis testing, power analysis is a crucial preliminary step used to determine the minimum sample size $n$ necessary to detect a signal that allows us to reject the null hypothesis $H_0$ in favor of the alternative hypothesis $H_1$. This analysis ensures that our inferential process can effectively distinguish true population effects from random noise. Note that power analysis requires three key components as inputs:

1. The significance level $\alpha$.
2. The desired power $1 - \beta$ (which relates to correctly rejecting $H_0$ in favour of $H_1$, resulting in a **true positive** as in @tbl-errors).
3. The effect size—a measure of the magnitude of the association (or causation) that the test is designed to detect.

These three components allow power analysis to provide the minimum sample size $n$ needed to avoid an underpowered study (which occurs when there is a high probability of committing a Type II error as in @tbl-errors, denoted as $\beta$) or an overly large $n$ that could waste resources.
::::
:::

![Image by [*Manfred Steger*](https://pixabay.com/users/manfredsteger-1848497/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3699345) via [*Pixabay*](https://pixabay.com/vectors/pixel-cells-blended-learning-6230153/).](img/blender.png){width="400"}

To effectively communicate our insights to stakeholders via our final storytelling, it is necessary to translate all modelling parameters and hypotheses into clear, plain language for those who may not have a technical background. We should remember that $H_0$ must be stated in a way that indicates a **status quo** in any given parameter(s), meaning there is nothing noteworthy in the context of our inferential study. On the other hand, $H_1$ must imply a **departure from this status quo**, indicating that there is indeed something of interest to consider in our inferential analysis.

### Hypothesis Definitions {#sec-hypothesis-definitions}

![Image by [*Manfred Steger*](https://pixabay.com/users/manfredsteger-1848497/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3699345) via [*Pixabay*](https://pixabay.com/vectors/pixel-cells-protocol-exchange-3947913/).](img/test.png){width="420"}

### Test Flavour and Components {#sec-test-flavour-components}

![Image by [*Manfred Steger*](https://pixabay.com/users/manfredsteger-1848497/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3699345) via [*Pixabay*](https://pixabay.com/vectors/pixel-cells-pixel-college-3702064/).](img/plug.png){width="500"}

### Inferential Conclusions {#sec-inferential-conclusions}

![Image by [*Manfred Steger*](https://pixabay.com/users/manfredsteger-1848497/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3699345) via [*Pixabay*](https://pixabay.com/vectors/pixel-cells-pixel-digital-3704070/.](img/pinned-notes.png){width="500"}


### Storytelling {#sec-storytelling}

![Image by [*Manfred Stege*](https://pixabay.com/users/manfredsteger-1848497/) via [*Pixabay*](https://pixabay.com/vectors/pixel-cells-seminar-conference-3974170/).](img/meeting-2.png){width="500"}

## The Test Mind Map {#sec-test-mind-map}

::: {#fig-test-general-mindmap}
```{mermaid}
mindmap
  root((Frequentist
  Hypothesis 
  Testings
  ))
    Simulation Based<br/>Tests
    Classical<br/>Tests
      (Chapter 2: <br/>Tests for One<br/>Continuous<br/>Population Mean)
        {{Unbounded<br/>Response}}
        {{Proportion between<br/>0 and 1<br/>obtained from a <br/>Binary Response}}
      (Chapter 3: <br/>Tests for Two<br/>Continuous<br/>Population Means)
        Two<br/>Independent<br/>Populations
          {{Unbounded<br/>Responses}}
          {{Proportions between<br/>0 and 1<br/>obtained from two <br/>Binary Responses}}
        Two<br/>Related<br/>Populations or<br/>Measurements
          {{Unbounded<br/>Responses}}
      (Chapter 4: ANOVA related <br/>Tests for<br/>k Continuous<br/>Population Means)
        {{Unbounded<br/>Responses}}
```

A general hypothesis testing mind map outlining all techniques explored in this book. Depending on the overall approach to be used, these techniques are divided into two broad categories: classical and simulation-based tests.
:::


