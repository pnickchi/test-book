<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-DZWGQVJSHE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-DZWGQVJSHE');
</script>

```{r}
#| include: false

library(reticulate)
library(DT)

# Setting up Python dependencies
# py_require("pandas")
# py_require("numpy")
# pandas <- import("pandas")
# numpy <- import("numpy")

options(htmlwidgets.TOJSON_ARGS = list(na = 'string')) 

print_as_dt <- function(x){
  DT::datatable(x,
                rownames = FALSE,
                options = list(
                  dom = 'ltipr', 
                  autoWidth = TRUE,
                  columnDefs = list(
                    list(className = 'dt-left', targets = "_all"),
                    list(width = '200px', targets = "_all")
                    )
                  )
                )
}
```

# ANOVA-related Tests for $k$ Continuous Population Means {#sec-anova}

::: {.LO}
::::{.LO-header}
Learning Objectives
::::
::::{.LO-container}
By the end of this chapter, you will be able to:

- Explain how analysis of variance (ANOVA) **partitions** total variation into **between-group** and **within-group** components.
- Interpret the meaning of the **$F$-statistic** and its role in testing mean differences across groups.
- Describe the difference between **main effects** and **interaction effects** in a two-way ANOVA.
- Identify potential **interaction patterns** via appropriate plotting when conducting a two-way ANOVA.
- Conduct one-way and two-way ANOVA in a **reproducible manner** using the hypothesis testing workflow via `R` and `Python`.
- Identify the assumptions underlying one-way and two-way ANOVA, including **independence**, **normality**, and **homoscedasticity**.
- Evaluate **model diagnostics** to assess whether ANOVA assumptions are met.
::::
:::

It is time to expand our hypothesis testing framework from comparing two population means to a generalized approach for $k$ population means by exploring **analysis of variance (ANOVA)**. ANOVA is a foundational test in frequentist statistics designed to compare means across multiple populations under specific distributional assumptions, which we will examine in this chapter. Originally formalized by Ronald A. Fisher [@fisher1925], ANOVA extends the concept of the two-sample $t$-test by partitioning the total variability of our outcome of interest into components attributable to **main effects**, **interactions**, and **random error**. This partitioning enables us to determine whether observed differences in groups are improbable to appear under the null hypothesis, which states that all groups share the same population mean.

::: {#fig-test-chapter-3-mindmap}
```{mermaid}
mindmap
  root((Frequentist
  Hypothesis 
  Testings
  ))
    Simulation Based<br/>Tests
    Classical<br/>Tests
      (Chapter 1: <br/>Tests for One<br/>Continuous<br/>Population Mean)
      (Chapter 2: <br/>Tests for Two<br/>Continuous<br/>Population Means)
      (Chapter 3: <br/>ANOVA-related <br/>Tests for<br/>k Continuous<br/>Population Means)
        {{Unbounded<br/>Responses}}
          One<br/>Factor type<br/>Feature
            )One way<br/>ANOVA(
          Two<br/>Factor type<br/>Features
            )Two way<br/>ANOVA(
```

A specific hypothesis testing mind map outlining the techniques explored in this chapter, which include ANOVA-related tests for $k$ population means.
:::

::::: Heads-up
::: Heads-up-header
Heads-up on some historical background in statistics!
:::
::: Heads-up-container
While Ronald A. Fisher (1890–1962) is rightly recognized as a significant figure in modern statistics for developing key concepts such as ANOVA, it is imperative to recognize the broader context of his legacy. Beyond his pioneering contributions to statistics, Fisher was also a prominent advocate of eugenics, a movement that promoted pseudoscientific ideas about human heredity and social hierarchy. His involvement with the eugenics community is well documented [@mackenzie1981]. These views have been called out by certain members of the scientific community [@tarran2020]. That said, we (the authors of this mini-book) consider that students and scholars need to distinguish Fisher’s statistical insights from the unethical ideologies he supported, while also acknowledging the social responsibility to critique the historical misuse of science.

Fisher’s statistical work remains central to frequentist inference. However, educators and researchers must confront the historical connection between statistical innovation and eugenic thinking in early 20th-century science [@tabery2015]. By explicitly addressing this context, we can acknowledge the rigour of Fisher’s methodological contributions while rejecting the discriminatory worldviews he promoted. This approach aligns with contemporary efforts to ensure that teaching statistics is grounded not only in subject matter accuracy but also in ethical reflection and historical accountability [@kennedyshaffer02024].
:::
:::::

This chapter builds on the concepts introduced in the earlier works by @sec-one-continuous-mean and @sec-two-continuous-means, which concentrated on hypothesis testing for one and two groups, respectively. While those chapters primarily addressed pairwise comparisons, we will now shift our focus multiple comparisons:

- The **one-way ANOVA**, discussed in @sec-one-way-ANOVA, will assume a **single categorical factor with $k$ levels**. This approach allows us to test whether at least one group mean is significantly different from the others.
- In contrast, the **two-way ANOVA**, from @sec-two-way-ANOVA, will incorporate an **additional categorical factor with $m$ levels**, permitting the analysis of both main effects and interaction effects. Interaction terms in ANOVA are especially useful for revealing cases where the effect of one factor depends on the level of another, a situation often encountered in complex experimental designs.

As a side note, the workflow guiding this chapter, as referenced in @fig-hypothesis-testing-workflow, will provide a structured approach for applying both one-way and two-way ANOVA to the same A/B/n dataset (see @sec-ANOVA-dataset).

::::: Heads-up
::: Heads-up-header
Heads-up on the importance of ANOVA in data science!
:::
::: Heads-up-container
In modern data science, ANOVA remains significant, particularly in **A/B/n testing** (the generalization of **A/B testing** to multiple treatments). This approach allows for the simultaneous evaluation of various treatment variations or designs. ANOVA is valued for its interpretability and its flexibility in handling both **balanced** designs (where there is an equal number of replicates for each experimental treatment) and **unbalanced** designs (where there are unequal numbers of replicates). These strengths have solidified its role in both academic research and practical applications.

![Image by [*Manfred Steger*](https://pixabay.com/users/manfredsteger-1848497/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3699345) via [*Pixabay*](https://pixabay.com/vectors/pixel-cells-download-data-transfer-3947910/).](img/pulling.png){width=100%}
:::
:::::

## The ANOVA Dataset {#sec-ANOVA-dataset}

The **simulated dataset** discussed in this chapter relates to an experimental context known as A/B/n testing, which is an expansion of traditional A/B testing as previously discussed. In a typical A/B testing, participants are randomly assigned to one of two strategies, referred to as treatments: treatment $A$ (the **control treatment**) and treatment $B$ (the **experimental treatment**). This approach enables us to infer **causation** concerning the following inquiry:

> **Will changing from treatment $A$ to treatment $B$ cause my outcome of interest, $Y$, to increase (or decrease, if that is the case)?**

In an ANOVA setting, the outcome must be continuous. The primary goal of A/B testing is to determine whether there is a statistically significant difference between treatments $A$ and $B$ concerning the outcome. Additionally, because we are conducting a proper randomized experiment, we can infer causation (which goes further than mere association), as treatment randomization enables us to get rid of the effect of further **confounders**.

::::: Heads-up
::: Heads-up-header
Heads-up on confounding!
:::
::: Heads-up-container
In causal inference, confounding refers to the mixing of effects between the outcome of interest, denoted as $Y$, the randomized factor $X$ (which is a two-level factor in A/B testing, corresponding to treatment $A$ and treatment $B$), and a third, uncontrollable factor known as the confounder $C$. This confounder is associated with the factor $X$ and independently affects the outcome $Y$, as shown by @fig-confounding.

![Diagram depicting confounding [@DSCI554].](img/confounding.png){fig-align="center" width=80% #fig-confounding}
:::
:::::

When conducting experiments with more than two treatments in A/B testing, the experiment is referred to as **A/B/n testing**. In this case, the "*n*" does not indicate the sample size; rather, it simply represents any number of additional treatments beyond treatments $A$ and $B$. With this clarification, we can now proceed with our simulated dataset.

![Image by [*Pabitra Kaity*](https://pixabay.com/users/pabitrakaity-7844390/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=6370790) via [*Pixabay*](https://pixabay.com/illustrations/ads-digital-marketing-advertisements-6370790/).](img/ads.png){fig-align="center" width=60%}

```{r}
#| label: tbl-ANOVA-ABn-data
#| tbl-cap: "First 100 rows of our A/B/n simulated data."
#| echo: false 
#| message: false

set.seed(123)  # Seed for reproducibility

# Factor levels and sampled customers per treatment
webpage_design_levels <- c("D1", "D2", "D3")
discount_framing_levels <- c("Low", "High")
n_per_treatment <- 200

# Population fixed additive parameters
alpha <- c(40, 50, 70)
beta <- c(-5, 12)
interaction <- matrix(
  c(
    0, 5,
    -8, 0,
    11, -13
  ),
  nrow = 3, byrow = TRUE
)

# Simulating data
data_list <- list()
for (i in 1:3) {
  for (j in 1:2) {
    mean_ij <- alpha[i] + beta[j] + interaction[i, j]
    y <- rnorm(n_per_treatment, mean = mean_ij, sd = sqrt(16))     # sigma^2 = 16
    df_ij <- data.frame(
      webpage_design = as.factor(webpage_design_levels[i]),
      discount_framing = as.factor(discount_framing_levels[j]),
      conversion_score = round(y, 2)
    )
    data_list[[length(data_list) + 1]] <- df_ij
  }
}
ABn_customer_data <- do.call(rbind, data_list)

# Showing the first 100 customers of the A/B/n testing
head(ABn_customer_data, n = 100) |> 
  print_as_dt()
```


## One-way ANOVA {#sec-one-way-ANOVA}

### Study Design {#sec-one-way-ANOVA-study-design}

### Data Collection and Wrangling {#sec-one-way-ANOVA-data-collection-wrangling}

### Exploratory Data Analysis {#sec-one-way-ANOVA-EDA}

### Testing Settings {#sec-one-way-ANOVA-testing-settings}

### Hypothesis Definitions {#sec-one-way-ANOVA-hypothesis-definitions}

### Test Flavour and Components {#sec-one-way-ANOVA-test-flavour}

### Inferential Conclusions {#sec-one-way-ANOVA-inferential-conclusions}

### Storytelling {#sec-one-way-ANOVA-storytelling}


## Two-way ANOVA {#sec-two-way-ANOVA}

### Study Design {#sec-two-way-ANOVA-study-design}

### Data Collection and Wrangling {#sec-two-way-ANOVA-data-collection-wrangling}

### Exploratory Data Analysis {#sec-two-way-ANOVA-EDA}

### Testing Settings {#sec-two-way-ANOVA-testing-settings}

### Hypothesis Definitions {#sec-two-way-ANOVA-hypothesis-definitions}

### Test Flavour and Components {#sec-two-way-ANOVA-test-flavour}

### Inferential Conclusions {#sec-two-way-ANOVA-inferential-conclusions}

### Storytelling {#sec-two-way-ANOVA-storytelling}


## Chapter Summary {#sec-chapter-4-summary}
