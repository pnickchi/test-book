<!-- Google tag (gtag.js) -->

<script async src="https://www.googletagmanager.com/gtag/js?id=G-DZWGQVJSHE"></script>

<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-DZWGQVJSHE');
</script>

# Chapter 1: Tests for One Continuous Population Mean {.unnumbered}

```{r setup, include=FALSE}
# Setting up Python dependencies
library(reticulate)

# Optional: check if modules are available
if (!py_module_available("pandas")) stop("pandas not found")
if (!py_module_available("seaborn")) stop("seaborn not found")
if (!py_module_available("sklearn")) stop("scikit-learn not found")
if (!py_module_available("statsmodels")) stop("statsmodels not found")

# Import Python modules
pandas <- import("pandas")
seaborn <- import("seaborn")
sklearn <- import("sklearn")
statsmodels <- import("statsmodels")
```

This chapter introduces statistical tests designed to analyze a single sample, which is a fundamental task in data analysis across many disciplines. Whether you're evaluating whether the average recovery time from a treatment differs from a known standard, assessing whether student test scores exceed a benchmark, or testing if the proportion of success in a group differs from an expected rate, these methods help determine whether the observed values are statistically significant or simply due to chance.

::: {#fig-test-chapter-1-mindmap}
```{mermaid}
mindmap
  root((Frequentist
  Hypothesis 
  Testings
  ))
    Simulation Based<br/>Tests
    Classical<br/>Tests
      (Chapter 1: <br/>Tests for One<br/>Continuous<br/>Population Mean)
        {{Unbounded<br/>Response}}
          Known<br/>Population<br/>Variance
            )One sample<br/>t test(
          Unknown<br/>Population<br/>Variance
            )One sample<br/>z test(
        {{Proportion between<br/>0 and 1<br/>obtained from a <br/>Binary Response}}
          )One sample<br/>z test(
      (Chapter 2: <br/>Tests for Two<br/>Continuous<br/>Population Means)
      (Chapter 3: <br/>ANOVA-related <br/>Tests for<br/>k Continuous<br/>Population Means)
```

A specific hypothesis testing mind map outlining the techniques explored in this chapter, which are classical tests for one continuous population mean.
:::

There are several statistical tests used to evaluate hypotheses about a single sample. The appropriate test depends on the type of variable (mean or proportion), sample size, and whether population parameters like variance are known.

We test whether a population mean equals a specific value. The right test depends on:

-   Type of response
-   Whether the population variance is known
-   Sample size

In this chapter, we focus on statistical tests used to evaluate hypotheses about a **single population mean** or **proportion**, based on sample data. These tests help determine whether a sample provides sufficient evidence to conclude that the population mean (or proportion) differs from a specified value.

We cover two cases for the mean — depending on whether the population variance is known or unknown — and one test for binary outcomes where we're testing a population proportion.

------------------------------------------------------------------------

Key tests include:

## One-sample z-test for the mean

Use this test when: - The population variance **σ² is known**, and - The sample comes from a **normally distributed population**, or the **sample size is large** (typically ( n \geq 30 )).

The test statistic is:

$$ z = \frac{\bar{x} - \mu_0}{\sigma / \sqrt{n}} $$

Where: - ( $\bar{x}$ ) is the sample mean\
- ( $\mu_0$ ) is the hypothesized population mean\
- ( $\sigma$ ) is the known population standard deviation\
- ( n ) is the sample size

We compare the calculated ( z )-value to a standard normal distribution to compute a p-value or make a decision based on a critical value.

------------------------------------------------------------------------

## One-sample t-test for the mean

Use this test when:
- The population variance **is unknown**, and
- The sample is either **normally distributed** or **large enough** to rely on the central limit theorem.


Imagine you want to assess whether a new method of teaching introductory physics improves student performance compared to the traditional method previously used. To explore this, you test the new method at the University of British Columbia (UBC) and compare the results to historical data from students who were taught using the traditional approach. This historical data serves as your **reference value**.

Suppose the population has an unknown average physics score, denoted as:

$$
\mu \quad \text{(mean physics score at UBC)}
$$

Since we do not have access to the grades of all students, we take a **random sample** from the population. Let this sample consist of $n$ students, with observed scores:

$$
X_1, X_2, \dots, X_n
$$

The central question becomes:

> **Is the mean physics score in our sample statistically different from a given reference value?**

If, for example, the historical average physics score is known to be **75**, then our question becomes more specific:

> **Is the mean physics score in the sample statistically different from 75?**

### Hypotheses

We can formally express this with the following hypotheses:

- **Null hypothesis** $H_0$: $\mu = 75$
- **Alternative hypothesis** $H_1$: $\mu \ne 75$

Under the null hypothesis, we assume that the average score under the new method is equal to the historical average of 75. If the null is rejected, we conclude that there is a **statistically significant difference**, suggesting that the new method may lead to either **higher or lower** average performance.

The test statistic is:

$$t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}}$$

Where: - ( s ) is the sample standard deviation (used instead of ( $\sigma$ ))

This statistic follows a **t-distribution** with ( n - 1 ) degrees of freedom. 




### Study Design

In this example we use the **Palmer Station Penguins** dataset collected by the LTER in Antarctica (2007 – 2009).  
The dataset spans three penguin species and includes continuous variables such as *flipper length*, *bill size*, and *body mass*.

> **Research question:**  
> *Is the average flipper length of penguins significantly different from 200 mm?*

---

### Data Collection & Wrangling

We obtain the dataset **Palmer Station Penguins** dataset collected by the 'LTER'

```{python}
import seaborn as sns
import pandas as pd
from sklearn.model_selection import train_test_split

# Load dataset
penguins = sns.load_dataset("penguins")

# Drop rows with missing values
penguins_clean = penguins.dropna()

# 80/20 train–test split
train_set, test_set = train_test_split(
    penguins_clean, test_size=0.2, random_state=42
)
```

### Exploratory Data Analysis (EDA)

Before conducting the statistical test, we begin with an exploratory analysis to understand the distribution and characteristics of the flipper_length_mm variable.

First, we examine summary statistics such as the mean, standard deviation, and quartiles. This helps us get a sense of the central tendency and spread of the data:

```{python}
print(train_set["flipper_length_mm"].describe())
```

Next, we visualize the distribution of flipper lengths using a histogram. This allows us to assess whether the data are approximately symmetric and whether any outliers are present:

```{python}
import matplotlib.pyplot as plt

train_set["flipper_length_mm"].hist(edgecolor="black", color="skyblue")
plt.title("Distribution of Flipper Length (mm)")
plt.xlabel("Flipper Length (mm)")
plt.ylabel("Frequency")
plt.show()
```

To explore the relationship between flipper length and another continuous variable, we create a scatter plot of flipper length versus body mass. This helps us visually assess whether larger penguins tend to have longer flippers, and whether this relationship is linear or varies across ranges:

```{python}
plt.scatter(
    train_set["body_mass_g"],
    train_set["flipper_length_mm"],
    alpha=0.6
)
plt.title("Body Mass vs. Flipper Length")
plt.xlabel("Body Mass (g)")
plt.ylabel("Flipper Length (mm)")
plt.show()
```

Now, we can perform one‑Sample t-Test
```{python}
import scipy.stats as stats

t_stat, p_value = stats.ttest_1samp(
    train_set["flipper_length_mm"], popmean=200
)
print(f"t = {t_stat:.3f},  p = {p_value:.4f}")
```
A one-sample t-test was conducted to determine whether the average flipper length of penguins is significantly different from 200 mm. Based on a training sample, the test produced a t-statistic of t  and a p-value of p.

Given a significance level of 0.05, if the p-value is less than 0.05, we reject the null hypothesis and conclude that the average flipper length is significantly different from 200 mm. If not, we do not have sufficient evidence to say it differs.
------------------------------------------------------------------------

## One-sample z-test for proportions

Use this test when: - The variable is **binary** (success/failure, yes/no, etc.), and - You want to test a **population proportion** ( p ), using a large enough sample.

The test statistic is:

$$z = \frac{\hat{p} - p_0}{\sqrt{p_0(1 - p_0)/n}}$$

Where: - ( $\hat{p}$ ) is the sample proportion\
- ( $p_0$ ) is the hypothesized population proportion\
- ( $n$ ) is the sample size

This test assumes ( $np_0 \geq 5$ ) and ( $n(1 - p_0)$ $\geq$ 5 ) to justify the normal approximation to the binomial distribution.

------------------------------------------------------------------------
